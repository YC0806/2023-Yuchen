{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nuse_gpu = torch.cuda.is_available()\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T19:11:03.160305Z","iopub.execute_input":"2023-08-03T19:11:03.161169Z","iopub.status.idle":"2023-08-03T19:11:06.667153Z","shell.execute_reply.started":"2023-08-03T19:11:03.161130Z","shell.execute_reply":"2023-08-03T19:11:06.665139Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Initialize for CPU & GPU","metadata":{}},{"cell_type":"code","source":"if use_gpu:\n    !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric --no-index --find-links=file:///kaggle/input/torch-geometric\n#     !pip install torch_geometric_temporal  \nelse:\n#     !pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n    !pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n    !pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n    !pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n    !pip install git+https://github.com/pyg-team/pytorch_geometric.git\n#     !pip install torch_geometric_temporal\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-03T19:11:06.669477Z","iopub.execute_input":"2023-08-03T19:11:06.670148Z","iopub.status.idle":"2023-08-03T19:12:11.791769Z","shell.execute_reply.started":"2023-08-03T19:11:06.670107Z","shell.execute_reply":"2023-08-03T19:12:11.790539Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\nCollecting torch-scatter\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.1%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (504 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.1/504.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torch-scatter\nSuccessfully installed torch-scatter-2.1.1+pt20cpu\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\nCollecting torch-sparse\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.17%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-sparse) (1.10.1)\nRequirement already satisfied: numpy<1.27.0,>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scipy->torch-sparse) (1.23.5)\nInstalling collected packages: torch-sparse\nSuccessfully installed torch-sparse-0.6.17+pt20cpu\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\nCollecting torch-cluster\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.1%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (732 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m732.3/732.3 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-cluster) (1.10.1)\nRequirement already satisfied: numpy<1.27.0,>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scipy->torch-cluster) (1.23.5)\nInstalling collected packages: torch-cluster\nSuccessfully installed torch-cluster-1.6.1+pt20cpu\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting git+https://github.com/pyg-team/pytorch_geometric.git\n  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-enpw2_eu\n  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-enpw2_eu\n  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 9f9a38bf02e392d3bda116b4b258204fde63098e\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (4.64.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (1.23.5)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (1.10.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (2.28.2)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (3.0.9)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (1.2.2)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (5.9.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch_geometric==2.4.0) (2.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric==2.4.0) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric==2.4.0) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric==2.4.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric==2.4.0) (2023.5.7)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch_geometric==2.4.0) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch_geometric==2.4.0) (3.1.0)\nBuilding wheels for collected packages: torch_geometric\n  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for torch_geometric: filename=torch_geometric-2.4.0-py3-none-any.whl size=978610 sha256=88685861c353b51dc3150a90b88f103690d6dbab837d0c74835bd9b632af2577\n  Stored in directory: /tmp/pip-ephem-wheel-cache-v5kwmawd/wheels/d3/78/eb/9e26525b948d19533f1688fb6c209cec8a0ba793d39b49ae8f\nSuccessfully built torch_geometric\nInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.4.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport re\nimport json\nfrom scipy.special import perm\nfrom itertools import combinations,chain\nfrom typing import List, Union\nfrom torch_geometric.data import Data\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport matplotlib.pyplot as plt\nimport pickle\nimport time\nfrom torch import nn\nfrom torch.nn import Linear as Lin\nfrom torch.nn import ReLU, LeakyReLU\nfrom torch.nn import Sequential as Seq\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, GINConv\nfrom torch_geometric.data import Batch\nfrom torch import autograd\nfrom torch_geometric.nn.models import InnerProductDecoder\nfrom torch_geometric.utils import to_dense_adj\n\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-08-03T19:50:32.951476Z","iopub.execute_input":"2023-08-03T19:50:32.951885Z","iopub.status.idle":"2023-08-03T19:50:32.961134Z","shell.execute_reply.started":"2023-08-03T19:50:32.951859Z","shell.execute_reply":"2023-08-03T19:50:32.959775Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# DataLoader","metadata":{}},{"cell_type":"code","source":"Edge_Flag = List[Union[np.ndarray, None]]\nEdge_Index = List[Union[np.ndarray, None]]\nEdge_Attr = List[Union[np.ndarray, None]]\n\nNode_Flag = List[Union[np.ndarray, None]]\nNode_Index = List[Union[np.ndarray, None]]\nNode_Attr = List[Union[np.ndarray, None]]\nAdditional_Attr = List[np.ndarray]\n\n\n\nclass GraphSignal(object):\n    # dynamic node static node attr dynamic edge and edge attr\n    def __init__(\n        self,\n        edge_flag: Edge_Flag,\n        edge_index: Edge_Index,\n        edge_attr: Edge_Attr,\n        node_flag: Node_Flag,\n        node_index: Node_Index,\n        node_attr: Node_Attr,\n        ts_list: List,\n        path: str,\n    ):\n        \n        self.raw_edge_flag = torch.LongTensor(edge_flag[:-1])\n        self.raw_edge_index = torch.LongTensor(edge_index).T\n        self.raw_edge_attr = edge_attr\n        self.raw_node_attr = node_attr \n        self.node_flag = torch.LongTensor(node_flag[:-1])\n        self.node_index = torch.LongTensor(node_index)\n        \n        self.ts_list = ts_list\n        \n        self.path = path\n        \n        self.node_attr = None\n        self.edge_flag = None\n        self.edge_index = None\n        \n        self._set_snapshot_count()\n        self._set_node_count()\n\n    def _set_snapshot_count(self):\n        self.snapshot_count = len(self.ts_list)\n    \n    def _set_node_count(self):\n        self.node_count = self.raw_node_attr.shape[0]\n    \n    def encode_edge_attr(self, enocder):\n        self.edge_attr_encoded = torch.FloatTensor(enocder.transform(self.raw_edge_attr))\n        \n    def encode_node_attr(self, enocder):\n        self.node_attr_encoded = torch.FloatTensor(enocder.transform(self.raw_node_attr))\n        \n    def extend_node_attr(self):\n        if self.edge_attr_encoded is None:\n            print(\"Edge Attr Need to be Encoded!\")\n            raise\n        node_index = self.node_index\n        node_attr = self.node_attr_encoded.index_select(dim=0,index=self.node_index)\n        node_flag = self.node_flag\n        \n        edge_index = self.raw_edge_index\n        edge_attr = self.edge_attr_encoded\n        edge_flag = self.raw_edge_flag\n        \n        node_index_split = torch.tensor_split(node_index, node_flag)\n        node_attr_split = torch.tensor_split(node_attr, node_flag)\n        edge_index_split = torch.tensor_split(edge_index, edge_flag, dim=1)\n        edge_attr_split = torch.tensor_split(edge_attr, edge_flag)\n\n        base = 0\n        new_node_attr = []\n        new_edge_flag = []\n        new_edge_index = []\n        \n        for i_snapshot in range(self.snapshot_count):\n            _node_index = node_index_split[i_snapshot]\n            _node_attr = node_attr_split[i_snapshot]\n            _edge_index = edge_index_split[i_snapshot]\n            _edge_attr = edge_attr_split[i_snapshot]\n\n            if _edge_index.shape[1] != _edge_attr.shape[0]:\n                print(i_snapshot, edge_index.shape, _edge_attr.shape)\n                raise\n            if _edge_index.shape[1] > 0:\n                index_dict = {}\n                for i_edge in range(_edge_index.shape[1]):\n                    index_tuple = tuple(_edge_index[:,i_edge].tolist())\n                    if index_tuple in index_dict:\n                        index_dict[index_tuple] += [i_edge]\n                    else:\n                        index_dict[index_tuple] = [i_edge]\n\n                _new_edge_index = []\n                _new_edge_attr = []\n                for key in index_dict.keys():\n                    _new_edge_index.append(key)\n                    _new_edge_attr.append(torch.sum(_edge_attr.index_select(0, torch.LongTensor(index_dict[key])),dim=0).unsqueeze(0))\n\n                _new_edge_index = torch.LongTensor(_new_edge_index).T\n                _new_edge_attr = torch.cat(_new_edge_attr,dim=0)\n                \n                base += _new_edge_index.shape[1]\n                new_edge_index.append(_new_edge_index)\n\n#                 _source_attr = torch.zeros((_node_attr.shape[0], _new_edge_attr.shape[1])).to(device)\n#                 _target_attr = torch.zeros((_node_attr.shape[0], _new_edge_attr.shape[1])).to(device)\n#                 _source_attr.index_add_(0, _new_edge_index[0], _new_edge_attr)\n#                 _target_attr.index_add_(0, _new_edge_index[1], _new_edge_attr)\n#                 new_node_attr.append(torch.cat([_node_attr,_source_attr,_target_attr], dim=1))\n\n                _node_attr_extend = torch.zeros((_node_attr.shape[0], _new_edge_attr.shape[1]))\n                _node_attr_extend.index_add_(0, _new_edge_index[0], _new_edge_attr)\n                _node_attr_extend.index_add_(0, _new_edge_index[1], _new_edge_attr)\n                new_node_attr.append(torch.cat([_node_attr,_node_attr_extend], dim=1)) \n                \n            new_edge_flag.append(base)\n        \n        self.node_attr = torch.cat(new_node_attr, dim=0).to(device)\n        self.edge_flag = torch.LongTensor(new_edge_flag)\n        self.edge_index = torch.cat(new_edge_index,dim=1).to(device)\n    \n    def remove_init_stop(self, threshold, period):\n        node_index = self.node_index\n        node_attr = self.node_attr\n        node_flag = self.node_flag\n\n        edge_index = self.edge_index\n        edge_flag = self.edge_flag\n        \n        raw_edge_index = self.raw_edge_index\n        raw_edge_attr = self.raw_edge_attr\n        raw_edge_flag = self.raw_edge_flag\n\n        node_index_split = torch.tensor_split(node_index, node_flag)\n        node_attr_split = torch.tensor_split(node_attr, node_flag)\n        edge_index_split = torch.tensor_split(edge_index, edge_flag, dim=1)\n        \n        raw_edge_index_split = torch.tensor_split(raw_edge_index, raw_edge_flag, dim=1)\n        raw_edge_attr_split = np.split(raw_edge_attr, raw_edge_flag)\n\n        i_init = None\n        i_stop = None\n        for i_snapshot, node_num in enumerate(torch.diff(self.node_flag)):\n            if node_num > threshold:\n                i_init = i_snapshot+1\n                break\n\n        for i_snapshot, node_num in enumerate(torch.flip(torch.diff(self.node_flag),dims=[0])):\n            if node_num > threshold:\n                i_stop = self.node_flag.shape[0]-1-i_snapshot\n                break\n        \n        new_node_attr = torch.cat(node_attr_split[i_init+1+period:i_stop-period],dim=0)\n        new_node_index = torch.cat(node_index_split[i_init+1+period:i_stop-period],dim=0)\n        new_edge_index = torch.cat(edge_index_split[i_init+1+period:i_stop-period],dim=1)\n        new_raw_edge_index = torch.cat(raw_edge_index_split[i_init+1+period:i_stop-period], dim=1)\n        new_raw_edge_attr = np.concatenate(raw_edge_attr_split[i_init+1+period:i_stop-period])\n\n        new_node_flag = node_flag[i_init+period+1:i_stop-period-1]-node_flag[i_init+period]\n        new_edge_flag = edge_flag[i_init+period+1:i_stop-period-1]-edge_flag[i_init+period]\n        new_raw_edge_flag = raw_edge_flag[i_init+period+1:i_stop-period-1]-raw_edge_flag[i_init+period]\n        \n        self.node_attr = F.tanh(new_node_attr)\n        self.node_index = new_node_index\n        self.edge_index = new_edge_index\n        self.raw_edge_attr = new_raw_edge_attr\n        self.raw_edge_index = new_raw_edge_index\n        \n        self.node_flag = new_node_flag\n        self.edge_flag = new_edge_flag\n        self.raw_edge_flag = new_raw_edge_flag\n        \n        self.ts_list = self.ts_list[i_init+1+period:i_stop-period]\n        \n        self._set_snapshot_count()\n    \n    def to(self,device):\n        self.node_attr = self.node_attr.to(device)\n        self.node_index = self.node_index.to(device)\n        self.edge_index = self.edge_index.to(device)\n    \n    def get_adj_list(self):\n        edge_index = self.edge_index\n        edge_flag = self.edge_flag\n        edge_index_split = torch.tensor_split(edge_index, edge_flag, dim=1)\n        adj_list = [torch.clamp(to_dense_adj(_edge_index)[0], min=0, max=1) for _edge_index in edge_index_split]\n        return adj_list\n\n    def _get_edge_index(self, time_index: int):\n        if time_index == 0:\n            _start = 0\n        else:\n            _start = self.edge_flag[time_index-1]\n        _end = self.edge_flag[time_index]\n        _edge_index = self.edge_index[:,_start:_end]\n        return _edge_index\n\n    def _get_edge_attr(self, time_index: int):\n        if self.edge_attr_encoded is None:\n            print(\"Edge Attr Need to be Encoded!\")\n            raise\n        if time_index == 0:\n            _start = 0\n        else:\n            _start = self.edge_flag[time_index-1]\n        _end = self.edge_flag[time_index]\n        _edge_attr = self.edge_attr_encoded[_start:_end]\n        return _edge_attr\n    \n    def _get_node_index_attr(self, time_index: int):\n        if self.node_attr_encoded is None:\n            print(\"Node Attr Need to be Encoded!\")\n            raise\n        if time_index == 0:\n            _start = 0\n        else:\n            _start = self.node_flag[time_index-1]\n        _end = self.node_flag[time_index]\n        _node_index = self.node_index[_start:_end]\n        _node_attr = self.node_attr_encoded[_node_index]\n        return _node_index,_node_attr\n    \n    def _get_timestamp(self, time_index: int):\n        _timestamp = self.ts_list[time_index]\n        return _timestamp\n\n\n    def __getitem__(self, time_index: int):\n        edge_index = self._get_edge_index(time_index)\n        edge_attr = self._get_edge_attr(time_index)\n        node_index,node_attr = self._get_node_index_attr(time_index)\n        _timestamp = self._get_timestamp(time_index)\n\n        snapshot = Data(\n            edge_index=edge_index,\n            edge_attr=edge_attr,\n            node_index=node_index,\n            node_attr=node_attr,\n            timestamp=_timestamp\n        )\n        return snapshot\n\n    def __next__(self):\n        if self.t < self.snapshot_count:\n            snapshot = self[self.t]\n            self.t = self.t + 1\n            return snapshot\n        else:\n            self.t = 0\n            raise StopIteration\n\n    def __iter__(self):\n        self.t = 0\n        return self\n    \n    def __len__(self):\n        return self.snapshot_count\n\n\nclass GraphDatasetLoader(object):\n    def __init__(self,input_path=\"\"):\n        self.input_path = input_path\n        self._read_data()\n    \n    def _read_data(self):\n        self._dataset = np.load(self.input_path)\n\n    def get_dataset(self): # -> DynamicGraphTemporalSignal:\n        dataset = GraphSignal(\n            edge_flag = self._dataset['edge_flag'],\n            edge_index = self._dataset['edge_index'],\n            edge_attr = self._dataset['edge_attr'],\n            node_flag = self._dataset['node_flag'],\n            node_index = self._dataset['node_index'],\n            node_attr = self._dataset['node_attr'],\n            ts_list = self._dataset['timestamp'],\n            path = self.input_path\n        )\n        return dataset","metadata":{"execution":{"iopub.status.busy":"2023-08-03T19:12:13.021786Z","iopub.execute_input":"2023-08-03T19:12:13.022571Z","iopub.status.idle":"2023-08-03T19:12:13.068238Z","shell.execute_reply.started":"2023-08-03T19:12:13.022543Z","shell.execute_reply":"2023-08-03T19:12:13.067300Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data_dir_0 = '/kaggle/input/dissertation-data'\ndata_dir_1 = '2021-09-11-umbrella-experiment-32run-fran'\n\n\nsignals = []\nannotation = []\nwith open(os.path.join(data_dir_0, data_dir_1, \"annotated.json\")) as f:\n    annotated_dict = json.load(f)\n\nfor data_dir_2 in os.listdir(os.path.join(data_dir_0, data_dir_1)):\n    if data_dir_2 == \"annotated.json\":\n        continue\n    r = re.compile(\".*.npz\")\n    graph_files = list(filter(r.match, os.listdir(os.path.join(data_dir_0, data_dir_1, data_dir_2))))\n\n    if len(graph_files) > 1:\n        print(\"Multiple Graph Files!\")\n        raise\n    if len(graph_files) == 0:\n        print(\"Not Found Graph File!\")\n        continue\n\n    dataloader = GraphDatasetLoader(os.path.join(data_dir_0, data_dir_1, data_dir_2, graph_files[0]))\n    signal = dataloader.get_dataset()\n    signals.append(signal)\n    annotation.append(annotated_dict[data_dir_2])\n\n# split train and test dataset\nsignals_train, signals_test, annotation_train, annotation_test = train_test_split(signals, annotation, test_size=0.2, random_state=1)\nsignals_train, signals_val, annotation_train, annotation_val = train_test_split(signals_train, annotation_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2","metadata":{"execution":{"iopub.status.busy":"2023-08-03T19:12:13.069647Z","iopub.execute_input":"2023-08-03T19:12:13.070049Z","iopub.status.idle":"2023-08-03T19:12:14.228589Z","shell.execute_reply.started":"2023-08-03T19:12:13.070011Z","shell.execute_reply":"2023-08-03T19:12:14.227702Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"_interval = 60\n_overlap = 30\n\nnode_num_list = []\nfor signal in signals_train:\n    node_num_list += torch.diff(signal.node_flag).tolist()\n    \nthreshold = np.median(node_num_list)\nperiod = 3\n\nprint(f\"Threshold = {threshold} Period = {period}\")\n\nnode_attr_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\nnode_attr_encoder = node_attr_encoder.fit(np.concatenate([sample.raw_node_attr for sample in signals_train]))\n\nedge_attr_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\nedge_attr_encoder = edge_attr_encoder.fit(np.concatenate([sample.raw_edge_attr for sample in signals_train]))\n\nfor i_signal, signal in enumerate(signals_train):\n    signal.encode_node_attr(node_attr_encoder)\n    signal.encode_edge_attr(edge_attr_encoder)\n    signal.extend_node_attr()\n    node_attr_split = signal.node_attr.tensor_split(signal.node_flag)\n    print(\"Original: \", [len(_node_attr) for _node_attr in node_attr_split])\n    signal.remove_init_stop(threshold, period)\n    node_attr_split = signal.node_attr.tensor_split(signal.node_flag)\n    print(\"Removed: \", [len(_node_attr) for _node_attr in node_attr_split])\n    \ny_train = []\nfor self, annotation in zip(signals_train, annotation_train): \n    ts_list = self.ts_list\n    y = torch.zeros(self.snapshot_count, dtype=torch.long)\n    for i_ts, ts in enumerate(ts_list):\n        if ts < float(annotation[1]) and float(annotation[1]) <= ts+_interval: \n            y[i_ts] = 1\n    y_train.append(y)\n\n\n    \nfor i_signal, signal in enumerate(signals_val):\n    signal.encode_node_attr(node_attr_encoder)\n    signal.encode_edge_attr(edge_attr_encoder)\n    signal.extend_node_attr()\n    signal.remove_init_stop(threshold, period)\n\ny_val = []\nfor signal, annotation in zip(signals_val, annotation_val): \n    ts_list = signal.ts_list\n    y = torch.zeros(signal.snapshot_count, dtype=torch.long)\n    for i_ts, ts in enumerate(ts_list):\n        if ts < float(annotation[1]) and float(annotation[1]) <= ts+_interval: \n            y[i_ts] = 1\n    y_val.append(y)\n\nfor signal in signals_train:\n    signal.to(device)\n\nfor signal in signals_val:\n    signal.to(device)\n    \n    \nIN_CHANNELS = signals_train[0].node_attr.shape[1]\n# EDGE_CHANNELS = signals_train[0].edge_attr_encoded.shape[1]","metadata":{"execution":{"iopub.status.busy":"2023-08-03T19:12:14.230194Z","iopub.execute_input":"2023-08-03T19:12:14.230708Z","iopub.status.idle":"2023-08-03T19:12:42.260017Z","shell.execute_reply.started":"2023-08-03T19:12:14.230670Z","shell.execute_reply":"2023-08-03T19:12:42.259123Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Threshold = 77.0 Period = 3\nOriginal:  [4, 4, 160, 82, 126, 84, 80, 77, 77, 70, 73, 63, 95, 70, 73, 77, 86, 84, 87, 70, 77, 90, 120, 72, 91, 70, 66, 70, 84, 76, 73, 69, 96, 48]\nRemoved:  [80, 77, 77, 70, 73, 63, 95, 70, 73, 77, 86, 84, 87, 70, 77, 90, 120, 72, 91, 70, 66, 70, 84]\nOriginal:  [4, 190, 69, 88, 69, 101, 76, 81, 69, 92, 131, 85, 69, 88, 62, 85, 69, 88, 68, 85, 82, 114, 83, 85, 62, 88, 75, 85, 68, 74, 76, 139]\nRemoved:  [101, 76, 81, 69, 92, 131, 85, 69, 88, 62, 85, 69, 88, 68, 85, 82, 114, 83, 85]\nOriginal:  [180, 71, 80, 130, 80, 84, 77, 77, 87, 65, 88, 69, 80, 70, 86, 70, 80, 70, 84, 70, 113, 77, 70, 90, 80, 63, 91, 99, 80, 69, 125]\nRemoved:  [77, 77, 87, 65, 88, 69, 80, 70, 86, 70, 80, 70, 84, 70, 113, 77, 70, 90, 80]\nOriginal:  [235, 88, 80, 101, 62, 74, 80, 97, 83, 99, 87, 81, 83, 74, 80, 66, 69, 80, 122, 121, 69, 67, 80, 74, 69, 81, 73, 74, 68, 119]\nRemoved:  [74, 80, 97, 83, 99, 87, 81, 83, 74, 80, 66, 69, 80, 122, 121, 69, 67]\nOriginal:  [222, 208, 83, 86, 90, 85, 76, 81, 76, 81, 91, 67, 83, 94, 80, 80, 69, 80, 192, 81, 116, 74, 75, 74, 76, 81, 66, 74, 69, 74, 107]\nRemoved:  [85, 76, 81, 76, 81, 91, 67, 83, 94, 80, 80, 69, 80, 192, 81, 116, 74]\nOriginal:  [324, 81, 80, 76, 69, 88, 73, 81, 69, 85, 80, 81, 83, 88, 79, 74, 76, 67, 73, 123, 76, 74, 73, 88, 76, 81, 73, 188, 76, 118]\nRemoved:  [88, 73, 81, 69, 85, 80, 81, 83, 88, 79, 74, 76, 67, 73, 123, 76, 74, 73, 88]\nOriginal:  [4, 4, 4, 180, 77, 74, 76, 85, 76, 74, 82, 78, 68, 85, 68, 92, 76, 74, 169, 125, 88, 76, 94, 134, 96, 74, 90, 79, 76, 67, 75, 78, 61, 133]\nRemoved:  [85, 76, 74, 82, 78, 68, 85, 68, 92, 76, 74, 169, 125, 88, 76, 94, 134, 96, 74, 90, 79]\nOriginal:  [198, 84, 80, 77, 84, 76, 66, 76, 84, 78, 91, 69, 77, 90, 80, 76, 77, 69, 87, 77, 234, 70, 80, 70, 77, 70, 82, 70, 84, 77, 125]\nRemoved:  [76, 66, 76, 84, 78, 91, 69, 77, 90, 80, 76, 77, 69, 87, 77, 234, 70, 80, 70, 77]\nOriginal:  [4, 4, 181, 71, 87, 74, 73, 70, 86, 185, 73, 77, 80, 85, 80, 84, 73, 80, 73, 72, 87, 74, 109, 85, 87, 67, 80, 70, 79, 74, 79, 70, 80, 99]\nRemoved:  [73, 70, 86, 185, 73, 77, 80, 85, 80, 84, 73, 80, 73, 72, 87, 74, 109, 85, 87, 67, 80, 70, 79]\nOriginal:  [208, 81, 76, 74, 80, 74, 69, 88, 80, 94, 87, 74, 73, 81, 69, 74, 80, 81, 69, 88, 120, 74, 83, 74, 73, 67, 68, 197, 69, 74, 107]\nRemoved:  [74, 69, 88, 80, 94, 87, 74, 73, 81, 69, 74, 80, 81, 69, 88, 120, 74, 83, 74]\nOriginal:  [160, 102, 73, 70, 84, 70, 73, 83, 84, 76, 80, 95, 77, 69, 80, 69, 76, 77, 79, 77, 102, 105, 80, 90, 77, 70, 79, 77, 129, 70, 80, 69]\nRemoved:  [70, 73, 83, 84, 76, 80, 95, 77, 69, 80, 69, 76, 77, 79, 77, 102, 105, 80, 90, 77, 70, 79]\nOriginal:  [211, 81, 80, 77, 84, 76, 73, 62, 77, 76, 84, 70, 79, 90, 73, 77, 84, 77, 87, 62, 124, 70, 73, 70, 77, 76, 80, 69, 126, 163, 117]\nRemoved:  [76, 73, 62, 77, 76, 84, 70, 79, 90, 73, 77, 84, 77, 87, 62, 124, 70, 73, 70, 77, 76]\nOriginal:  [247, 88, 71, 130, 76, 74, 80, 102, 69, 85, 79, 74, 75, 81, 72, 81, 75, 74, 72, 114, 69, 81, 80, 74, 76, 81, 80, 81, 69, 129, 22]\nRemoved:  [74, 80, 102, 69, 85, 79, 74, 75, 81, 72, 81, 75, 74, 72, 114, 69, 81, 80, 74, 76, 81]\nOriginal:  [4, 205, 69, 90, 69, 78, 75, 87, 199, 75, 76, 81, 76, 73, 83, 77, 69, 81, 69, 85, 69, 134, 84, 85, 90, 76, 90, 85, 76, 81, 76, 118]\nRemoved:  [78, 75, 87, 199, 75, 76, 81, 76, 73, 83, 77, 69, 81, 69, 85, 69, 134, 84, 85, 90, 76]\nOriginal:  [4, 4, 4, 215, 69, 81, 76, 130, 76, 73, 76, 77, 69, 91, 76, 77, 76, 73, 76, 89, 74, 80, 82, 132, 69, 74, 99, 85, 69, 74, 75, 78, 89, 125]\nRemoved:  [130, 76, 73, 76, 77, 69, 91, 76, 77, 76, 73, 76, 89, 74, 80, 82, 132, 69, 74, 99, 85, 69]\nOriginal:  [4, 4, 4, 229, 76, 88, 83, 94, 68, 201, 68, 81, 69, 82, 71, 81, 69, 78, 76, 74, 76, 78, 77, 134, 69, 92, 69, 97, 83, 78, 75, 73, 76, 125]\nRemoved:  [94, 68, 201, 68, 81, 69, 82, 71, 81, 69, 78, 76, 74, 76, 78, 77, 134, 69, 92]\nOriginal:  [201, 82, 91, 63, 77, 70, 68, 70, 77, 77, 98, 84, 77, 76, 73, 70, 84, 213, 74, 77, 124, 84, 73, 84, 77, 70, 79, 63, 83, 70, 112]\nRemoved:  [70, 68, 70, 77, 77, 98, 84, 77, 76, 73, 70, 84, 213, 74, 77, 124, 84, 73, 84, 77]\nOriginal:  [203, 74, 69, 76, 80, 74, 76, 87, 73, 81, 80, 81, 80, 74, 76, 74, 73, 67, 69, 103, 151, 81, 69, 81, 87, 73, 69, 80, 73, 73, 104]\nRemoved:  [73, 81, 80, 81, 80, 74, 76, 74, 73, 67, 69, 103, 151, 81, 69, 81]\nOriginal:  [260, 74, 73, 101, 76, 81, 73, 81, 69, 99, 132, 76, 76, 74, 87, 74, 75, 80, 73, 121, 69, 74, 80, 81, 62, 81, 80, 73, 69, 118]\nRemoved:  [81, 69, 99, 132, 76, 76, 74, 87, 74, 75, 80, 73, 121, 69, 74, 80]\nOriginal:  [4, 506, 76, 74, 69, 85, 69, 74, 76, 92, 76, 78, 83, 85, 76, 74, 129, 88, 76, 74, 80, 121, 69, 81, 76, 85, 69, 87, 76, 92, 62, 125]\nRemoved:  [85, 69, 74, 76, 92, 76, 78, 83, 85, 76, 74, 129, 88, 76, 74, 80, 121, 69, 81, 76, 85]\nOriginal:  [4, 204, 69, 88, 82, 81, 82, 69, 79, 90, 82, 85, 73, 81, 76, 81, 80, 74, 76, 74, 80, 116, 76, 81, 80, 88, 69, 74, 192, 94, 64, 125]\nRemoved:  [81, 82, 69, 79, 90, 82, 85, 73, 81, 76, 81, 80, 74, 76, 74, 80, 116, 76, 81, 80, 88]\nOriginal:  [4, 4, 4, 188, 76, 88, 69, 85, 90, 67, 83, 71, 69, 99, 69, 92, 78, 89, 90, 78, 82, 74, 76, 125, 62, 81, 76, 85, 180, 67, 76, 78, 69, 132]\nRemoved:  [85, 90, 67, 83, 71, 69, 99, 69, 92, 78, 89, 90, 78, 82, 74, 76, 125, 62, 81, 76, 85]\nOriginal:  [4, 4, 208, 76, 87, 74, 80, 79, 93, 80, 80, 69, 121, 80, 198, 73, 80, 73, 73, 76, 87, 73, 113, 63, 66, 88, 80, 70, 80, 88, 87, 77, 125]\nRemoved:  [80, 79, 93, 80, 80, 69, 121, 80, 198, 73, 80, 73, 73, 76, 87, 73, 113, 63, 66, 88, 80]\nOriginal:  [228, 74, 87, 74, 76, 74, 73, 81, 71, 99, 73, 81, 69, 74, 82, 74, 69, 134, 71, 121, 66, 81, 83, 81, 73, 93, 76, 74, 73, 116]\nRemoved:  [73, 81, 71, 99, 73, 81, 69, 74, 82, 74, 69, 134, 71, 121, 66, 81]\nOriginal:  [193, 77, 73, 77, 84, 70, 79, 77, 84, 70, 91, 70, 77, 70, 73, 77, 84, 77, 74, 104, 117, 131, 66, 77, 77, 70, 79, 70, 84, 70, 117]\nRemoved:  [84, 70, 91, 70, 77, 70, 73, 77, 84, 77, 74, 104, 117, 131, 66, 77, 77]\nOriginal:  [233, 81, 71, 81, 73, 94, 71, 80, 87, 75, 101, 73, 73, 78, 74, 93, 73, 73, 76, 73, 120, 74, 83, 130, 69, 73, 76, 84, 69, 94, 107]\nRemoved:  [94, 71, 80, 87, 75, 101, 73, 73, 78, 74, 93, 73, 73, 76, 73, 120, 74, 83, 130, 69, 73]\nOriginal:  [4, 9, 215, 81, 71, 78, 76, 74, 76, 78, 69, 183, 94, 88, 69, 78, 69, 74, 83, 85, 72, 74, 116, 78, 90, 81, 89, 85, 69, 74, 91, 78, 94]\nRemoved:  [76, 74, 76, 78, 69, 183, 94, 88, 69, 78, 69, 74, 83, 85, 72, 74, 116, 78, 90, 81, 89, 85]\nOriginal:  [226, 77, 73, 77, 84, 72, 73, 77, 77, 84, 86, 69, 84, 84, 73, 89, 87, 83, 80, 76, 117, 127, 80, 77, 91, 77, 80, 70, 84, 77, 118]\nRemoved:  [77, 84, 86, 69, 84, 84, 73, 89, 87, 83, 80, 76, 117, 127, 80, 77, 91]\nOriginal:  [208, 221, 132, 81, 69, 74, 73, 74, 76, 81, 91, 87, 76, 81, 73, 74, 69, 74, 80, 74, 116, 74, 80, 74, 76, 81, 80, 74, 82, 81, 99]\nRemoved:  [74, 73, 74, 76, 81, 91, 87, 76, 81, 73, 74, 69, 74, 80, 74, 116, 74, 80, 74, 76, 81]\nOriginal:  [4, 13, 293, 81, 76, 74, 73, 73, 83, 74, 80, 81, 87, 94, 73, 81, 69, 83, 73, 81, 77, 210, 120, 82, 70, 82, 74, 108, 133, 75, 98, 108, 98]\nRemoved:  [73, 73, 83, 74, 80, 81, 87, 94, 73, 81, 69, 83, 73, 81, 77, 210, 120, 82, 70, 82, 74, 108]\nOriginal:  [4, 8, 214, 87, 76, 78, 188, 74, 75, 81, 75, 85, 91, 85, 68, 78, 69, 81, 69, 85, 69, 74, 116, 78, 69, 74, 76, 85, 61, 88, 82, 71, 97]\nRemoved:  [188, 74, 75, 81, 75, 85, 91, 85, 68, 78, 69, 81, 69, 85, 69, 74, 116, 78, 69, 74, 76]\nOriginal:  [4, 7, 184, 80, 86, 77, 71, 79, 71, 91, 71, 72, 89, 76, 71, 86, 86, 76, 71, 78, 78, 82, 111, 79, 177, 79, 85, 72, 75, 71, 92, 78, 110]\nRemoved:  [71, 79, 71, 91, 71, 72, 89, 76, 71, 86, 86, 76, 71, 78, 78, 82, 111, 79, 177, 79, 85, 72]\nOriginal:  [4, 186, 76, 74, 183, 71, 76, 73, 87, 73, 76, 85, 69, 70, 76, 88, 83, 85, 76, 74, 69, 118, 76, 95, 69, 91, 69, 81, 83, 85, 69, 133]\nRemoved:  [71, 76, 73, 87, 73, 76, 85, 69, 70, 76, 88, 83, 85, 76, 74, 69, 118, 76, 95, 69, 91]\nOriginal:  [233, 81, 122, 81, 68, 74, 72, 74, 75, 99, 72, 81, 69, 74, 82, 87, 75, 74, 75, 113, 76, 94, 62, 92, 85, 74, 68, 85, 68, 119]\nRemoved:  [74, 72, 74, 75, 99, 72, 81, 69, 74, 82, 87, 75, 74, 75, 113, 76, 94, 62, 92]\nOriginal:  [201, 81, 73, 81, 78, 94, 87, 80, 85, 91, 94, 73, 69, 74, 80, 80, 76, 80, 87, 107, 76, 74, 80, 74, 83, 180, 78, 81, 80, 93, 53]\nRemoved:  [94, 87, 80, 85, 91, 94, 73, 69, 74, 80, 80, 76, 80, 87, 107, 76, 74, 80, 74, 83, 180]\nOriginal:  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 13, 201, 78, 77, 203, 70, 80, 70, 80, 74, 87, 88, 73, 87, 80, 84, 75, 74, 85, 83, 73, 109, 93, 84, 71, 74, 91, 107, 79, 103, 976, 77, 87, 69, 313, 929, 6, 72, 26, 4, 4, 4, 4, 4, 697, 140, 84, 85, 78, 81, 182, 81, 68, 81, 83, 74, 77, 76, 75, 85, 82, 81, 68, 78, 102, 81, 69, 85, 83, 109, 68, 74, 82, 80, 104, 4]\nRemoved:  [70, 80, 70, 80, 74, 87, 88, 73, 87, 80, 84, 75, 74, 85, 83, 73, 109, 93, 84, 71, 74, 91, 107, 79, 103, 976, 77, 87, 69, 313, 929, 6, 72, 26, 4, 4, 4, 4, 4, 697, 140, 84, 85, 78, 81, 182, 81, 68, 81, 83, 74, 77, 76, 75, 85, 82, 81, 68, 78, 102, 81, 69, 85, 83, 109, 68]\nOriginal:  [246, 81, 80, 74, 68, 74, 86, 74, 75, 87, 73, 81, 69, 74, 80, 81, 76, 81, 73, 114, 76, 74, 73, 88, 75, 127, 68, 81, 79, 129]\nRemoved:  [74, 86, 74, 75, 87, 73, 81, 69, 74, 80, 81, 76, 81, 73, 114, 76, 74, 73, 88, 75]\nOriginal:  [4, 4, 197, 84, 69, 81, 101, 84, 73, 81, 73, 84, 91, 81, 87, 116, 80, 93, 73, 74, 73, 77, 120, 69, 73, 70, 80, 74, 87, 77, 80, 74, 116]\nRemoved:  [101, 84, 73, 81, 73, 84, 91, 81, 87, 116, 80, 93, 73, 74, 73, 77, 120, 69, 73, 70, 80]\n","output_type":"stream"}]},{"cell_type":"code","source":"signal = signals_train[0]\n\nnode_index = signal.node_index\nnode_attr = signal.node_attr\nnode_flag = signal.node_flag\n\nedge_index = signal.edge_index\nedge_flag = signal.edge_flag\n\nnode_index_split = torch.tensor_split(node_index, node_flag)\nnode_attr_split = torch.tensor_split(node_attr, node_flag)\nedge_index_split = torch.tensor_split(edge_index, edge_flag, dim=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T19:14:36.573266Z","iopub.execute_input":"2023-08-03T19:14:36.573685Z","iopub.status.idle":"2023-08-03T19:14:36.581077Z","shell.execute_reply.started":"2023-08-03T19:14:36.573657Z","shell.execute_reply":"2023-08-03T19:14:36.579996Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class MultiGraphConv(torch.nn.Module):\n    def __init__(\n        self, \n        channels, \n    ):\n        super().__init__()\n         \n        self.convs = nn.ModuleList()\n        \n        net1 = Seq(\n            Lin(channels, channels),\n            LeakyReLU(),\n            Lin(channels, channels*2),\n            LeakyReLU(),\n            Lin(channels*2, channels*2),\n            LeakyReLU(),\n        )\n        conv1 = GINConv(net1,train_eps=True)\n        self.convs.append(conv1)\n        \n        net2 = Seq(\n            Lin(channels*2, channels*2),\n            LeakyReLU(),\n            Lin(channels*2, channels),\n            LeakyReLU(),\n            Lin(channels, channels),\n            LeakyReLU(),\n        )\n        conv2 = GINConv(net2,train_eps=True)\n        self.convs.append(conv2)\n        \n\n    def forward(self, x, edge_index):\n        out = x\n        for conv in self.convs:\n            out = conv(x=out, edge_index=edge_index)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-08-03T19:14:37.365623Z","iopub.execute_input":"2023-08-03T19:14:37.366552Z","iopub.status.idle":"2023-08-03T19:14:37.375003Z","shell.execute_reply.started":"2023-08-03T19:14:37.366517Z","shell.execute_reply":"2023-08-03T19:14:37.374081Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class GraphGRU(torch.nn.Module):\n    def __init__(\n        self,\n        channels: int,\n        bias: bool = True,\n    ):\n        super().__init__()\n\n        self.channels = channels\n        self.bias = bias\n        self._create_parameters_and_layers()\n\n    def _create_update_gate_parameters_and_layers(self):\n\n        self.conv_x_z = MultiGraphConv(channels = self.channels)\n\n        self.conv_h_z = MultiGraphConv(channels = self.channels)\n        \n    def _create_reset_gate_parameters_and_layers(self):\n\n        self.conv_x_r = MultiGraphConv(channels = self.channels)\n\n        self.conv_h_r = MultiGraphConv(channels = self.channels)\n\n    def _create_candidate_state_parameters_and_layers(self):\n\n        self.conv_x_h = MultiGraphConv(channels = self.channels)\n\n        self.conv_h_h = MultiGraphConv(channels = self.channels)\n\n    def _create_parameters_and_layers(self):\n        self._create_update_gate_parameters_and_layers()\n        self._create_reset_gate_parameters_and_layers()\n        self._create_candidate_state_parameters_and_layers()\n\n    def _set_hidden_state(self, X, H):\n        if H is None:\n            H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n        return H\n\n    def _calculate_update_gate(self, X, edge_index, H):\n        Z = self.conv_x_z(X, edge_index)\n        Z = Z + self.conv_h_z(H, edge_index)\n        Z = torch.sigmoid(Z)\n        return Z\n\n    def _calculate_reset_gate(self, X, edge_index, H):\n        R = self.conv_x_r(X, edge_index)\n        R = R + self.conv_h_r(H, edge_index)\n        R = torch.sigmoid(R)\n        return R\n\n    def _calculate_candidate_state(self, X, edge_index, H, R):\n        H_tilde = self.conv_x_h(X, edge_index)\n        H_tilde = H_tilde + self.conv_h_h(H * R, edge_index)\n        H_tilde = torch.tanh(H_tilde)\n        return H_tilde\n\n    def _calculate_hidden_state(self, Z, H, H_tilde):\n        H = Z * H + (1 - Z) * H_tilde\n        return H\n\n    def forward(\n            self,\n            X: torch.FloatTensor,\n            edge_index: torch.LongTensor,\n            H: torch.FloatTensor = None,\n        ) -> torch.FloatTensor:\n        H = self._set_hidden_state(X, H)\n        Z = self._calculate_update_gate(X, edge_index, H)\n        R = self._calculate_reset_gate(X, edge_index, H)\n        H_tilde = self._calculate_candidate_state(X, edge_index, H, R)\n        H = self._calculate_hidden_state(Z, H, H_tilde)\n        return H","metadata":{"execution":{"iopub.status.busy":"2023-08-03T19:14:37.770045Z","iopub.execute_input":"2023-08-03T19:14:37.770423Z","iopub.status.idle":"2023-08-03T19:14:37.788260Z","shell.execute_reply.started":"2023-08-03T19:14:37.770395Z","shell.execute_reply":"2023-08-03T19:14:37.787396Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def create_hidden(num_node, out_channels):\n#     hidden_global = torch.FloatTensor(np.zeros([num_node,out_channels])).to(device)\n    hidden =torch.zeros([num_node,out_channels], dtype=torch.float).to(device)\n    return hidden\n\ndef select_hidden(hidden, index):\n#     h = hidden_global[index] #REGULAR INDEXING\n    h = hidden.index_select(dim=0, index=index) #INDEX SELECT\n    return h\n\ndef update_hidden(num_node, out_channels, h, index):\n    # hidden_global[index] = h.detach() #REGULAR INDEXING\n    # for key,value in mapping.items():\n    #     hidden_global[value] = h[key] \n    hidden = torch.zeros([num_node,out_channels], dtype=torch.float).to(device)\n    hidden.index_add_(0, index, h)  \n    return hidden\n\n# def update_hidden(hidden, h, index):\n#     hidden.index_copy_(0, index, h)  \n#     return hidden\n\nclass GraphGRULayer(torch.nn.Module):\n    def __init__(\n        self,\n        channels: int,\n        bias: bool = True,\n    ):\n        super().__init__()\n        self.gru = GraphGRU(\n            channels = channels,\n            bias = bias\n        )\n        \n        self.channels = channels\n        \n    def forward(\n        self,\n        X: torch.FloatTensor,\n        node_index: torch.LongTensor,\n        node_flag: torch.LongTensor,\n        edge_index: torch.LongTensor,\n        edge_flag: torch.LongTensor,\n        num_node: int,\n        direction: bool # True for Forward; False for Backward\n    ) -> torch.FloatTensor:\n        \n        X_split = torch.tensor_split(X, node_flag)\n        node_index_split = torch.tensor_split(node_index, node_flag)\n        edge_index_split = torch.tensor_split(edge_index, edge_flag, dim=1)\n        \n        hidden = create_hidden(num_node, self.channels)\n        \n        outs = []\n        if direction:\n            snapshot_index = range(len(X_split))\n        else:\n            snapshot_index = range(len(X_split)-1,-1,-1)\n        for i_snapshot in snapshot_index:\n            _X = X_split[i_snapshot]\n            _node_index = node_index_split[i_snapshot]\n            _edge_index = edge_index_split[i_snapshot]\n\n            _hidden = select_hidden(hidden, _node_index)\n            _new_hidden = self.gru(_X, _edge_index, _hidden)\n            hidden = update_hidden(num_node, self.channels, _new_hidden, _node_index)\n#             hidden = update_hidden(hidden, _new_hidden, _node_index)\n            outs.append(_new_hidden)\n        if direction:\n            H = torch.cat(outs)\n        else:\n            H = torch.cat(outs[::-1])\n        return H","metadata":{"execution":{"iopub.status.busy":"2023-08-03T19:14:38.193323Z","iopub.execute_input":"2023-08-03T19:14:38.193697Z","iopub.status.idle":"2023-08-03T19:14:38.209104Z","shell.execute_reply.started":"2023-08-03T19:14:38.193660Z","shell.execute_reply":"2023-08-03T19:14:38.208297Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class TGAE(torch.nn.Module): # Not Heterogeneous\n    def __init__(\n        self, \n        in_channels, \n        out_channels, \n        embed_layers,  \n        decide_layers,\n    ):\n        super(TGAE, self).__init__()\n        \n        # Encoder Embeding\n#         layers = [torch.nn.BatchNorm1d(in_channels)]\n        layers = []\n        pre_h_num = in_channels\n        for h_num in embed_layers[:-1]:\n            layers.append(torch.nn.Dropout(p=0.2))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,embed_layers[-1]))\n        self.embed_net = Seq(*layers)\n                \n        self.encoder_gru = GraphGRULayer(channels=embed_layers[-1])\n\n        layers = []\n        pre_h_num = embed_layers[-1]\n        for h_num in decide_layers:\n            layers.append(torch.nn.Dropout(p=0.2))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,out_channels))\n#         layers.append(torch.nn.Sigmoid())\n        self.decide_net = Seq(*layers)\n        \n        # Decoder\n#         self.decoder = InnerProductDecoder()\n        layers = []\n        pre_h_num = out_channels\n        for h_num in decide_layers[::-1]:\n            layers.append(torch.nn.Dropout(p=0.2))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(torch.nn.LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,embed_layers[-1]))\n        self.decode_decide_net = Seq(*layers)\n        \n        self.decoder_gru = GraphGRULayer(channels=embed_layers[-1])\n        \n        layers = []\n        pre_h_num = embed_layers[-1]\n        for h_num in embed_layers[:-1][::-1]:\n            layers.append(torch.nn.Dropout(p=0.2))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(torch.nn.LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,in_channels))\n        self.decode_embed_net = Seq(*layers)\n        \n\n    def forward(self, x, node_index, node_flag, edge_index, edge_flag, num_node):\n        # Encoder\n        out = self.embed_net(x)\n        \n        # GNN layer\n        h_encoder = self.encoder_gru(out, node_index, node_flag, edge_index, edge_flag, num_node, True) \n        \n        out = self.decide_net(h_encoder)\n        out = self.decode_decide_net(out)\n \n        h_decoder = self.decoder_gru(out, node_index, node_flag, torch.flip(edge_index,dims=(0,)), edge_flag, num_node, True)\n        \n        out = self.decode_embed_net(h_decoder)\n\n        return out\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-03T19:14:38.800576Z","iopub.execute_input":"2023-08-03T19:14:38.800981Z","iopub.status.idle":"2023-08-03T19:14:38.817911Z","shell.execute_reply.started":"2023-08-03T19:14:38.800952Z","shell.execute_reply":"2023-08-03T19:14:38.816961Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# model = torch.load(\n#     \"/kaggle/input/tgae-model-saved/TGAE2_GRUConv_50_5.7319_5.8686.model\",\n#     map_location=torch.device(device)\n# )","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:37:58.335348Z","iopub.execute_input":"2023-08-02T13:37:58.335734Z","iopub.status.idle":"2023-08-02T13:37:58.340145Z","shell.execute_reply.started":"2023-08-02T13:37:58.335705Z","shell.execute_reply":"2023-08-02T13:37:58.339212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = TGAE(\n    in_channels=IN_CHANNELS, \n    out_channels=32, \n    embed_layers=[128,256,512,256],\n    decide_layers=[512,256,128],\n)\n\n# loss_f = torch.nn.CrossEntropyLoss()\nloss_f = torch.nn.MSELoss(reduction = 'none')\noptimizer = torch.optim.Adam(model.parameters(), lr = 5e-4)\n\nmodel = model.to(device)\nloss_f = loss_f.to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T19:15:00.778393Z","iopub.execute_input":"2023-08-03T19:15:00.778848Z","iopub.status.idle":"2023-08-03T19:15:01.032380Z","shell.execute_reply.started":"2023-08-03T19:15:00.778818Z","shell.execute_reply":"2023-08-03T19:15:01.031400Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"TGAE(\n  (embed_net): Sequential(\n    (0): Dropout(p=0.2, inplace=False)\n    (1): Linear(in_features=63, out_features=128, bias=True)\n    (2): LeakyReLU(negative_slope=0.01)\n    (3): Dropout(p=0.2, inplace=False)\n    (4): Linear(in_features=128, out_features=256, bias=True)\n    (5): LeakyReLU(negative_slope=0.01)\n    (6): Dropout(p=0.2, inplace=False)\n    (7): Linear(in_features=256, out_features=512, bias=True)\n    (8): LeakyReLU(negative_slope=0.01)\n    (9): Linear(in_features=512, out_features=256, bias=True)\n  )\n  (encoder_gru): GraphGRULayer(\n    (gru): GraphGRU(\n      (conv_x_z): MultiGraphConv(\n        (convs): ModuleList(\n          (0): GINConv(nn=Sequential(\n            (0): Linear(in_features=256, out_features=256, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=256, out_features=512, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=512, out_features=512, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n          (1): GINConv(nn=Sequential(\n            (0): Linear(in_features=512, out_features=512, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=512, out_features=256, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=256, out_features=256, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n        )\n      )\n      (conv_h_z): MultiGraphConv(\n        (convs): ModuleList(\n          (0): GINConv(nn=Sequential(\n            (0): Linear(in_features=256, out_features=256, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=256, out_features=512, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=512, out_features=512, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n          (1): GINConv(nn=Sequential(\n            (0): Linear(in_features=512, out_features=512, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=512, out_features=256, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=256, out_features=256, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n        )\n      )\n      (conv_x_r): MultiGraphConv(\n        (convs): ModuleList(\n          (0): GINConv(nn=Sequential(\n            (0): Linear(in_features=256, out_features=256, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=256, out_features=512, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=512, out_features=512, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n          (1): GINConv(nn=Sequential(\n            (0): Linear(in_features=512, out_features=512, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=512, out_features=256, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=256, out_features=256, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n        )\n      )\n      (conv_h_r): MultiGraphConv(\n        (convs): ModuleList(\n          (0): GINConv(nn=Sequential(\n            (0): Linear(in_features=256, out_features=256, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=256, out_features=512, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=512, out_features=512, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n          (1): GINConv(nn=Sequential(\n            (0): Linear(in_features=512, out_features=512, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=512, out_features=256, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=256, out_features=256, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n        )\n      )\n      (conv_x_h): MultiGraphConv(\n        (convs): ModuleList(\n          (0): GINConv(nn=Sequential(\n            (0): Linear(in_features=256, out_features=256, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=256, out_features=512, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=512, out_features=512, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n          (1): GINConv(nn=Sequential(\n            (0): Linear(in_features=512, out_features=512, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=512, out_features=256, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=256, out_features=256, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n        )\n      )\n      (conv_h_h): MultiGraphConv(\n        (convs): ModuleList(\n          (0): GINConv(nn=Sequential(\n            (0): Linear(in_features=256, out_features=256, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=256, out_features=512, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=512, out_features=512, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n          (1): GINConv(nn=Sequential(\n            (0): Linear(in_features=512, out_features=512, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=512, out_features=256, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=256, out_features=256, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n        )\n      )\n    )\n  )\n  (decide_net): Sequential(\n    (0): Dropout(p=0.2, inplace=False)\n    (1): Linear(in_features=256, out_features=512, bias=True)\n    (2): LeakyReLU(negative_slope=0.01)\n    (3): Dropout(p=0.2, inplace=False)\n    (4): Linear(in_features=512, out_features=256, bias=True)\n    (5): LeakyReLU(negative_slope=0.01)\n    (6): Dropout(p=0.2, inplace=False)\n    (7): Linear(in_features=256, out_features=128, bias=True)\n    (8): LeakyReLU(negative_slope=0.01)\n    (9): Linear(in_features=128, out_features=32, bias=True)\n  )\n  (decode_decide_net): Sequential(\n    (0): Dropout(p=0.2, inplace=False)\n    (1): Linear(in_features=32, out_features=128, bias=True)\n    (2): LeakyReLU(negative_slope=0.01)\n    (3): Dropout(p=0.2, inplace=False)\n    (4): Linear(in_features=128, out_features=256, bias=True)\n    (5): LeakyReLU(negative_slope=0.01)\n    (6): Dropout(p=0.2, inplace=False)\n    (7): Linear(in_features=256, out_features=512, bias=True)\n    (8): LeakyReLU(negative_slope=0.01)\n    (9): Linear(in_features=512, out_features=256, bias=True)\n  )\n  (decoder_gru): GraphGRULayer(\n    (gru): GraphGRU(\n      (conv_x_z): MultiGraphConv(\n        (convs): ModuleList(\n          (0): GINConv(nn=Sequential(\n            (0): Linear(in_features=256, out_features=256, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=256, out_features=512, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=512, out_features=512, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n          (1): GINConv(nn=Sequential(\n            (0): Linear(in_features=512, out_features=512, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=512, out_features=256, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=256, out_features=256, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n        )\n      )\n      (conv_h_z): MultiGraphConv(\n        (convs): ModuleList(\n          (0): GINConv(nn=Sequential(\n            (0): Linear(in_features=256, out_features=256, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=256, out_features=512, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=512, out_features=512, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n          (1): GINConv(nn=Sequential(\n            (0): Linear(in_features=512, out_features=512, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=512, out_features=256, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=256, out_features=256, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n        )\n      )\n      (conv_x_r): MultiGraphConv(\n        (convs): ModuleList(\n          (0): GINConv(nn=Sequential(\n            (0): Linear(in_features=256, out_features=256, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=256, out_features=512, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=512, out_features=512, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n          (1): GINConv(nn=Sequential(\n            (0): Linear(in_features=512, out_features=512, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=512, out_features=256, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=256, out_features=256, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n        )\n      )\n      (conv_h_r): MultiGraphConv(\n        (convs): ModuleList(\n          (0): GINConv(nn=Sequential(\n            (0): Linear(in_features=256, out_features=256, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=256, out_features=512, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=512, out_features=512, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n          (1): GINConv(nn=Sequential(\n            (0): Linear(in_features=512, out_features=512, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=512, out_features=256, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=256, out_features=256, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n        )\n      )\n      (conv_x_h): MultiGraphConv(\n        (convs): ModuleList(\n          (0): GINConv(nn=Sequential(\n            (0): Linear(in_features=256, out_features=256, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=256, out_features=512, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=512, out_features=512, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n          (1): GINConv(nn=Sequential(\n            (0): Linear(in_features=512, out_features=512, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=512, out_features=256, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=256, out_features=256, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n        )\n      )\n      (conv_h_h): MultiGraphConv(\n        (convs): ModuleList(\n          (0): GINConv(nn=Sequential(\n            (0): Linear(in_features=256, out_features=256, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=256, out_features=512, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=512, out_features=512, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n          (1): GINConv(nn=Sequential(\n            (0): Linear(in_features=512, out_features=512, bias=True)\n            (1): LeakyReLU(negative_slope=0.01)\n            (2): Linear(in_features=512, out_features=256, bias=True)\n            (3): LeakyReLU(negative_slope=0.01)\n            (4): Linear(in_features=256, out_features=256, bias=True)\n            (5): LeakyReLU(negative_slope=0.01)\n          ))\n        )\n      )\n    )\n  )\n  (decode_embed_net): Sequential(\n    (0): Dropout(p=0.2, inplace=False)\n    (1): Linear(in_features=256, out_features=512, bias=True)\n    (2): LeakyReLU(negative_slope=0.01)\n    (3): Dropout(p=0.2, inplace=False)\n    (4): Linear(in_features=512, out_features=256, bias=True)\n    (5): LeakyReLU(negative_slope=0.01)\n    (6): Dropout(p=0.2, inplace=False)\n    (7): Linear(in_features=256, out_features=128, bias=True)\n    (8): LeakyReLU(negative_slope=0.01)\n    (9): Linear(in_features=128, out_features=63, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train Loop","metadata":{}},{"cell_type":"code","source":"# for i_signal, signal in enumerate(signals_train):\n#     print(i_signal,signal.snapshot_count)\nsignal = signals_train[35]\nprint(signal.path)\nprint(torch.diff(signal.node_flag))","metadata":{"execution":{"iopub.status.busy":"2023-08-03T19:15:10.502848Z","iopub.execute_input":"2023-08-03T19:15:10.503244Z","iopub.status.idle":"2023-08-03T19:15:10.510972Z","shell.execute_reply.started":"2023-08-03T19:15:10.503213Z","shell.execute_reply":"2023-08-03T19:15:10.510147Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"/kaggle/input/dissertation-data/2021-09-11-umbrella-experiment-32run-fran/2021-09-10T185854/2021-09-10T191416_audit.npz\ntensor([ 80,  70,  80,  74,  87,  88,  73,  87,  80,  84,  75,  74,  85,  83,\n         73, 109,  93,  84,  71,  74,  91, 107,  79, 103, 976,  77,  87,  69,\n        313, 929,   6,  72,  26,   4,   4,   4,   4,   4, 697, 140,  84,  85,\n         78,  81, 182,  81,  68,  81,  83,  74,  77,  76,  75,  85,  82,  81,\n         68,  78, 102,  81,  69,  85,  83, 109])\n","output_type":"stream"}]},{"cell_type":"code","source":"# random select seriers\nimport random\n\nBATCH_SIZE = 60\nMIN_LEN = min([signal.snapshot_count for signal in signals_train])\n# print(len(signals_train))\n\ndata_list_2D = [[] for _ in range(MIN_LEN)]\n_node_index_list = [[] for _ in range(MIN_LEN)]\nbase_node_index = 0\nfor i_signal in np.random.randint(low=0, high=len(signals_train), size=BATCH_SIZE, dtype=int):\n    signal = signals_train[i_signal]\n    node_attr_split = signal.node_attr.tensor_split(signal.node_flag)\n    node_index_split = signal.node_index.tensor_split(signal.node_flag)\n    edge_index_split = signal.edge_index.tensor_split(signal.edge_flag, dim=1)\n\n    if signal.snapshot_count-MIN_LEN != 0:\n        _start = np.random.randint(low=0, high=signal.snapshot_count-MIN_LEN+1)\n    else:\n        _start = 0\n    print(i_signal, _start)\n    for i_series, i_snapshot in enumerate(range(_start, _start+MIN_LEN)):\n        data = Data(\n            x = node_attr_split[i_snapshot],\n            edge_index = edge_index_split[i_snapshot],\n            node_index = node_index_split[i_snapshot],\n            node_count =  signal.node_count\n        )\n        data_list_2D[i_series].append(data)\n        \n        _node_index_list[i_series].append(node_index_split[i_snapshot]+base_node_index)\n    base_node_index += signal.node_count\nnode_index_list = [torch.cat(_node_index, dim=0) for _node_index in _node_index_list]  ","metadata":{"execution":{"iopub.status.busy":"2023-08-03T21:21:14.819407Z","iopub.execute_input":"2023-08-03T21:21:14.819846Z","iopub.status.idle":"2023-08-03T21:21:14.904676Z","shell.execute_reply.started":"2023-08-03T21:21:14.819810Z","shell.execute_reply":"2023-08-03T21:21:14.903395Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"20 5\n27 1\n16 2\n0 4\n29 5\n36 3\n34 2\n34 5\n22 3\n11 4\n25 0\n4 1\n31 1\n12 3\n31 3\n20 2\n31 0\n7 1\n0 4\n32 1\n30 5\n28 2\n14 4\n25 4\n37 2\n9 3\n18 0\n35 5\n30 3\n4 0\n18 0\n11 0\n20 2\n15 2\n24 0\n12 0\n13 4\n14 6\n23 0\n25 4\n14 5\n32 0\n30 1\n24 1\n7 3\n3 1\n14 2\n32 4\n34 1\n14 2\n25 5\n1 0\n33 2\n10 5\n12 1\n19 4\n31 2\n11 1\n3 1\n6 2\n","output_type":"stream"}]},{"cell_type":"code","source":"data_list_2D[1][0].node_index","metadata":{"execution":{"iopub.status.busy":"2023-08-03T21:14:08.366998Z","iopub.execute_input":"2023-08-03T21:14:08.368271Z","iopub.status.idle":"2023-08-03T21:14:08.376465Z","shell.execute_reply.started":"2023-08-03T21:14:08.368225Z","shell.execute_reply":"2023-08-03T21:14:08.375481Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"tensor([  9,  10,   2,  11,  60,   1,  17, 111, 151, 152, 153,  75, 385,  32,\n         33, 155,  25, 156,  36,  37, 386, 158, 159, 387, 161, 162, 163, 164,\n        165, 388,  67, 167, 168,  68, 169, 170, 171, 389, 173, 390, 391, 176,\n        177,   8,   3, 150,  12, 178, 392, 393, 394, 395, 396, 397, 398, 399,\n        400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413,\n        414, 415, 416, 417, 418, 419,  20,  21, 257, 258, 420, 421, 422, 423,\n        424, 425, 426])"},"metadata":{}}]},{"cell_type":"code","source":"data_list_2D[2][0].node_count","metadata":{"execution":{"iopub.status.busy":"2023-08-03T21:21:19.972756Z","iopub.execute_input":"2023-08-03T21:21:19.973163Z","iopub.status.idle":"2023-08-03T21:21:19.979864Z","shell.execute_reply.started":"2023-08-03T21:21:19.973132Z","shell.execute_reply":"2023-08-03T21:21:19.978866Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"1394"},"metadata":{}}]},{"cell_type":"code","source":"node_index_list","metadata":{"execution":{"iopub.status.busy":"2023-08-03T21:12:36.605413Z","iopub.execute_input":"2023-08-03T21:12:36.605812Z","iopub.status.idle":"2023-08-03T21:12:36.617968Z","shell.execute_reply.started":"2023-08-03T21:12:36.605782Z","shell.execute_reply":"2023-08-03T21:12:36.616750Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"[tensor([  337,   336,     2,  ..., 87717, 87718, 87719]),\n tensor([    9,    10,     2,  ..., 87759, 87760, 87761]),\n tensor([    9,    10,     2,  ..., 87794, 87795, 87796]),\n tensor([  460,   461,     2,  ..., 87836, 87837, 87838]),\n tensor([    9,    10,     2,  ..., 87877, 87878, 87879]),\n tensor([    9,    10,     2,  ..., 87926, 87927, 87928]),\n tensor([    9,    10,     2,  ..., 87954, 87955, 87956]),\n tensor([    9,    10,     2,  ..., 87982, 87983, 87984]),\n tensor([    9,    10,     2,  ..., 88010, 88011, 88012]),\n tensor([    9,    10,     2,  ..., 88045, 88046, 88047]),\n tensor([    9,    10,     2,  ..., 88080, 88081, 88082]),\n tensor([    9,    10,     2,  ..., 88115, 88116, 88117]),\n tensor([    9,    10,     2,  ..., 88150, 88151, 88152]),\n tensor([    9,    10,     2,  ..., 88192, 88193, 88194]),\n tensor([    9,    10,     2,  ..., 88248, 88249, 88250]),\n tensor([  151,    17,     2,  ..., 88283, 88284, 88285])]"},"metadata":{}}]},{"cell_type":"code","source":"Batch.from_data_list(data_list_2D[0])","metadata":{"execution":{"iopub.status.busy":"2023-08-03T20:49:48.082517Z","iopub.execute_input":"2023-08-03T20:49:48.082934Z","iopub.status.idle":"2023-08-03T20:49:48.093983Z","shell.execute_reply.started":"2023-08-03T20:49:48.082906Z","shell.execute_reply":"2023-08-03T20:49:48.093246Z"},"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"DataBatch(x=[4686, 63], edge_index=[2, 16553], node_index=[4686], batch=[4686], ptr=[61])"},"metadata":{}}]},{"cell_type":"code","source":"# check batch works\nnormal_hidden_list = [[] for _ in range(MIN_LEN)]\npre_hidden_list = None\npre_node_index_list = None\nfor i_series in range(MIN_LEN):\n    _hidden_list = []\n    _node_index_list = []\n    for i_batch in range(BATCH_SIZE):\n        if pre_hidden_list is not None:\n            _hidden = torch.zeros((data_list_2D[i_series][i_batch].node_count,data_list_2D[i_series][i_batch].x.shape[1]))            \n            _hidden.index_add_(0,pre_node_index_list[i_batch], pre_hidden_list[i_batch])\n            normal_hidden_list[i_series].append(torch.index_select(_hidden,0,data_list_2D[i_series][i_batch].node_index))\n        \n        _hidden_list.append(data_list_2D[i_series][i_batch].x)\n        _node_index_list.append(data_list_2D[i_series][i_batch].node_index)\n    \n    pre_hidden_list = _hidden_list\n    pre_node_index_list = _node_index_list\nnormal_hidden_list = [torch.cat(_hiddens) for _hiddens in normal_hidden_list[1:]]\n\nbatch_list = [Batch.from_data_list(data_list) for data_list in data_list_2D]\nbatch_hidden_list = []\npre_hidden = None\npre_node_index = None\nfor i_series in range(MIN_LEN):\n    if pre_hidden is not None:\n        _hidden = torch.zeros((batch_list[i_series].x.shape))\n        # Solution from https://discuss.pytorch.org/t/find-indexes-of-elements-from-one-tensor-that-matches-in-another-tensor/147482/2\n        _index = (pre_node_index.unsqueeze(1) == node_index_list[i_series].unsqueeze(0)).nonzero() \n        _hidden.index_add_(0, _index[:,1], torch.index_select(pre_hidden,0, _index[:,0]))\n        batch_hidden_list.append(_hidden)\n    pre_hidden = batch_list[i_series].x\n    pre_node_index = node_index_list[i_series]\n\ntorch.all(torch.eq(normal_hidden_list[2], batch_hidden_list[2]))","metadata":{"execution":{"iopub.status.busy":"2023-08-03T22:42:36.862136Z","iopub.execute_input":"2023-08-03T22:42:36.862602Z","iopub.status.idle":"2023-08-03T22:42:36.942742Z","shell.execute_reply.started":"2023-08-03T22:42:36.862565Z","shell.execute_reply":"2023-08-03T22:42:36.941470Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-08-03T22:44:34.733020Z","iopub.execute_input":"2023-08-03T22:44:34.733458Z","iopub.status.idle":"2023-08-03T22:44:35.508977Z","shell.execute_reply.started":"2023-08-03T22:44:34.733424Z","shell.execute_reply":"2023-08-03T22:44:35.507994Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_loop\ndef train_loop(signal, model, loss_fn, optimizer, device):\n    model.train()\n    \n    X = signal.node_attr\n    node_index = signal.node_index\n    node_flag = signal.node_flag\n    edge_index = signal.edge_index\n    edge_flag = signal.edge_flag\n    \n    outs = model(X, node_index, node_flag, edge_index, edge_flag, signal.raw_node_attr.shape[0])\n\n    train_losses = torch.sqrt(torch.sum(loss_f(X, outs),dim=1))\n    total_loss = torch.mean(train_losses)\n    snapshot_losses = [loss.cpu().numpy() for loss in torch.tensor_split(train_losses.detach(), node_flag)]\n    \n    optimizer.zero_grad()\n    total_loss.backward()\n    optimizer.step()\n    return snapshot_losses","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:38:00.210668Z","iopub.execute_input":"2023-08-02T13:38:00.211722Z","iopub.status.idle":"2023-08-02T13:38:00.220229Z","shell.execute_reply.started":"2023-08-02T13:38:00.211685Z","shell.execute_reply":"2023-08-02T13:38:00.219202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test Loop","metadata":{}},{"cell_type":"code","source":"# test_loop\ndef test_loop(signal, model, loss_fn, optimizer, device):\n    with torch.no_grad():\n        X = signal.node_attr\n        node_index = signal.node_index\n        node_flag = signal.node_flag\n        edge_index = signal.edge_index\n        edge_flag = signal.edge_flag\n\n        outs = model(X, node_index, node_flag, edge_index, edge_flag, signal.raw_node_attr.shape[0])\n\n        train_losses = torch.sqrt(torch.sum(loss_f(X, outs),dim=1))\n        total_loss = torch.mean(train_losses)\n        snapshot_losses = [loss.cpu().numpy() for loss in torch.tensor_split(train_losses.detach(), node_flag)]\n    \n    return snapshot_losses","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:38:01.591808Z","iopub.execute_input":"2023-08-02T13:38:01.592863Z","iopub.status.idle":"2023-08-02T13:38:01.600518Z","shell.execute_reply.started":"2023-08-02T13:38:01.592831Z","shell.execute_reply":"2023-08-02T13:38:01.599565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GLOBAL_EPOCH = 0\ndef train_function(num_epoch):\n    global GLOBAL_EPOCH\n    \n    history_train = []\n    history_val = []\n\n    for i_epoch in range(1,num_epoch+1):\n        train_losses = []\n        _start = time.time()\n        for signal in signals_train:\n            snapshot_losses = train_loop(signal, model, loss_f, optimizer, device)\n#             print(np.mean(train_loss))\n            train_losses.append(np.mean([np.mean(loss) for loss in snapshot_losses]))\n            \n        \n        if i_epoch % 5 == 0:\n            val_losses = []\n            for signal in signals_val:\n                snapshot_losses = test_loop(signal, model, loss_f, optimizer, device)\n#                 print(np.mean(val_loss))\n                val_losses.append(np.mean([np.mean(loss) for loss in snapshot_losses]))\n            _end = time.time()\n            \n            history_train.append(np.mean(train_losses))\n            history_val.append(np.mean(val_losses))\n            print(f\"{i_epoch+GLOBAL_EPOCH}/{num_epoch+GLOBAL_EPOCH}: cost {_end-_start:.4f}s train loss {np.mean(train_losses):.4f} val loss {np.mean(val_losses):.4f}\")\n        else:\n            _end = time.time()\n            history_train.append(np.mean(train_losses))\n#             if i_epoch % 10 == 0:\n            print(f\"{i_epoch+GLOBAL_EPOCH}/{num_epoch+GLOBAL_EPOCH}: cost {_end-_start:.4f}s train loss {np.mean(train_losses):.4f}\")\n    GLOBAL_EPOCH += num_epoch\n    return (history_train,history_val)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:38:02.300814Z","iopub.execute_input":"2023-08-02T13:38:02.301175Z","iopub.status.idle":"2023-08-02T13:38:02.313001Z","shell.execute_reply.started":"2023-08-02T13:38:02.301146Z","shell.execute_reply":"2023-08-02T13:38:02.31214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_train_list = []\nhistory_val_list = []","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:38:03.085714Z","iopub.execute_input":"2023-08-02T13:38:03.086654Z","iopub.status.idle":"2023-08-02T13:38:03.091764Z","shell.execute_reply.started":"2023-08-02T13:38:03.086614Z","shell.execute_reply":"2023-08-02T13:38:03.090609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_train, history_val = train_function(50)\nhistory_train_list += history_train\nhistory_val_list += history_val\nplt.plot(history_train_list[1::5],label=\"Train\")\nplt.plot(history_val_list,label=\"Val\")\nplt.legend()\ntorch.save(model,f\"TGAE2_GRUConv_{GLOBAL_EPOCH}_{np.mean(history_train_list[-1]):.4f}_{np.mean(history_val_list[-1]):.4f}.model\")","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:38:03.903065Z","iopub.execute_input":"2023-08-02T13:38:03.904029Z","iopub.status.idle":"2023-08-02T13:53:40.891285Z","shell.execute_reply.started":"2023-08-02T13:38:03.903988Z","shell.execute_reply":"2023-08-02T13:53:40.890379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history_train, history_val = train_function(50)\n# history_train_list += history_train\n# history_val_list += history_val\n# plt.plot(history_train_list[1::5],label=\"Train\")\n# plt.plot(history_val_list,label=\"Val\")\n# plt.legend()","metadata":{"execution":{"iopub.status.busy":"2023-08-01T09:41:28.406233Z","iopub.status.idle":"2023-08-01T09:41:28.407188Z","shell.execute_reply.started":"2023-08-01T09:41:28.406947Z","shell.execute_reply":"2023-08-01T09:41:28.406969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"snapshot_losses_list = []\nfor i_signal,(self,y) in enumerate(zip(signals_val,y_val)):\n    snapshot_losses = test_loop(self, model, loss_f, optimizer, device)\n    snapshot_losses_list.append(snapshot_losses)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T10:38:54.630817Z","iopub.execute_input":"2023-08-01T10:38:54.631267Z","iopub.status.idle":"2023-08-01T10:39:11.876031Z","shell.execute_reply.started":"2023-08-01T10:38:54.631228Z","shell.execute_reply":"2023-08-01T10:39:11.875164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,20))    \nfor i_signal,(self, snapshot_losses, annotation) in enumerate(zip(signals_val, snapshot_losses_list, annotation_val)):\n    ts_list = self.ts_list\n    plt.subplot(len(signals_val)+1,1,i_signal+1)\n#     print(len(snapshot_losses))\n    plt.plot(ts_list,[np.sum(loss) for loss in snapshot_losses])\n    if annotation[0] == 'dos':\n        plt.axvline(x = float(annotation[1]), color = 'red', label = annotation[0])\n    if annotation[0] == 'privesc':\n        plt.axvline(x = float(annotation[1]), color = 'blue', label = annotation[0])","metadata":{"execution":{"iopub.status.busy":"2023-08-01T10:58:09.973351Z","iopub.execute_input":"2023-08-01T10:58:09.973995Z","iopub.status.idle":"2023-08-01T10:58:12.295351Z","shell.execute_reply.started":"2023-08-01T10:58:09.973957Z","shell.execute_reply":"2023-08-01T10:58:12.294045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for snapshot_losses, y in zip(snapshot_losses_list,y_val):\n#     print(snapshot_losses)\n    print([(i_snapshot, len(loss),int(label)) for i_snapshot, (loss, label) in enumerate(zip(snapshot_losses, y))])\n    loss_list = []\n    for losses in snapshot_losses:\n        loss_list += list(losses)\n    counts, edges, bars = plt.hist(loss_list)\n    plt.bar_label(bars)\n    plt.show()\n    break\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-01T10:39:17.745177Z","iopub.execute_input":"2023-08-01T10:39:17.745579Z","iopub.status.idle":"2023-08-01T10:39:18.084884Z","shell.execute_reply.started":"2023-08-01T10:39:17.745548Z","shell.execute_reply":"2023-08-01T10:39:18.083652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counts, edges, bars = plt.hist(snapshot_losses_list[0][5],bins=20)\nplt.bar_label(bars)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-01T11:15:13.83813Z","iopub.execute_input":"2023-08-01T11:15:13.838631Z","iopub.status.idle":"2023-08-01T11:15:14.221674Z","shell.execute_reply.started":"2023-08-01T11:15:13.838596Z","shell.execute_reply":"2023-08-01T11:15:14.22083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counts, edges, bars = plt.hist(snapshot_losses_list[0][11],bins=20)\nplt.bar_label(bars)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-01T11:18:25.135489Z","iopub.execute_input":"2023-08-01T11:18:25.135956Z","iopub.status.idle":"2023-08-01T11:18:25.472637Z","shell.execute_reply.started":"2023-08-01T11:18:25.135925Z","shell.execute_reply":"2023-08-01T11:18:25.471395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history_train, history_val = train_function(50)\n# history_train_list += history_train\n# history_val_list += history_val\n# plt.plot(history_train_list[1::5],label=\"Train\")\n# plt.plot(history_val_list,label=\"Val\")\n# plt.legend()","metadata":{"execution":{"iopub.status.busy":"2023-08-01T09:41:28.422214Z","iopub.status.idle":"2023-08-01T09:41:28.423097Z","shell.execute_reply.started":"2023-08-01T09:41:28.422848Z","shell.execute_reply":"2023-08-01T09:41:28.422872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fig = plt.figure(figsize=(20,20))    \n# for i_signal,(signal,y) in enumerate(zip(signals_val,y_val)):\n#     snapshot_losses = test_loop(signal, model, loss_f, optimizer, device)\n# #                 print(np.mean(val_loss))\n# #     val_losses.append(np.mean(snapshot_losses))\n#     ts_list = signal.ts_list\n#     plt.subplot(len(signals_val)+1,1,i_signal+1)\n# #     print(len(snapshot_losses))\n#     plt.plot(ts_list,[np.max(loss) for loss in snapshot_losses])\n#     if y[0] == 'dos':\n#         plt.axvline(x = float(y[1]), color = 'red', label = y[0])\n#     if y[0] == 'privesc':\n#         plt.axvline(x = float(y[1]), color = 'blue', label = y[0])\n# # plt.show()\n# plt.savefig(f'val_res_TGAE_NNConv_{GLOBAL_EPOCH}_{np.mean(history_train_list[-1]):.4f}_{np.mean(history_val_list[-1]):.4f}.png')","metadata":{"execution":{"iopub.status.busy":"2023-08-01T09:41:28.424521Z","iopub.status.idle":"2023-08-01T09:41:28.42534Z","shell.execute_reply.started":"2023-08-01T09:41:28.425108Z","shell.execute_reply":"2023-08-01T09:41:28.425131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], use_cuda=True, record_shapes=True) as prof:\n#         history_train, history_val = train_function(1)\n#         history_train_list += history_train\n#         history_val_list += history_val\n#         plt.plot(history_train_list[1::5],label=\"Train\")\n#         plt.plot(history_val_list,label=\"Val\")\n#         plt.legend()\n# print(prof.key_averages().table(sort_by=\"cuda_time_total\"))","metadata":{"execution":{"iopub.status.busy":"2023-08-01T09:41:28.427011Z","iopub.status.idle":"2023-08-01T09:41:28.428071Z","shell.execute_reply.started":"2023-08-01T09:41:28.427799Z","shell.execute_reply":"2023-08-01T09:41:28.427826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(prof.key_averages().table(sort_by=\"cpu_time_total\"))","metadata":{"execution":{"iopub.status.busy":"2023-08-01T09:41:28.429599Z","iopub.status.idle":"2023-08-01T09:41:28.430143Z","shell.execute_reply.started":"2023-08-01T09:41:28.429853Z","shell.execute_reply":"2023-08-01T09:41:28.429891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fig = plt.figure(figsize=(20,20))    \n# for i_signal,(signal,y) in enumerate(zip(signals_val,y_val)):\n#     snapshot_losses = test_loop(signal, model, loss_f, optimizer, device)\n# #                 print(np.mean(val_loss))\n# #     val_losses.append(np.mean(snapshot_losses))\n#     ts_list = signal.ts_list\n#     plt.subplot(len(signals_val)+1,1,i_signal+1)\n# #     print(len(snapshot_losses))\n#     plt.plot(ts_list,snapshot_losses[:-1])\n#     if y[0] == 'dos':\n#         plt.axvline(x = float(y[1]), color = 'red', label = y[0])\n#     if y[0] == 'privesc':\n#         plt.axvline(x = float(y[1]), color = 'blue', label = y[0])\n# # plt.show()\n# plt.savefig('val_res.png')","metadata":{"execution":{"iopub.status.busy":"2023-08-01T09:41:28.432298Z","iopub.status.idle":"2023-08-01T09:41:28.433393Z","shell.execute_reply.started":"2023-08-01T09:41:28.433146Z","shell.execute_reply":"2023-08-01T09:41:28.433169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.save(model,f\"{GLOBAL_EPOCH}_{np.mean(history_train_list[-1]):.4f}_{np.mean(history_val_list[-1]):.4f}.model\")","metadata":{"execution":{"iopub.status.busy":"2023-08-01T09:41:28.434774Z","iopub.status.idle":"2023-08-01T09:41:28.435566Z","shell.execute_reply.started":"2023-08-01T09:41:28.435285Z","shell.execute_reply":"2023-08-01T09:41:28.43531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history_train, history_val = train_function(100)\n# history_train_list += history_train\n# history_val_list += history_val\n# plt.plot(history_train_list[1::5],label=\"Train\")\n# plt.plot(history_val_list,label=\"Val\")\n# plt.legend()","metadata":{"execution":{"iopub.status.busy":"2023-08-01T09:41:28.437339Z","iopub.status.idle":"2023-08-01T09:41:28.437931Z","shell.execute_reply.started":"2023-08-01T09:41:28.437699Z","shell.execute_reply":"2023-08-01T09:41:28.437721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# states_encoder_val = []\n# states_decoder_val = []\n# for num_node in nums_node_val:\n#     states_encoder_val.append(create_hidden_global(num_node=num_node,out_channels=model.gnn_out_channels))\n#     states_decoder_val.append(create_hidden_global(num_node=num_node,out_channels=model.embedding_hidden_nums[-1]))    \n\n# fig = plt.figure(figsize=(20,20))    \n# for i_sample, (sample, y, hidden_encoder_global, hidden_decoder_global) in enumerate(zip(X_val, y_val, states_encoder_val, states_decoder_val)):\n#     val_loss = test_loop(sample, hidden_encoder_global, hidden_decoder_global, model, loss_f, optimizer, device)\n#     # print(np.mean(val_loss))\n#     ts_list = [snapshot.timestamp for snapshot in sample]\n#     plt.subplot(len(X_val)+1,1,i_sample+1)\n#     plt.plot(ts_list,val_loss)\n#     if y[0] == 'dos':\n#         plt.axvline(x = float(y[1]), color = 'red', label = y[0])\n#     if y[0] == 'privesc':\n#         plt.axvline(x = float(y[1]), color = 'blue', label = y[0])\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-01T09:41:28.440161Z","iopub.status.idle":"2023-08-01T09:41:28.4407Z","shell.execute_reply.started":"2023-08-01T09:41:28.440416Z","shell.execute_reply":"2023-08-01T09:41:28.440441Z"},"trusted":true},"execution_count":null,"outputs":[]}]}