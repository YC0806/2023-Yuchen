{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nuse_gpu = torch.cuda.is_available()\nprint(torch.__version__)\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-08-28T00:51:07.235688Z","iopub.execute_input":"2023-08-28T00:51:07.236653Z","iopub.status.idle":"2023-08-28T00:51:11.581782Z","shell.execute_reply.started":"2023-08-28T00:51:07.236617Z","shell.execute_reply":"2023-08-28T00:51:11.579826Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"2.0.0\ncuda:0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Initialize for CPU & GPU","metadata":{}},{"cell_type":"code","source":"if use_gpu:\n    !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric --no-index --find-links=file:///kaggle/input/torch-geometric\n#     !pip install torch_geometric_temporal  \nelse:\n    !pip install /kaggle/input/pytorch-geometric-cpu/torch_scatter-2.1.1pt20cpu-cp310-cp310-linux_x86_64.whl\n    !pip install /kaggle/input/pytorch-geometric-cpu/torch_sparse-0.6.17pt20cpu-cp310-cp310-linux_x86_64.whl\n    !pip install /kaggle/input/pytorch-geometric-cpu/torch_cluster-1.6.1pt20cpu-cp310-cp310-linux_x86_64.whl\n    !pip install /kaggle/input/pytorch-geometric-cpu/torch_spline_conv-1.2.2pt20cpu-cp310-cp310-linux_x86_64.whl\n    !pip install /kaggle/input/pytorch-geometric-cpu/torch_geometric-2.3.1-py3-none-any.whl\n#     !pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n#     !pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n#     !pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n#     !pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n#     !pip install torch_spline_conv -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n#     !pip install git+https://github.com/pyg-team/pytorch_geometric.git\n#     !pip install torch_geometric_temporal","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-28T00:51:11.584775Z","iopub.execute_input":"2023-08-28T00:51:11.585677Z","iopub.status.idle":"2023-08-28T00:51:25.943493Z","shell.execute_reply.started":"2023-08-28T00:51:11.585639Z","shell.execute_reply":"2023-08-28T00:51:25.942305Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Looking in links: file:///kaggle/input/torch-geometric\nProcessing /kaggle/input/torch-geometric/torch_scatter-2.1.1-cp310-cp310-linux_x86_64.whl\nProcessing /kaggle/input/torch-geometric/torch_sparse-0.6.17-cp310-cp310-linux_x86_64.whl\nProcessing /kaggle/input/torch-geometric/torch_cluster-1.6.1-cp310-cp310-linux_x86_64.whl\nProcessing /kaggle/input/torch-geometric/torch_spline_conv-1.2.2-cp310-cp310-linux_x86_64.whl\nProcessing /kaggle/input/torch-geometric/torch_geometric-2.3.1-py3-none-any.whl\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-sparse) (1.10.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (4.64.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.23.5)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (2.28.2)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.0.9)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.2.2)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (5.9.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch-geometric) (2.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (2023.5.7)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.1.0)\nInstalling collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster, torch-geometric\nSuccessfully installed torch-cluster-1.6.1 torch-geometric-2.3.1 torch-scatter-2.1.1 torch-sparse-0.6.17 torch-spline-conv-1.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport re\nimport json\nimport random\nfrom scipy.special import perm\nfrom itertools import combinations,chain\nfrom typing import List, Union\nfrom torch_geometric.data import Data\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport matplotlib.pyplot as plt\nimport pickle\nimport time\nfrom torch import nn\nfrom torch.nn import Linear as Lin\nfrom torch.nn import ReLU, LeakyReLU\nfrom torch.nn import Sequential as Seq\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, GINEConv, GATConv\nfrom torch_geometric.data import Batch\nfrom torch import autograd\nfrom torch_geometric.nn.models import InnerProductDecoder\nfrom torch_geometric.utils import to_dense_adj\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score\n\nfrom texttable import Texttable\nfrom itertools import product","metadata":{"execution":{"iopub.status.busy":"2023-08-28T00:51:25.945911Z","iopub.execute_input":"2023-08-28T00:51:25.947088Z","iopub.status.idle":"2023-08-28T00:51:27.388417Z","shell.execute_reply.started":"2023-08-28T00:51:25.947045Z","shell.execute_reply":"2023-08-28T00:51:27.387343Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# DataLoader","metadata":{}},{"cell_type":"code","source":"Edge_Flag = List[Union[np.ndarray, None]]\nEdge_Index = List[Union[np.ndarray, None]]\nEdge_Attr = List[Union[np.ndarray, None]]\n\nNode_Flag = List[Union[np.ndarray, None]]\nNode_Index = List[Union[np.ndarray, None]]\nNode_Attr = List[Union[np.ndarray, None]]\n\n\n\nclass GraphSignal(object):\n    # dynamic node static node attr dynamic edge and edge attr\n    def __init__(\n        self,\n        edge_flag: Edge_Flag,\n        edge_index: Edge_Index,\n        edge_attr: Edge_Attr,\n        node_flag: Node_Flag,\n        node_index: Node_Index,\n        node_attr: Node_Attr,\n        ts_list: List,\n        path: str,\n    ):\n        \n        self.raw_edge_flag = torch.LongTensor(edge_flag[:-1])\n        self.raw_edge_index = torch.LongTensor(edge_index).T\n        self.raw_edge_attr = edge_attr\n        self.raw_node_attr = node_attr \n        self.node_flag = torch.LongTensor(node_flag[:-1])\n        self.node_index = torch.LongTensor(node_index)\n        \n        self.ts_list = ts_list\n        \n        self.path = path\n        \n        self.node_attr = None\n        self.edge_flag = None\n        self.edge_index = None\n        \n        self.y = None\n        \n        self._set_snapshot_count()\n        self._set_node_count()\n\n    def _set_snapshot_count(self):\n        self.snapshot_count = len(self.ts_list)\n    \n    def _set_node_count(self):\n        self.node_count = self.raw_node_attr.shape[0]\n    \n    def encode_edge_attr(self, enocder):\n        self.edge_attr_encoded = torch.FloatTensor(enocder.transform(self.raw_edge_attr))\n        \n    def encode_node_attr(self, enocder):\n        self.node_attr_encoded = torch.FloatTensor(enocder.transform(self.raw_node_attr)).index_select(dim=0,index=self.node_index)\n        \n    def extend_node_attr(self):\n        if self.edge_attr_encoded is None:\n            print(\"Edge Attr Need to be Encoded!\")\n            raise\n        node_index = self.node_index\n        node_attr = self.node_attr_encoded\n        node_flag = self.node_flag\n        \n        edge_index = self.raw_edge_index\n        edge_attr = self.edge_attr_encoded\n        edge_flag = self.raw_edge_flag\n        \n        node_index_split = torch.tensor_split(node_index, node_flag)\n        node_attr_split = torch.tensor_split(node_attr, node_flag)\n        edge_index_split = torch.tensor_split(edge_index, edge_flag, dim=1)\n        edge_attr_split = torch.tensor_split(edge_attr, edge_flag)\n\n        base = 0\n        new_node_attr = []\n        new_edge_flag = []\n        new_edge_index = []\n        \n        for i_snapshot in range(self.snapshot_count):\n            _node_index = node_index_split[i_snapshot]\n            _node_attr = node_attr_split[i_snapshot]\n            _edge_index = edge_index_split[i_snapshot]\n            _edge_attr = edge_attr_split[i_snapshot]\n\n            if _edge_index.shape[1] != _edge_attr.shape[0]:\n                print(i_snapshot, edge_index.shape, _edge_attr.shape)\n                raise\n            if _edge_index.shape[1] > 0:\n                index_dict = {}\n                for i_edge in range(_edge_index.shape[1]):\n                    index_tuple = tuple(_edge_index[:,i_edge].tolist())\n                    if index_tuple in index_dict:\n                        index_dict[index_tuple] += [i_edge]\n                    else:\n                        index_dict[index_tuple] = [i_edge]\n\n                _new_edge_index = []\n                _new_edge_attr = []\n                for key in index_dict.keys():\n                    _new_edge_index.append(key)\n                    _new_edge_attr.append(torch.sum(_edge_attr.index_select(0, torch.LongTensor(index_dict[key])),dim=0).unsqueeze(0))\n\n                _new_edge_index = torch.LongTensor(_new_edge_index).T\n                _new_edge_attr = torch.cat(_new_edge_attr,dim=0)\n                \n                base += _new_edge_index.shape[1]\n                new_edge_index.append(_new_edge_index)\n\n#                 _source_attr = torch.zeros((_node_attr.shape[0], _new_edge_attr.shape[1])).to(device)\n#                 _target_attr = torch.zeros((_node_attr.shape[0], _new_edge_attr.shape[1])).to(device)\n#                 _source_attr.index_add_(0, _new_edge_index[0], _new_edge_attr)\n#                 _target_attr.index_add_(0, _new_edge_index[1], _new_edge_attr)\n#                 new_node_attr.append(torch.cat([_node_attr,_source_attr,_target_attr], dim=1))\n\n                _node_attr_extend = torch.zeros((_node_attr.shape[0], _new_edge_attr.shape[1]))\n                _node_attr_extend.index_add_(0, _new_edge_index[0], _new_edge_attr)\n                _node_attr_extend.index_add_(0, _new_edge_index[1], _new_edge_attr)\n                new_node_attr.append(torch.cat([_node_attr,_node_attr_extend], dim=1)) \n                \n            new_edge_flag.append(base)\n        \n        self.node_attr = F.tanh(torch.cat(new_node_attr, dim=0))\n        self.edge_flag = torch.LongTensor(new_edge_flag)\n        self.edge_index = torch.cat(new_edge_index,dim=1)\n    \n    def remove_init_stop(self, threshold, period):  \n        node_index = self.node_index\n        node_flag = self.node_flag\n        raw_edge_index = self.raw_edge_index\n        raw_edge_attr = self.raw_edge_attr\n        raw_edge_flag = self.raw_edge_flag\n\n        node_index_split = torch.tensor_split(node_index, node_flag)\n        raw_edge_index_split = torch.tensor_split(raw_edge_index, raw_edge_flag, dim=1)\n        raw_edge_attr_split = np.split(raw_edge_attr, raw_edge_flag)\n        \n        if self.node_attr_encoded is not None:\n            node_attr_encoded = self.node_attr_encoded\n            node_attr_encoded_split = torch.tensor_split(node_attr_encoded, node_flag)\n          \n        if self.edge_attr_encoded is not None:\n            edge_attr_encoded = self.edge_attr_encoded\n            edge_attr_encoded_split = torch.tensor_split(edge_attr_encoded, raw_edge_flag)\n        \n        if self.node_attr is not None:\n            node_attr = self.node_attr\n            edge_index = self.edge_index\n            edge_flag = self.edge_flag\n            \n            node_attr_split = torch.tensor_split(node_attr, node_flag)\n            edge_index_split = torch.tensor_split(edge_index, edge_flag, dim=1)\n\n        i_init = None\n        i_stop = None\n        for i_snapshot, node_num in enumerate(torch.diff(self.node_flag)):\n            if node_num > threshold:\n                i_init = i_snapshot+1\n                break\n\n        for i_snapshot, node_num in enumerate(torch.flip(torch.diff(self.node_flag),dims=[0])):\n            if node_num > threshold:\n                i_stop = self.node_flag.shape[0]-1-i_snapshot\n                break\n        \n\n        new_node_index = torch.cat(node_index_split[i_init+1+period:i_stop-period],dim=0)\n        new_node_flag = node_flag[i_init+period+1:i_stop-period-1]-node_flag[i_init+period]\n        new_raw_edge_index = torch.cat(raw_edge_index_split[i_init+1+period:i_stop-period], dim=1)\n        new_raw_edge_attr = np.concatenate(raw_edge_attr_split[i_init+1+period:i_stop-period])\n        new_raw_edge_flag = raw_edge_flag[i_init+period+1:i_stop-period-1]-raw_edge_flag[i_init+period]\n        \n        self.node_index = new_node_index\n        self.node_flag = new_node_flag\n        self.raw_edge_attr = new_raw_edge_attr\n        self.raw_edge_index = new_raw_edge_index\n        self.raw_edge_flag = new_raw_edge_flag\n        \n        if self.node_attr_encoded is not None:\n            new_node_attr_encoded = torch.cat(node_attr_encoded_split[i_init+1+period:i_stop-period],dim=0)\n            self.node_attr_encoded = new_node_attr_encoded\n          \n        if self.edge_attr_encoded is not None:\n            new_edge_attr_encoded = torch.cat(edge_attr_encoded_split[i_init+1+period:i_stop-period],dim=0)\n            self.edge_attr_encoded = new_edge_attr_encoded\n        \n        if self.node_attr is not None:\n            new_node_attr = torch.cat(node_attr_split[i_init+1+period:i_stop-period],dim=0)\n            new_edge_index = torch.cat(edge_index_split[i_init+1+period:i_stop-period],dim=1)\n            new_edge_flag = edge_flag[i_init+period+1:i_stop-period-1]-edge_flag[i_init+period]\n            self.node_attr = new_node_attr\n            self.edge_index = new_edge_index\n            self.edge_flag = new_edge_flag\n        \n        self.ts_list = self.ts_list[i_init+1+period:i_stop-period]\n        \n        self._set_snapshot_count()\n    \n    def annotation2y(self, annotation, interval, overlap, offset= -30):\n        ts_list = self.ts_list\n        y = torch.zeros(self.snapshot_count, dtype=torch.long)\n        for i_ts, ts in enumerate(ts_list):\n            if ts < float(annotation[1])+offset and float(annotation[1])+offset <= ts+interval-overlap: \n                y[i_ts] = 1\n        self.y = y\n    \n    def to(self,device):\n        self.node_index = self.node_index.to(device)\n        self.raw_edge_index = self.raw_edge_index.to(device)\n        if self.node_attr_encoded is not None:\n            self.node_attr_encoded = self.node_attr_encoded.to(device)\n        if self.edge_attr_encoded is not None:\n            self.edge_attr_encoded = self.edge_attr_encoded.to(device)\n            \n        if self.node_attr is not None:\n            self.node_attr = self.node_attr.to(device)\n            self.edge_index = self.edge_index.to(device)\n    \n    def get_adj_list(self):\n        edge_index = self.edge_index\n        edge_flag = self.edge_flag\n        edge_index_split = torch.tensor_split(edge_index, edge_flag, dim=1)\n        adj_list = [torch.clamp(to_dense_adj(_edge_index)[0], min=0, max=1) for _edge_index in edge_index_split]\n        return adj_list\n\n    def _get_edge_index(self, time_index: int):\n        if time_index == 0:\n            _start = 0\n        else:\n            _start = self.edge_flag[time_index-1]\n        _end = self.edge_flag[time_index]\n        _edge_index = self.edge_index[:,_start:_end]\n        return _edge_index\n\n    def _get_edge_attr(self, time_index: int):\n        if self.edge_attr_encoded is None:\n            print(\"Edge Attr Need to be Encoded!\")\n            raise\n        if time_index == 0:\n            _start = 0\n        else:\n            _start = self.edge_flag[time_index-1]\n        _end = self.edge_flag[time_index]\n        _edge_attr = self.edge_attr_encoded[_start:_end]\n        return _edge_attr\n    \n    def _get_node_index_attr(self, time_index: int):\n        if self.node_attr_encoded is None:\n            print(\"Node Attr Need to be Encoded!\")\n            raise\n        if time_index == 0:\n            _start = 0\n        else:\n            _start = self.node_flag[time_index-1]\n        _end = self.node_flag[time_index]\n        _node_index = self.node_index[_start:_end]\n        _node_attr = self.node_attr_encoded[_node_index]\n        return _node_index,_node_attr\n    \n    def _get_timestamp(self, time_index: int):\n        _timestamp = self.ts_list[time_index]\n        return _timestamp\n\n\n    def __getitem__(self, time_index: int):\n        edge_index = self._get_edge_index(time_index)\n        edge_attr = self._get_edge_attr(time_index)\n        node_index,node_attr = self._get_node_index_attr(time_index)\n        _timestamp = self._get_timestamp(time_index)\n\n        snapshot = Data(\n            edge_index=edge_index,\n            edge_attr=edge_attr,\n            node_index=node_index,\n            node_attr=node_attr,\n            timestamp=_timestamp\n        )\n        return snapshot\n\n    def __next__(self):\n        if self.t < self.snapshot_count:\n            snapshot = self[self.t]\n            self.t = self.t + 1\n            return snapshot\n        else:\n            self.t = 0\n            raise StopIteration\n\n    def __iter__(self):\n        self.t = 0\n        return self\n    \n    def __len__(self):\n        return self.snapshot_count\n\n\nclass GraphDatasetLoader(object):\n    def __init__(self,input_path=\"\"):\n        self.input_path = input_path\n        self._read_data()\n    \n    def _read_data(self):\n        self._dataset = np.load(self.input_path)\n\n    def get_dataset(self): # -> DynamicGraphTemporalSignal:\n        dataset = GraphSignal(\n            edge_flag = self._dataset['edge_flag'],\n            edge_index = self._dataset['edge_index'],\n            edge_attr = self._dataset['edge_attr'],\n            node_flag = self._dataset['node_flag'],\n            node_index = self._dataset['node_index'],\n            node_attr = self._dataset['node_attr'],\n            ts_list = self._dataset['timestamp'],\n            path = self.input_path\n        )\n        return dataset","metadata":{"execution":{"iopub.status.busy":"2023-08-28T00:51:27.391717Z","iopub.execute_input":"2023-08-28T00:51:27.392360Z","iopub.status.idle":"2023-08-28T00:51:27.445527Z","shell.execute_reply.started":"2023-08-28T00:51:27.392324Z","shell.execute_reply":"2023-08-28T00:51:27.444018Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Read Data","metadata":{}},{"cell_type":"code","source":"data_dir_0 = '/kaggle/input/dissertation-data'\ndata_dir_1_list = [\n    '2021-09-24-umbrella-experiment-64run-fran',\n    '2021-09-27-RaspVM-experiment-64run-env1',\n    '2021-09-29-RaspVM-experiment-64run-env1'\n]\n\n\nsignals = []\nannotation = []\n\nfor data_dir_1 in data_dir_1_list:\n    with open(os.path.join(data_dir_0, data_dir_1, \"annotated.json\")) as f:\n        annotated_dict = json.load(f)\n\n    for data_dir_2 in os.listdir(os.path.join(data_dir_0, data_dir_1)):\n        if data_dir_2 == \"annotated.json\":\n            continue\n        r = re.compile(\".*.npz\")\n        graph_files = list(filter(r.match, os.listdir(os.path.join(data_dir_0, data_dir_1, data_dir_2))))\n\n        if len(graph_files) > 1:\n            print(\"Multiple Graph Files!\")\n            raise\n        if len(graph_files) == 0:\n            print(\"Not Found Graph File!\")\n            continue\n\n        dataloader = GraphDatasetLoader(os.path.join(data_dir_0, data_dir_1, data_dir_2, graph_files[0]))\n        signal = dataloader.get_dataset()\n        signals.append(signal)\n        annotation.append(annotated_dict[data_dir_2])\n\n# split train and test dataset\nsignals_train, signals_val, annotation_train, annotation_val = train_test_split(signals, annotation, test_size=0.5, random_state=1365)","metadata":{"execution":{"iopub.status.busy":"2023-08-28T00:51:27.448547Z","iopub.execute_input":"2023-08-28T00:51:27.448880Z","iopub.status.idle":"2023-08-28T00:51:30.631926Z","shell.execute_reply.started":"2023-08-28T00:51:27.448855Z","shell.execute_reply":"2023-08-28T00:51:30.630960Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"76\n38\n76\n","output_type":"stream"}]},{"cell_type":"code","source":"_interval = 60\n_overlap = 30\n\nnode_num_list = []\nfor signal in signals_train:\n    node_num_list += torch.diff(signal.node_flag).tolist()\n    \nthreshold = np.median(node_num_list)\nperiod = 3\n\nprint(f\"Threshold = {threshold} Period = {period}\")\n\nnode_attr_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\nnode_attr_encoder = node_attr_encoder.fit(np.concatenate([sample.raw_node_attr for sample in signals_train]))\n\nedge_attr_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\nedge_attr_encoder = edge_attr_encoder.fit(np.concatenate([sample.raw_edge_attr for sample in signals_train]))\n\nfor i_signal, (signal, annotation) in enumerate(zip(signals_train, annotation_train)):\n    signal.encode_node_attr(node_attr_encoder)\n    signal.encode_edge_attr(edge_attr_encoder)\n#     signal.extend_node_attr()\n    signal.remove_init_stop(threshold, period)\n    signal.annotation2y(annotation, _interval, _overlap)    \n    signal.to(device)\n    signal.node_attr = signal.node_attr_encoded\n    signal.edge_attr = signal.edge_attr_encoded\n    signal.edge_index = signal.raw_edge_index\n    signal.edge_flag = signal.raw_edge_flag\n    \nfor i_signal, (signal, annotation) in enumerate(zip(signals_val, annotation_val)):\n    signal.encode_node_attr(node_attr_encoder)\n    signal.encode_edge_attr(edge_attr_encoder)\n#     signal.extend_node_attr()\n    signal.remove_init_stop(threshold, period)\n    signal.annotation2y(annotation, _interval, _overlap)    \n    signal.to(device)\n    signal.node_attr = signal.node_attr_encoded\n    signal.edge_attr = signal.edge_attr_encoded\n    signal.edge_index = signal.raw_edge_index\n    signal.edge_flag = signal.raw_edge_flag","metadata":{"execution":{"iopub.status.busy":"2023-08-28T00:51:30.633191Z","iopub.execute_input":"2023-08-28T00:51:30.634126Z","iopub.status.idle":"2023-08-28T00:51:41.603779Z","shell.execute_reply.started":"2023-08-28T00:51:30.634090Z","shell.execute_reply":"2023-08-28T00:51:41.602792Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Threshold = 25.0 Period = 3\n","output_type":"stream"}]},{"cell_type":"code","source":"IN_CHANNELS = signals_train[0].node_attr.shape[1]\nEDGE_CHANNELS = signals_train[0].edge_attr.shape[1]","metadata":{"execution":{"iopub.status.busy":"2023-08-28T00:51:41.605129Z","iopub.execute_input":"2023-08-28T00:51:41.605500Z","iopub.status.idle":"2023-08-28T00:51:41.611401Z","shell.execute_reply.started":"2023-08-28T00:51:41.605467Z","shell.execute_reply":"2023-08-28T00:51:41.610422Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Multi-Layer GraphConv","metadata":{}},{"cell_type":"code","source":"class MultiGraphConv(torch.nn.Module):\n    def __init__(\n        self, \n        channels, \n    ):\n        super().__init__()\n         \n        self.convs = nn.ModuleList()\n        \n        net1 = Seq(\n            Lin(channels, channels),\n            LeakyReLU(),\n            Lin(channels, channels*2),\n            LeakyReLU(),\n            Lin(channels*2, channels*2),\n            LeakyReLU(),\n        )\n        self.conv1 = GINEConv(net1,edge_dim=EDGE_CHANNELS,train_eps=True)\n        \n        net2 = Seq(\n            Lin(channels*2, channels*2),\n            LeakyReLU(),\n            Lin(channels*2, channels),\n            LeakyReLU(),\n            Lin(channels, channels),\n            LeakyReLU(),\n        )\n        self.conv2 = GINEConv(net2,edge_dim=EDGE_CHANNELS,train_eps=True)\n        \n\n    def forward(self, x, edge_index, edge_attr):\n        out = x\n        out = F.dropout(out, p=0.6)\n        out = F.elu(self.conv1(x=out, edge_index=edge_index, edge_attr=edge_attr))\n#         out = F.dropout(out, p=0.6)\n#         out = F.elu(self.conv2(out, edge_index))\n        out = F.dropout(out, p=0.6)\n        out = self.conv2(x=out, edge_index=edge_index, edge_attr=edge_attr)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-08-28T02:07:36.693449Z","iopub.execute_input":"2023-08-28T02:07:36.693899Z","iopub.status.idle":"2023-08-28T02:07:36.704404Z","shell.execute_reply.started":"2023-08-28T02:07:36.693864Z","shell.execute_reply":"2023-08-28T02:07:36.703330Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# Graph RNN Operator","metadata":{}},{"cell_type":"code","source":"class GraphGRU(torch.nn.Module):\n    def __init__(\n        self,\n        channels: int,\n        bias: bool = True,\n    ):\n        super().__init__()\n\n        self.channels = channels\n        self.bias = bias\n        self._create_parameters_and_layers()\n\n    def _create_update_gate_parameters_and_layers(self):\n\n        self.conv_x_z = MultiGraphConv(channels = self.channels)\n\n        self.conv_h_z = MultiGraphConv(channels = self.channels)\n        \n    def _create_reset_gate_parameters_and_layers(self):\n\n        self.conv_x_r = MultiGraphConv(channels = self.channels)\n\n        self.conv_h_r = MultiGraphConv(channels = self.channels)\n\n    def _create_candidate_state_parameters_and_layers(self):\n\n        self.conv_x_h = MultiGraphConv(channels = self.channels)\n\n        self.conv_h_h = MultiGraphConv(channels = self.channels)\n\n    def _create_parameters_and_layers(self):\n        self._create_update_gate_parameters_and_layers()\n        self._create_reset_gate_parameters_and_layers()\n        self._create_candidate_state_parameters_and_layers()\n\n    def _set_hidden_state(self, X, H):\n        if H is None:\n            H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n        return H\n\n    def _calculate_update_gate(self, X, edge_index, edge_attr, H):\n        Z = self.conv_x_z(X, edge_index, edge_attr)\n        Z = Z + self.conv_h_z(H, edge_index, edge_attr)\n        Z = torch.sigmoid(Z)\n        return Z\n\n    def _calculate_reset_gate(self, X, edge_index, edge_attr, H):\n        R = self.conv_x_r(X, edge_index, edge_attr)\n        R = R + self.conv_h_r(H, edge_index, edge_attr)\n        R = torch.sigmoid(R)\n        return R\n\n    def _calculate_candidate_state(self, X, edge_index, edge_attr, H, R):\n        H_tilde = self.conv_x_h(X, edge_index, edge_attr)\n        H_tilde = H_tilde + self.conv_h_h(H * R, edge_index, edge_attr)\n        H_tilde = torch.tanh(H_tilde)\n        return H_tilde\n\n    def _calculate_hidden_state(self, Z, H, H_tilde):\n        H = Z * H + (1 - Z) * H_tilde\n        return H\n\n    def forward(\n            self,\n            X: torch.FloatTensor,\n            edge_index: torch.LongTensor,\n            edge_attr: torch.LongTensor,\n            H: torch.FloatTensor = None,\n        ) -> torch.FloatTensor:\n        H = self._set_hidden_state(X, H)\n        Z = self._calculate_update_gate(X, edge_index, edge_attr, H)\n        R = self._calculate_reset_gate(X, edge_index,edge_attr, H)\n        H_tilde = self._calculate_candidate_state(X, edge_index,edge_attr, H, R)\n        H = self._calculate_hidden_state(Z, H, H_tilde)\n        return H","metadata":{"execution":{"iopub.status.busy":"2023-08-28T00:51:41.632207Z","iopub.execute_input":"2023-08-28T00:51:41.632663Z","iopub.status.idle":"2023-08-28T00:51:41.649113Z","shell.execute_reply.started":"2023-08-28T00:51:41.632632Z","shell.execute_reply":"2023-08-28T00:51:41.648158Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Graph RNN Layer","metadata":{}},{"cell_type":"code","source":"class GraphGRULayer(torch.nn.Module):\n    def __init__(\n        self,\n        channels: int,\n        bias: bool = True,\n    ):\n        super().__init__()\n        self.gru = GraphGRU(\n            channels = channels,\n            bias = bias\n        )\n        \n        self.channels = channels\n        \n    def forward(\n        self,\n        X: torch.FloatTensor,\n        node_index: torch.LongTensor,\n        node_flag: torch.LongTensor,\n        edge_index: torch.LongTensor,\n        edge_attr: torch.LongTensor,\n        edge_flag: torch.LongTensor,\n        direction: bool # True for Forward; False for Backward\n    ) -> torch.FloatTensor:\n        \n        X_split = torch.tensor_split(X, node_flag)\n        edge_attr_split = torch.tensor_split(edge_attr, edge_flag)\n        node_index_split = torch.tensor_split(node_index, node_flag)\n        edge_index_split = torch.tensor_split(edge_index, edge_flag, dim=1)\n        \n#         print(X_split[0].device)\n#         print(node_index_split[0].device)\n#         print(edge_index_split[0].device)\n             \n        pre_hidden = None\n        \n        outs = []\n        if direction:\n            snapshot_index = range(len(X_split))\n        else:\n            snapshot_index = range(len(X_split)-1,-1,-1)\n            \n        for i_snapshot in snapshot_index:\n            _X = X_split[i_snapshot]\n            _edge_attr = edge_attr_split[i_snapshot]\n            _node_index = node_index_split[i_snapshot]\n            _edge_index = edge_index_split[i_snapshot]\n            \n            curr_hidden = torch.zeros(_X.shape[0],self.channels).to(_X.device)\n            if i_snapshot != 0:\n                pre_node_index = node_index_split[i_snapshot-1]\n                # Solution from https://discuss.pytorch.org/t/find-indexes-of-elements-from-one-tensor-that-matches-in-another-tensor/147482/2\n                _index = (node_index_split[i_snapshot-1].unsqueeze(1) == node_index_split[i_snapshot].unsqueeze(0)).nonzero() \n                curr_hidden.index_add_(0, _index[:,1], torch.index_select(pre_hidden,0, _index[:,0]))\n\n            new_hidden = self.gru(_X, _edge_index, _edge_attr, curr_hidden)\n            pre_hidden = new_hidden\n            outs.append(new_hidden)\n        if direction:\n            H = torch.cat(outs)\n        else:\n            H = torch.cat(outs[::-1])\n        return H","metadata":{"execution":{"iopub.status.busy":"2023-08-28T00:51:41.650378Z","iopub.execute_input":"2023-08-28T00:51:41.651230Z","iopub.status.idle":"2023-08-28T00:51:41.664576Z","shell.execute_reply.started":"2023-08-28T00:51:41.651199Z","shell.execute_reply":"2023-08-28T00:51:41.663906Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# STAE Model","metadata":{}},{"cell_type":"code","source":"class STAE(torch.nn.Module): # Not Heterogeneous\n    def __init__(\n        self, \n        in_channels, \n        out_channels, \n        gcn_channels,\n        embed_layers,  \n        decide_layers,\n        bidirectional=False,\n        dropout=0.2,\n    ):\n        super().__init__()\n        \n        # Encoder Embeding\n#         layers = [torch.nn.BatchNorm1d(in_channels)]\n        self.bidirectional = bidirectional\n        self.dropout = dropout\n    \n        layers = []\n        pre_h_num = in_channels\n        for h_num in embed_layers:\n            layers.append(torch.nn.Dropout(p=dropout))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,gcn_channels))\n        self.embed_net = Seq(*layers)\n                \n        self.encoder_gru = GraphGRULayer(channels=gcn_channels)\n        if self.bidirectional:\n            self.encoder_gru_back = GraphGRULayer(channels=gcn_channels)\n\n        layers = []\n        if self.bidirectional:\n            pre_h_num = gcn_channels*2\n        else:\n            pre_h_num = gcn_channels\n            \n        for h_num in decide_layers:\n            layers.append(torch.nn.Dropout(p=dropout))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,out_channels))\n#         layers.append(torch.nn.Sigmoid())\n        self.decide_net = Seq(*layers)\n        \n        # Decoder\n#         self.decoder = InnerProductDecoder()\n        layers = []\n        pre_h_num = out_channels\n        for h_num in decide_layers[::-1]:\n            layers.append(torch.nn.Dropout(p=dropout))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(torch.nn.LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,gcn_channels))\n        self.decode_decide_net = Seq(*layers)\n        \n        self.decoder_gru = GraphGRULayer(channels=gcn_channels)\n        if self.bidirectional:\n            self.decoder_gru_back = GraphGRULayer(channels=gcn_channels)\n        \n        layers = []\n        if self.bidirectional:\n            pre_h_num = gcn_channels*2\n        else:\n            pre_h_num = gcn_channels\n            \n        for h_num in embed_layers[::-1]:\n            layers.append(torch.nn.Dropout(p=dropout))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(torch.nn.LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,in_channels))\n        self.decode_embed_net = Seq(*layers)\n        \n\n    def forward(self, x, node_index, node_flag, edge_index, edge_attr, edge_flag):\n        # Encoder\n        out = self.embed_net(x)\n        \n        # GNN layer\n        h_encoder = self.encoder_gru(out, node_index, node_flag, edge_index, edge_attr, edge_flag, True) \n        \n        if self.bidirectional:\n            h_encoder_back = self.encoder_gru_back(out, node_index, node_flag, edge_index, edge_attr, edge_flag, False) \n            out = torch.concat([h_encoder,h_encoder_back],dim=1)\n        else:\n            out = h_encoder\n            \n        out = self.decide_net(out)\n        \n        out = self.decode_decide_net(out)\n \n        h_decoder = self.decoder_gru(out, node_index, node_flag, torch.flip(edge_index,dims=(0,)),edge_attr, edge_flag, True)\n    \n        if self.bidirectional:\n            h_decoder_back = self.decoder_gru_back(out, node_index, node_flag, torch.flip(edge_index,dims=(0,)),edge_attr, edge_flag, False)\n            out = torch.concat([h_decoder,h_decoder_back],dim=1)\n        else:\n            out = h_encoder\n        \n        out = self.decode_embed_net(out)\n\n        return out\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-28T00:51:41.668687Z","iopub.execute_input":"2023-08-28T00:51:41.669273Z","iopub.status.idle":"2023-08-28T00:51:41.689657Z","shell.execute_reply.started":"2023-08-28T00:51:41.669242Z","shell.execute_reply":"2023-08-28T00:51:41.688778Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Batch Signal","metadata":{}},{"cell_type":"code","source":"# Concat Batchs to from BatchSignal\nclass BatchSignal():\n    def __init__(self, signals, batch_size, seq_len):   \n        data_list_2D = [[] for _ in range(seq_len)]\n        node_index_split_list = [[] for _ in range(seq_len)]\n        base_node_index = 0\n        \n        self.batch_index = [[i_signal, 0] for i_signal in np.random.randint(low=0, high=len(signals), size=batch_size, dtype=int)]\n\n        for i_batch, (i_signal,_) in enumerate(self.batch_index):\n            signal = signals[i_signal]\n    \n            while signal.snapshot_count < seq_len:\n                new_index = np.random.randint(low=0, high=len(signals))\n                signal = signals[new_index]\n                self.batch_index[i_batch] = [new_index, 0]\n            \n            node_attr_split = signal.node_attr.tensor_split(signal.node_flag)\n            edge_attr_split = signal.edge_attr.tensor_split(signal.edge_flag)\n            node_index_split = signal.node_index.tensor_split(signal.node_flag)\n            edge_index_split = signal.edge_index.tensor_split(signal.edge_flag, dim=1)\n\n            if signal.snapshot_count-seq_len != 0:\n                _start = np.random.randint(low=0, high=signal.snapshot_count-seq_len+1)\n                self.batch_index[i_batch][1] = _start\n            else:\n                _start = 0\n\n            for i_series, i_snapshot in enumerate(range(_start, _start+seq_len)):\n                data = Data(\n                    x = node_attr_split[i_snapshot],\n                    edge_attr = edge_attr_split[i_snapshot],\n                    edge_index = edge_index_split[i_snapshot],\n                    y = signal.y[i_snapshot]\n                )\n                data_list_2D[i_series].append(data)\n                node_index_split_list[i_series].append(node_index_split[i_snapshot]+base_node_index)\n            base_node_index += signal.node_count\n\n        batch_list = [Batch.from_data_list(data_list) for data_list in data_list_2D]\n        node_index_list = [torch.cat(_node_index, dim=0) for _node_index in node_index_split_list]\n\n        node_flag_list = []\n        edge_flag_list = []\n        node_attr = []\n        edge_index = []\n\n        node_base = 0\n        edge_base = 0\n\n        for batch in batch_list:\n            node_base += batch.x.shape[0]\n            edge_base += batch.edge_index.shape[1]\n            node_flag_list.append(node_base)\n            edge_flag_list.append(edge_base)\n\n        self.node_index = torch.cat([_node_index for _node_index in node_index_list], dim=0) \n        self.node_attr = torch.cat([_batch.x for _batch in batch_list], dim=0)\n        self.edge_attr = torch.cat([_batch.edge_attr for _batch in batch_list], dim=0)\n        self.edge_index = torch.cat([_batch.edge_index for _batch in batch_list], dim=1)\n        self.y = torch.cat([_batch.y for _batch in batch_list], dim=0)\n        self.batch_index_dict = [batch._slice_dict for batch in batch_list]\n        \n        self.node_flag = torch.LongTensor(node_flag_list)[:-1]\n        self.edge_flag = torch.LongTensor(edge_flag_list)[:-1]\n    \n    def to(self, device):\n        self.node_attr = self.node_attr.to(device)\n        self.edge_attr = self.edge_attr.to(device)\n        self.node_index = self.node_index.to(device)\n        self.edge_index = self.edge_index.to(device)\n        return self","metadata":{"execution":{"iopub.status.busy":"2023-08-28T00:51:41.693686Z","iopub.execute_input":"2023-08-28T00:51:41.695216Z","iopub.status.idle":"2023-08-28T00:51:41.715160Z","shell.execute_reply.started":"2023-08-28T00:51:41.695061Z","shell.execute_reply":"2023-08-28T00:51:41.714276Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Train Loop","metadata":{}},{"cell_type":"code","source":"# train_loop\ndef train_loop(signal, model, loss_fn, optimizer, device, split_loss: bool = False):\n    model.train()\n    \n    X = signal.node_attr\n    node_index = signal.node_index\n    node_flag = signal.node_flag\n    edge_index = signal.edge_index\n    edge_attr = signal.edge_attr\n    edge_flag = signal.edge_flag\n\n    outs = model(X, node_index, node_flag, edge_index, edge_attr, edge_flag)\n\n    train_losses = torch.sqrt(torch.sum(loss_f(X, outs),dim=1))\n    total_loss = torch.mean(train_losses)\n        \n    optimizer.zero_grad()\n    total_loss.backward()\n    optimizer.step()\n    \n    if split_loss:\n        snapshot_losses = [loss.cpu().numpy() for loss in torch.tensor_split(train_losses.detach(), node_flag)]\n        return snapshot_losses\n    else:\n        return total_loss.cpu().detach().numpy()\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-28T00:51:41.716306Z","iopub.execute_input":"2023-08-28T00:51:41.716887Z","iopub.status.idle":"2023-08-28T00:51:41.727623Z","shell.execute_reply.started":"2023-08-28T00:51:41.716850Z","shell.execute_reply":"2023-08-28T00:51:41.726714Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Test Loop","metadata":{}},{"cell_type":"code","source":"# test_loop\ndef test_loop(signal, model, loss_fn, optimizer, device, split_loss: bool = False):\n    with torch.no_grad():\n        X = signal.node_attr\n        node_index = signal.node_index\n        node_flag = signal.node_flag\n        edge_index = signal.edge_index\n        edge_attr = signal.edge_attr\n        edge_flag = signal.edge_flag\n\n        outs = model(X, node_index, node_flag, edge_index, edge_attr, edge_flag)\n\n        train_losses = torch.sqrt(torch.sum(loss_f(X, outs),dim=1))\n        total_loss = torch.mean(train_losses)\n        snapshot_losses = [loss.cpu().numpy() for loss in torch.tensor_split(train_losses.detach(), node_flag)]\n    \n        if split_loss:\n            snapshot_losses = [loss.cpu().numpy() for loss in torch.tensor_split(train_losses.detach(), node_flag)]\n            return snapshot_losses\n        else:\n            return total_loss.cpu().detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2023-08-28T00:51:41.729682Z","iopub.execute_input":"2023-08-28T00:51:41.730469Z","iopub.status.idle":"2023-08-28T00:51:41.740966Z","shell.execute_reply.started":"2023-08-28T00:51:41.730387Z","shell.execute_reply":"2023-08-28T00:51:41.740152Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation Function","metadata":{}},{"cell_type":"code","source":"def get_graph_anomaly_threshold(batch_signal, batch_node_losses,q=95):\n    batch_index_dict = batch_signal.batch_index_dict\n    graph_losses = []\n    for i_series in range(MIN_LEN):\n        loss_split = np.split(batch_node_losses[i_series], batch_index_dict[i_series]['x'][1:-1])\n        graph_losses += [np.sum(node_losses) for node_losses in loss_split]\n        \n    return np.percentile(graph_losses,q)\n\ndef batch_graph_eval_func(batch_signal, batch_node_losses, threshold):\n    batch_index_dict = batch_signal.batch_index_dict\n    y_pred = []\n    for i_series in range(MIN_LEN):\n        loss_split = np.split(batch_node_losses[i_series], batch_index_dict[i_series]['x'][1:-1])\n        for losses in loss_split:\n            y_pred.append(int(np.sum(losses.reshape(-1, 1)) > threshold))\n    tn, fp, fn, tp = confusion_matrix(batch_signal.y, y_pred, labels=[0,1]).ravel()\n    return tn, fp, fn, tp\n\ndef batch_graph_eval_func_2(batch_signal, batch_node_losses):\n    batch_index_dict = batch_signal.batch_index_dict\n    y_loss = []\n    for i_series in range(MIN_LEN):\n        loss_split = np.split(batch_node_losses[i_series], batch_index_dict[i_series]['x'][1:-1])\n        for losses in loss_split:\n            y_loss.append(np.mean(losses.reshape(-1, 1)))\n            \n    precision_list, recall_list, thresholds = precision_recall_curve(batch_signal.y,y_loss)\n    f1_list = []\n    for precision, recall in zip(precision_list, recall_list):\n        if precision == 0 and recall == 0:\n            f1_list.append(0)\n        else:\n            f1_list.append(2 * (precision * recall) / (precision + recall))\n        \n    precision = precision_list[np.nanargmax(f1_list)]\n    recall = recall_list[np.nanargmax(f1_list)]\n    f1 = f1_list[np.nanargmax(f1_list)]\n    roc_auc = roc_auc_score(batch_signal.y,y_loss)\n    \n    return precision, recall, f1, roc_auc\n\ndef single_graph_eval_func(signal, node_losses, threshold):\n    y_pred = []\n    for losses in node_losses:\n        y_pred.append(int(np.sum(losses.reshape(-1, 1)) > threshold))\n    tn, fp, fn, tp = confusion_matrix(signal.y, y_pred, labels=[0,1]).ravel()\n    return tn, fp, fn, tp\n\ndef single_graph_eval_func_2(signals, node_losses_list):\n    y_true = np.concatenate([signal.y for signal in signals])\n    y_loss = []\n    for losses in node_losses_list:\n        y_loss.append(np.mean(losses.reshape(-1, 1)))\n            \n    precision_list, recall_list, thresholds = precision_recall_curve(y_true,y_loss)\n    f1_list = []\n    for precision, recall in zip(precision_list, recall_list):\n        if precision == 0 and recall == 0:\n            f1_list.append(0)\n        else:\n            f1_list.append(2 * (precision * recall) / (precision + recall))\n        \n    precision = precision_list[np.nanargmax(f1_list)]\n    recall = recall_list[np.nanargmax(f1_list)]\n    f1 = f1_list[np.nanargmax(f1_list)]\n    roc_auc = roc_auc_score(y_true,y_loss)\n    \n    return precision, recall, f1, roc_auc","metadata":{"execution":{"iopub.status.busy":"2023-08-28T00:51:41.742467Z","iopub.execute_input":"2023-08-28T00:51:41.743282Z","iopub.status.idle":"2023-08-28T00:51:41.762372Z","shell.execute_reply.started":"2023-08-28T00:51:41.743228Z","shell.execute_reply":"2023-08-28T00:51:41.761444Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Train Function","metadata":{}},{"cell_type":"code","source":"def train_function(num_epoch, val_interval=100, start_val=0, save=False, save_dir=None):\n    global GLOBAL_EPOCH\n    \n    history = {}\n    history['train'] = {\n        \"loss\":[],\n        \"precision\":[],\n        \"recall\":[],\n        \"f1\":[],\n        \"roc_auc\":[],\n        \"time\":[]\n    }\n    history['val'] = {\n        \"loss\":[],\n        \"precision\":[],\n        \"recall\":[],\n        \"f1\":[],\n        \"roc_auc\":[],\n    }\n    history['save'] = []\n    \n    batch_signal = BatchSignal(signals=signals_train, batch_size=BATCH_SIZE, seq_len=MIN_LEN).to(device)\n    for i_epoch in range(1,num_epoch+1):\n        _start = time.time()    \n#         if i_epoch % 10: \n        del batch_signal\n        batch_signal = BatchSignal(signals=signals_train, batch_size=BATCH_SIZE, seq_len=MIN_LEN).to(device)\n        train_losses = train_loop(batch_signal, model, loss_f, optimizer, device, split_loss=False)\n        _end = time.time()\n        if i_epoch >= start_val and i_epoch % val_interval == 0:\n            \n#             batch_signal = BatchSignal(signals=signals_train, batch_size=BATCH_SIZE, seq_len=MIN_LEN).to(device)        \n#             node_losses_list_train = test_loop(batch_signal, model, loss_f, optimizer, device, split_loss=True)\n#             precision_train, recall_train, f1_train, roc_auc_train = batch_graph_eval_func_2(batch_signal, node_losses_list_train)\n            \n            f1_list = []\n            roc_auc_list = []\n            for _ in range(5):\n                batch_signal_val = BatchSignal(signals=signals_val, batch_size=BATCH_SIZE, seq_len=MIN_LEN).to(device)\n                node_losses_list_val = test_loop(batch_signal_val, model, loss_f, optimizer, device, split_loss=True)\n                precision_val, recall_val, f1_val, roc_auc_val = batch_graph_eval_func_2(batch_signal_val, node_losses_list_val)\n                f1_list.append(f1_val)\n                roc_auc_list.append(roc_auc_val)\n#             train_losses = np.concatenate(node_losses_list_train)\n            val_losses = np.concatenate(node_losses_list_val)\n            \n\n            history['train']['time'].append(_end-_start)\n            \n            history['val']['loss'].append(np.mean(val_losses))\n            history['val']['f1'].append(np.mean(f1_val))\n            history['val']['roc_auc'].append(np.mean(roc_auc_val))\n                \n            print(f\"{i_epoch+GLOBAL_EPOCH}/{num_epoch+GLOBAL_EPOCH}: cost {_end-_start:.4f}s train loss {np.mean(train_losses):.4f} val loss {np.mean(val_losses):.4f}\")\n            t = Texttable()\n            t.add_rows([\n                ['', 'F1', 'AUC_ROC'], \n#                 ['Train', precision_train, recall_train, f1_train, roc_auc_train], \n                ['Val', f1_val, roc_auc_val]])\n            print(t.draw())\n            \n            if save:\n                if save_dir is not None:\n                    os.makedirs(save_dir,exist_ok=True)\n                    path = os.path.join(save_dir, f\"{i_epoch+GLOBAL_EPOCH}.pt\")\n                else:\n                    path =  f\"{i_epoch+GLOBAL_EPOCH}.pt\"\n                torch.save(model.state_dict(), path)\n                history['save'].append(path)\n        else:\n            if i_epoch % 50 == 0:\n                history['train']['time'].append(_end-_start)\n                print(f\"{i_epoch+GLOBAL_EPOCH}/{num_epoch+GLOBAL_EPOCH}: cost {_end-_start:.4f}s train loss {np.mean(train_losses):.4f}\")\n    GLOBAL_EPOCH += num_epoch\n    return history","metadata":{"execution":{"iopub.status.busy":"2023-08-28T00:51:41.765642Z","iopub.execute_input":"2023-08-28T00:51:41.766034Z","iopub.status.idle":"2023-08-28T00:51:41.782440Z","shell.execute_reply.started":"2023-08-28T00:51:41.765981Z","shell.execute_reply":"2023-08-28T00:51:41.781542Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"IN_CHANNELS = signals_train[0].node_attr.shape[1]\nMIN_LEN=10\nBATCH_SIZE = 30\nGLOBAL_EPOCH = 0\n# print(lr, dropout)\nmodel = STAE(\n    in_channels=IN_CHANNELS, \n    out_channels=32, \n    gcn_channels=128,\n    embed_layers=[128,512,256],\n    decide_layers=[256,128,128,64],\n    dropout=0.2\n)\n\nloss_f = torch.nn.MSELoss(reduction = 'none')\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nmodel = model.to(device)\nloss_f = loss_f.to(device)\n\nhistory = train_function(1000,100,0,save=True)\nraise","metadata":{"execution":{"iopub.status.busy":"2023-08-28T02:07:41.980598Z","iopub.execute_input":"2023-08-28T02:07:41.981377Z","iopub.status.idle":"2023-08-28T02:17:49.216164Z","shell.execute_reply.started":"2023-08-28T02:07:41.981343Z","shell.execute_reply":"2023-08-28T02:17:49.214800Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"50/1000: cost 0.5750s train loss 0.2272\n100/1000: cost 0.5974s train loss 0.1144 val loss 0.1117\n+-----+-------+---------+\n|     |  F1   | AUC_ROC |\n+=====+=======+=========+\n| Val | 0.085 | 0.543   |\n+-----+-------+---------+\n150/1000: cost 0.5684s train loss 0.0572\n200/1000: cost 0.5715s train loss 0.0465 val loss 0.0432\n+-----+-------+---------+\n|     |  F1   | AUC_ROC |\n+=====+=======+=========+\n| Val | 0.200 | 0.825   |\n+-----+-------+---------+\n250/1000: cost 0.6308s train loss 0.0390\n300/1000: cost 0.5890s train loss 0.0405 val loss 0.0360\n+-----+-------+---------+\n|     |  F1   | AUC_ROC |\n+=====+=======+=========+\n| Val | 0.200 | 0.783   |\n+-----+-------+---------+\n350/1000: cost 0.5748s train loss 0.0375\n400/1000: cost 0.5331s train loss 0.0403 val loss 0.0338\n+-----+-------+---------+\n|     |  F1   | AUC_ROC |\n+=====+=======+=========+\n| Val | 0.171 | 0.752   |\n+-----+-------+---------+\n450/1000: cost 0.5607s train loss 0.0353\n500/1000: cost 0.5837s train loss 0.0315 val loss 0.0321\n+-----+-------+---------+\n|     |  F1   | AUC_ROC |\n+=====+=======+=========+\n| Val | 0.061 | 0.716   |\n+-----+-------+---------+\n550/1000: cost 0.5866s train loss 0.0342\n600/1000: cost 0.5448s train loss 0.0332 val loss 0.0304\n+-----+-------+---------+\n|     |  F1   | AUC_ROC |\n+=====+=======+=========+\n| Val | 0.141 | 0.811   |\n+-----+-------+---------+\n650/1000: cost 0.5771s train loss 0.0317\n700/1000: cost 0.5867s train loss 0.0284 val loss 0.0333\n+-----+-------+---------+\n|     |  F1   | AUC_ROC |\n+=====+=======+=========+\n| Val | 0.173 | 0.724   |\n+-----+-------+---------+\n750/1000: cost 0.5822s train loss 0.0301\n800/1000: cost 0.5772s train loss 0.0278 val loss 0.0255\n+-----+-------+---------+\n|     |  F1   | AUC_ROC |\n+=====+=======+=========+\n| Val | 0.217 | 0.852   |\n+-----+-------+---------+\n850/1000: cost 0.5716s train loss 0.0282\n900/1000: cost 0.8513s train loss 0.0248 val loss 0.0231\n+-----+-------+---------+\n|     |  F1   | AUC_ROC |\n+=====+=======+=========+\n| Val | 0.205 | 0.678   |\n+-----+-------+---------+\n950/1000: cost 0.5704s train loss 0.0250\n1000/1000: cost 0.5765s train loss 0.0239 val loss 0.0238\n+-----+-------+---------+\n|     |  F1   | AUC_ROC |\n+=====+=======+=========+\n| Val | 0.141 | 0.614   |\n+-----+-------+---------+\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m loss_f \u001b[38;5;241m=\u001b[39m loss_f\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m history \u001b[38;5;241m=\u001b[39m train_function(\u001b[38;5;241m1000\u001b[39m,\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m0\u001b[39m,save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"],"ename":"RuntimeError","evalue":"No active exception to reraise","output_type":"error"}]},{"cell_type":"code","source":"np.mean(history['train']['time'])","metadata":{"execution":{"iopub.status.busy":"2023-08-28T02:51:35.324878Z","iopub.execute_input":"2023-08-28T02:51:35.325787Z","iopub.status.idle":"2023-08-28T02:51:35.334351Z","shell.execute_reply.started":"2023-08-28T02:51:35.325725Z","shell.execute_reply":"2023-08-28T02:51:35.333299Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"0.5904504418373108"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}