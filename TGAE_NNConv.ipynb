{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nuse_gpu = torch.cuda.is_available()\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:13:27.624935Z","iopub.execute_input":"2023-07-26T22:13:27.625406Z","iopub.status.idle":"2023-07-26T22:13:27.632366Z","shell.execute_reply.started":"2023-07-26T22:13:27.625376Z","shell.execute_reply":"2023-07-26T22:13:27.631198Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Initialize for CPU & GPU","metadata":{}},{"cell_type":"code","source":"if use_gpu:\n    !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric --no-index --find-links=file:///kaggle/input/torch-geometric\n#     !pip install torch_geometric_temporal  \nelse:\n#     !pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n    !pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n    !pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n    !pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n    !pip install git+https://github.com/pyg-team/pytorch_geometric.git\n#     !pip install torch_geometric_temporal\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-26T22:13:27.634502Z","iopub.execute_input":"2023-07-26T22:13:27.634900Z","iopub.status.idle":"2023-07-26T22:14:36.416984Z","shell.execute_reply.started":"2023-07-26T22:13:27.634869Z","shell.execute_reply":"2023-07-26T22:14:36.415593Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\nRequirement already satisfied: torch-scatter in /opt/conda/lib/python3.10/site-packages (2.1.1+pt20cpu)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\nRequirement already satisfied: torch-sparse in /opt/conda/lib/python3.10/site-packages (0.6.17+pt20cpu)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-sparse) (1.10.1)\nRequirement already satisfied: numpy<1.27.0,>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scipy->torch-sparse) (1.23.5)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\nRequirement already satisfied: torch-cluster in /opt/conda/lib/python3.10/site-packages (1.6.1+pt20cpu)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-cluster) (1.10.1)\nRequirement already satisfied: numpy<1.27.0,>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scipy->torch-cluster) (1.23.5)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting git+https://github.com/pyg-team/pytorch_geometric.git\n  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-_53ed48c\n  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-_53ed48c\n  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 02cc18d9d6841ecda4eb61eebb48b86f1aaae477\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (4.64.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (1.23.5)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (1.10.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (2.28.2)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (3.0.9)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (1.2.2)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (5.9.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch_geometric==2.4.0) (2.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric==2.4.0) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric==2.4.0) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric==2.4.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric==2.4.0) (2023.5.7)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch_geometric==2.4.0) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch_geometric==2.4.0) (3.1.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"from torch.profiler import profile, record_function, ProfilerActivity\nimport torch.autograd.profiler as profiler","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:14:36.420136Z","iopub.execute_input":"2023-07-26T22:14:36.420674Z","iopub.status.idle":"2023-07-26T22:14:36.430998Z","shell.execute_reply.started":"2023-07-26T22:14:36.420614Z","shell.execute_reply":"2023-07-26T22:14:36.428764Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport re\nimport json\nfrom scipy.special import perm\nfrom itertools import combinations,chain\nfrom typing import List, Union\nfrom torch_geometric.data import Data\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport matplotlib.pyplot as plt\nimport pickle\nimport time\nfrom torch import nn\nfrom torch.nn import Linear as Lin\nfrom torch.nn import ReLU\nfrom torch.nn import Sequential as Seq\nimport torch.nn.functional as F\nfrom torch_geometric.nn import NNConv\nfrom torch import autograd\n\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:14:36.432961Z","iopub.execute_input":"2023-07-26T22:14:36.433342Z","iopub.status.idle":"2023-07-26T22:14:36.469192Z","shell.execute_reply.started":"2023-07-26T22:14:36.433311Z","shell.execute_reply":"2023-07-26T22:14:36.468152Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# DataLoader","metadata":{}},{"cell_type":"code","source":"Edge_Flag = List[Union[np.ndarray, None]]\nEdge_Index = List[Union[np.ndarray, None]]\nEdge_Attr = List[Union[np.ndarray, None]]\n\nNode_Flag = List[Union[np.ndarray, None]]\nNode_Index = List[Union[np.ndarray, None]]\nNode_Attr = List[Union[np.ndarray, None]]\nAdditional_Attr = List[np.ndarray]\n\n\n\nclass GraphSignal(object):\n    # dynamic node static node attr dynamic edge and edge attr\n    def __init__(\n        self,\n        edge_flag: Edge_Flag,\n        edge_index: Edge_Index,\n        edge_attr: Edge_Attr,\n        node_flag: Node_Flag,\n        node_index: Node_Index,\n        node_attr: Node_Attr,\n        ts_list: List,\n    ):\n        \n        self.edge_flag = torch.LongTensor(edge_flag)\n        self.edge_index = torch.LongTensor(edge_index).T.to(device)\n        self.edge_attr = edge_attr\n        self.node_flag = torch.LongTensor(node_flag)\n        self.node_index = torch.LongTensor(node_index).to(device)\n        self.node_attr = node_attr\n        self.ts_list = ts_list\n        self.edge_attr_encoded = None\n        self.node_attr_encoded = None\n        \n        self._set_snapshot_count()\n\n    def _set_snapshot_count(self):\n        self.snapshot_count = len(self.edge_flag)\n    \n    def encode_edge_attr(self, enocder):\n        self.edge_attr_encoded = torch.FloatTensor(enocder.transform(self.edge_attr)).to(device)\n    \n    def encode_node_attr(self, enocder):\n        self.node_attr_encoded = torch.FloatTensor(enocder.transform(self.node_attr)).to(device)\n        \n    def _get_edge_index(self, time_index: int):\n        if time_index == 0:\n            _start = 0\n        else:\n            _start = self.edge_flag[time_index-1]\n        _end = self.edge_flag[time_index]\n        _edge_index = self.edge_index[:,_start:_end]\n        return _edge_index\n\n    # def _get_edge_weight(self, time_index: int):\n    #     if self.edge_weights[time_index] is None:\n    #         return self.edge_weights[time_index]\n    #     else:\n    #         return torch.FloatTensor(self.edge_weights[time_index])\n\n    def _get_edge_attr(self, time_index: int):\n        if self.edge_attr_encoded is None:\n            print(\"Edge Attr Need to be Encoded!\")\n            raise\n        if time_index == 0:\n            _start = 0\n        else:\n            _start = self.edge_flag[time_index-1]\n        _end = self.edge_flag[time_index]\n        _edge_attr = self.edge_attr_encoded[_start:_end]\n        return _edge_attr\n    \n    def _get_node_index_attr(self, time_index: int):\n        if self.node_attr_encoded is None:\n            print(\"Node Attr Need to be Encoded!\")\n            raise\n        if time_index == 0:\n            _start = 0\n        else:\n            _start = self.node_flag[time_index-1]\n        _end = self.node_flag[time_index]\n        _node_index = self.node_index[_start:_end]\n        _node_attr = self.node_attr_encoded[_node_index]\n        return _node_index,_node_attr\n    \n    def _get_timestamp(self, time_index: int):\n        _timestamp = self.ts_list[time_index]\n        return _timestamp\n\n\n    def __getitem__(self, time_index: int):\n        edge_index = self._get_edge_index(time_index)\n        edge_attr = self._get_edge_attr(time_index)\n        node_index,node_attr = self._get_node_index_attr(time_index)\n        _timestamp = self._get_timestamp(time_index)\n\n        snapshot = Data(\n            edge_index=edge_index,\n            edge_attr=edge_attr,\n            node_index=node_index,\n            node_attr=node_attr,\n            timestamp = _timestamp\n        )\n        return snapshot\n\n    def __next__(self):\n        if self.t < self.snapshot_count:\n            snapshot = self[self.t]\n            self.t = self.t + 1\n            return snapshot\n        else:\n            self.t = 0\n            raise StopIteration\n\n    def __iter__(self):\n        self.t = 0\n        return self\n    \n    def __len__(self):\n        return self.snapshot_count\n\n\nclass GraphDatasetLoader(object):\n    def __init__(self,input_path=\"\"):\n        self.input_path = input_path\n        self._read_data()\n    \n    def _read_data(self):\n        self._dataset = np.load(self.input_path)\n\n    def get_dataset(self): # -> DynamicGraphTemporalSignal:\n        dataset = GraphSignal(\n            edge_flag = self._dataset['edge_flag'],\n            edge_index = self._dataset['edge_index'],\n            edge_attr = self._dataset['edge_attr'],\n            node_flag = self._dataset['node_flag'],\n            node_index = self._dataset['node_index'],\n            node_attr = self._dataset['node_attr'],\n            ts_list = self._dataset['timestamp']\n        )\n        return dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:14:36.472150Z","iopub.execute_input":"2023-07-26T22:14:36.472712Z","iopub.status.idle":"2023-07-26T22:14:36.502426Z","shell.execute_reply.started":"2023-07-26T22:14:36.472679Z","shell.execute_reply":"2023-07-26T22:14:36.501281Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"## MultiNNConv","metadata":{}},{"cell_type":"code","source":"class MultiNNConv(torch.nn.Module):\n    def __init__(self, in_channels, out_channels, edge_channels, conv_layers, edge_layers, lin_layers):\n        super().__init__()\n        \n        def _create_edge_net(edge_out_channels):\n            edge_net = Seq()\n            pre_size = edge_channels\n            for size in edge_layers:\n                edge_net.append(Lin(pre_size,size))\n                edge_net.append(ReLU())\n                pre_size = size\n            edge_net.append(Lin(pre_size,edge_out_channels))\n            return edge_net\n        \n        self.convs = nn.ModuleList()\n        pre_size = in_channels\n        for size in conv_layers:\n            edge_net = _create_edge_net(pre_size*size)\n            self.convs.append(NNConv(pre_size, size, edge_net, aggr='mean'))\n            pre_size = size\n        \n        self.lin_net = Seq()\n        for size in lin_layers[:-1]:\n            self.lin_net.append(Lin(pre_size,size))\n            pre_size = size\n        self.lin_net.append(ReLU())\n        self.lin_net.append(Lin(pre_size,out_channels))\n\n    def forward(self, x, edge_index, edge_attr):\n        out = x\n        with profiler.record_function(\"Graph Conv\"):\n            for conv in self.convs:\n                out = conv(\n                    x=out,\n                    edge_index=edge_index,\n                    edge_attr=edge_attr,\n                )\n        out = self.lin_net(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:14:36.503996Z","iopub.execute_input":"2023-07-26T22:14:36.504473Z","iopub.status.idle":"2023-07-26T22:14:36.520279Z","shell.execute_reply.started":"2023-07-26T22:14:36.504429Z","shell.execute_reply":"2023-07-26T22:14:36.519142Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Graph GRU Unit","metadata":{}},{"cell_type":"code","source":"class GraphGRU(torch.nn.Module):\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        edge_channels: int,\n        conv_layers: List,\n        edge_layers: List,\n        lin_layers: List,\n        bias: bool = True,\n    ):\n        super().__init__()\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.edge_channels = edge_channels\n        self.conv_layers = conv_layers\n        self.edge_layers = edge_layers\n        self.lin_layers = lin_layers\n        self.bias = bias\n        self._create_parameters_and_layers()\n\n    def _create_update_gate_parameters_and_layers(self):\n\n        self.conv_x_z = MultiNNConv(\n            in_channels = self.in_channels,\n            out_channels = self.out_channels,\n            edge_channels = self.edge_channels,\n            conv_layers = self.conv_layers,\n            edge_layers = self.edge_layers,\n            lin_layers = self.lin_layers,\n        )\n\n        self.conv_h_z = MultiNNConv(\n            in_channels = self.out_channels,\n            out_channels = self.out_channels,\n            edge_channels = self.edge_channels,\n            conv_layers = self.conv_layers,\n            edge_layers = self.edge_layers,\n            lin_layers = self.lin_layers,\n        )\n        \n    def _create_reset_gate_parameters_and_layers(self):\n\n        self.conv_x_r = MultiNNConv(\n            in_channels = self.in_channels,\n            out_channels = self.out_channels,\n            edge_channels = self.edge_channels,\n            conv_layers = self.conv_layers,\n            edge_layers = self.edge_layers,\n            lin_layers = self.lin_layers,\n        )\n\n        self.conv_h_r = MultiNNConv(\n            in_channels = self.out_channels,\n            out_channels = self.out_channels,\n            edge_channels = self.edge_channels,\n            conv_layers = self.conv_layers,\n            edge_layers = self.edge_layers,\n            lin_layers = self.lin_layers,\n        )\n\n    def _create_candidate_state_parameters_and_layers(self):\n\n        self.conv_x_h = MultiNNConv(\n            in_channels = self.in_channels,\n            out_channels = self.out_channels,\n            edge_channels = self.edge_channels,\n            conv_layers = self.conv_layers,\n            edge_layers = self.edge_layers,\n            lin_layers = self.lin_layers,\n        )\n\n        self.conv_h_h = MultiNNConv(\n            in_channels = self.out_channels,\n            out_channels = self.out_channels,\n            edge_channels = self.edge_channels,\n            conv_layers = self.conv_layers,\n            edge_layers = self.edge_layers,\n            lin_layers = self.lin_layers,\n        )\n\n    def _create_parameters_and_layers(self):\n        self._create_update_gate_parameters_and_layers()\n        self._create_reset_gate_parameters_and_layers()\n        self._create_candidate_state_parameters_and_layers()\n\n    def _set_hidden_state(self, X, H):\n        if H is None:\n            H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n        return H\n\n    def _calculate_update_gate(self, X, edge_index, edge_attr, H):\n        Z = self.conv_x_z(X, edge_index, edge_attr)\n        Z = Z + self.conv_h_z(H, edge_index, edge_attr)\n        Z = torch.sigmoid(Z)\n        return Z\n\n    def _calculate_reset_gate(self, X, edge_index, edge_attr, H):\n        R = self.conv_x_r(X, edge_index, edge_attr)\n        R = R + self.conv_h_r(H, edge_index, edge_attr)\n        R = torch.sigmoid(R)\n        return R\n\n    def _calculate_candidate_state(self, X, edge_index, edge_attr, H, R):\n        H_tilde = self.conv_x_h(X, edge_index, edge_attr)\n        H_tilde = H_tilde + self.conv_h_h(H * R, edge_index, edge_attr)\n        H_tilde = torch.tanh(H_tilde)\n        return H_tilde\n\n    def _calculate_hidden_state(self, Z, H, H_tilde):\n        H = Z * H + (1 - Z) * H_tilde\n        return H\n\n    def forward(\n            self,\n            X: torch.FloatTensor,\n            edge_index: torch.LongTensor,\n            edge_attr: torch.FloatTensor,\n            H: torch.FloatTensor = None,\n        ) -> torch.FloatTensor:\n            H = self._set_hidden_state(X, H)\n            Z = self._calculate_update_gate(X, edge_index, edge_attr, H)\n            R = self._calculate_reset_gate(X, edge_index, edge_attr, H)\n            H_tilde = self._calculate_candidate_state(X, edge_index, edge_attr, H, R)\n            H = self._calculate_hidden_state(Z, H, H_tilde)\n            return H","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:14:36.521978Z","iopub.execute_input":"2023-07-26T22:14:36.522336Z","iopub.status.idle":"2023-07-26T22:14:36.547755Z","shell.execute_reply.started":"2023-07-26T22:14:36.522307Z","shell.execute_reply":"2023-07-26T22:14:36.546198Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Graph GRU Layer and Global Hidden Function","metadata":{}},{"cell_type":"code","source":"def create_hidden(num_node, out_channels):\n#     hidden_global = torch.FloatTensor(np.zeros([num_node,out_channels])).to(device)\n    hidden =torch.zeros([num_node,out_channels], dtype=torch.float).to(device)\n    return hidden\n\ndef select_hidden(hidden, index):\n#     h = hidden_global[index] #REGULAR INDEXING\n    h = hidden.index_select(dim=0, index=index) #INDEX SELECT\n    return h\n\n# TODO: Aggregation of hidden and cell\ndef update_hidden(hidden, h, index):\n    # hidden_global[index] = h.detach() #REGULAR INDEXING\n    # for key,value in mapping.items():\n    #     hidden_global[value] = h[key] \n    hidden.index_copy_(dim=0, index=index, source=h.detach())        \n\nclass GraphGRULayer(torch.nn.Module):\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        edge_channels: int,\n        conv_layers: List,\n        edge_layers: List,\n        lin_layers: List,\n        bias: bool = True,\n    ):\n        super().__init__()\n        self.gru = GraphGRU(\n            in_channels = in_channels,\n            out_channels = out_channels,\n            edge_channels = edge_channels,\n            conv_layers = conv_layers,\n            edge_layers = edge_layers,\n            lin_layers = lin_layers,\n            bias = bias\n        )\n        \n        self.out_channels = out_channels\n        \n    def forward(\n        self,\n        X: torch.FloatTensor,\n        node_index: torch.LongTensor,\n        node_flag: torch.LongTensor,\n        edge_index: torch.LongTensor,\n        edge_attr: torch.FloatTensor,\n        edge_flag: torch.LongTensor,\n        num_node: int\n    ) -> torch.FloatTensor:\n        \n        X_split = torch.tensor_split(X, node_flag)\n        node_index_split = torch.tensor_split(node_index, node_flag)\n        edge_index_split = torch.tensor_split(edge_index, edge_flag, dim=1)\n        edge_attr_split = torch.tensor_split(edge_attr, edge_flag)\n        \n        hidden = create_hidden(num_node, self.out_channels)\n        \n        outs = []\n        for _X,_node_index,_edge_index,_edge_attr in zip(X_split,node_index_split,edge_index_split,edge_attr_split):\n            _hidden = select_hidden(hidden, _node_index)\n            _new_hidden = self.gru(_X, _edge_index, _edge_attr, _hidden)\n            update_hidden(hidden, _new_hidden, _node_index)\n            outs.append(_new_hidden)\n        \n        H = torch.cat(outs)\n        return H","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:14:36.549961Z","iopub.execute_input":"2023-07-26T22:14:36.550439Z","iopub.status.idle":"2023-07-26T22:14:36.568132Z","shell.execute_reply.started":"2023-07-26T22:14:36.550397Z","shell.execute_reply":"2023-07-26T22:14:36.566820Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## TGAE","metadata":{}},{"cell_type":"code","source":"class TGAE(torch.nn.Module): # Not Heterogeneous\n    def __init__(\n        self, \n        in_channels, \n        out_channels, \n        edge_channels, \n        embed_layers, \n        gru_out_channels, \n        decide_layers,\n        gru_conv_layers, \n        gru_edge_layers, \n        gru_lin_layers\n    ):\n        super(TGAE, self).__init__()\n        \n        # Encoder\n        layers = []\n        pre_h_num = in_channels\n        for h_num in embed_layers[:-1]:\n#             layers.append(torch.nn.Dropout(p=0.2))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(torch.nn.LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,embed_layers[-1]))\n        self.encoder_embedding_net = Seq(*layers)\n        \n        self.encoder_gru = GraphGRULayer(\n            in_channels=embed_layers[-1],\n            out_channels=gru_out_channels,\n            edge_channels=edge_channels,\n            conv_layers=gru_conv_layers,\n            edge_layers=gru_edge_layers,\n            lin_layers=gru_lin_layers,\n        )\n\n        layers = []\n        pre_h_num = gru_out_channels\n        for h_num in decide_layers:\n#             layers.append(torch.nn.Dropout(p=0.2))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(torch.nn.LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,out_channels))\n        self.encoder_deciding_net = Seq(*layers)\n        \n        # Decoder\n        layers = []\n        pre_h_num = out_channels\n        for h_num in decide_layers[::-1]:\n            layers.append(torch.nn.Dropout(p=0.2))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(torch.nn.LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,gru_out_channels))\n        self.decoder_deciding_net = Seq(*layers)\n        \n        self.decoder_gru = GraphGRULayer(\n            in_channels=gru_out_channels,\n            out_channels=embed_layers[-1],\n            edge_channels=edge_channels,\n            conv_layers=gru_conv_layers,\n            edge_layers=gru_edge_layers,\n            lin_layers=gru_lin_layers,\n        )\n        \n        layers = []\n        pre_h_num = embed_layers[-1]\n        for h_num in embed_layers[:-1][::-1]:\n            layers.append(torch.nn.Dropout(p=0.2))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(torch.nn.LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,in_channels))\n        self.decoder_embedding_net = Seq(*layers)\n        \n\n    def forward(self, x, node_index, node_flag, edge_index, edge_attr, edge_flag, num_node):\n        # Encoder\n        out = self.encoder_embedding_net(x)\n        \n        # GNN layer\n        with profiler.record_function(\"gru encoder\"):\n            h_encoder = self.encoder_gru(out, node_index, node_flag, edge_index, edge_attr, edge_flag, num_node) \n        \n        out = self.encoder_deciding_net(h_encoder)\n\n        out = self.decoder_deciding_net(out)\n        \n        # TODO Reverse Edge Index \n        with profiler.record_function(\"gru decoder\"):\n            h_decoder = self.decoder_gru(out, node_index, node_flag, torch.flip(edge_index,dims=(0,)), edge_attr, edge_flag, num_node)\n        \n        out = self.decoder_embedding_net(h_decoder)\n\n        return out\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:14:36.570255Z","iopub.execute_input":"2023-07-26T22:14:36.570693Z","iopub.status.idle":"2023-07-26T22:14:36.593129Z","shell.execute_reply.started":"2023-07-26T22:14:36.570661Z","shell.execute_reply":"2023-07-26T22:14:36.591708Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"## Read Data","metadata":{}},{"cell_type":"code","source":"data_dir_0 = '/kaggle/input/dissertation-data'\ndata_dir_1 = '2021-09-11-umbrella-experiment-32run-fran'\n\n\nsignals = []\ny = []\nwith open(os.path.join(data_dir_0, data_dir_1, \"annotated.json\")) as f:\n    annotated_dict = json.load(f)\n\nfor data_dir_2 in os.listdir(os.path.join(data_dir_0, data_dir_1)):\n    if data_dir_2 == \"annotated.json\":\n        continue\n    r = re.compile(\".*.npz\")\n    graph_files = list(filter(r.match, os.listdir(os.path.join(data_dir_0, data_dir_1, data_dir_2))))\n\n    if len(graph_files) > 1:\n        print(\"Multiple Graph Files!\")\n        raise\n    if len(graph_files) == 0:\n        print(\"Not Found Graph File!\")\n        raise\n\n    dataloader = GraphDatasetLoader(os.path.join(data_dir_0, data_dir_1, data_dir_2, graph_files[0]))\n    signal = dataloader.get_dataset()\n    signals.append(signal)\n    y.append(annotated_dict[data_dir_2])\n\n# split train and test dataset\nsignals_train, signals_test, y_train, y_test = train_test_split(signals, y, test_size=0.2, random_state=1)\nsignals_train, signals_val, y_train, y_val = train_test_split(signals_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-07-26T22:14:36.595031Z","iopub.execute_input":"2023-07-26T22:14:36.595450Z","iopub.status.idle":"2023-07-26T22:14:37.083801Z","shell.execute_reply.started":"2023-07-26T22:14:36.595417Z","shell.execute_reply":"2023-07-26T22:14:37.082932Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"node_attr_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\nnode_attr_encoder = node_attr_encoder.fit(np.concatenate([sample.node_attr for sample in signals_train]))\n\nedge_attr_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\nedge_attr_encoder = edge_attr_encoder.fit(np.concatenate([sample.edge_attr for sample in signals_train]))\n\nfor signal in signals_train:\n    signal.encode_node_attr(node_attr_encoder)\n    signal.encode_edge_attr(edge_attr_encoder)\n\nX_train = []\nfor signal in signals_train:\n#     X_train.append(list(signal))\n    X_train.append(signal.node_attr_encoded.index_select(dim=0,index=signal.node_index))\n    \nnum_node_train = []\nfor signal in signals_train:\n    num_node_train.append(signal.node_attr.shape[0])\n\n    \nfor signal in signals_val:\n    signal.encode_node_attr(node_attr_encoder)\n    signal.encode_edge_attr(edge_attr_encoder)\n\nX_val = []\n# for signal in signals_val:\n#     X_val.append(list(signal))\nfor signal in signals_val:\n#     X_train.append(list(signal))\n    X_val.append(signal.node_attr_encoded.index_select(dim=0,index=signal.node_index))\n\nnums_node_val = []\nfor signal in signals_val:\n    nums_node_val.append(signal.node_attr.shape[0])","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-07-26T22:14:37.088148Z","iopub.execute_input":"2023-07-26T22:14:37.089120Z","iopub.status.idle":"2023-07-26T22:14:40.747593Z","shell.execute_reply.started":"2023-07-26T22:14:37.089086Z","shell.execute_reply":"2023-07-26T22:14:40.746708Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# for sample in X_train[:1]:\n#     for snapshot in sample:\n#         node_attr = snapshot.node_attr\n#         node_index = snapshot.node_index\n#         edge_attr = snapshot.edge_attr\n#         edge_index = snapshot.edge_index\n        \n#         print(f\"node_attr: {node_attr.shape}\")\n#         print(f\"node_index: {node_index.shape}\")\n#         print(f\"edge_attr: {edge_attr.shape}\")\n#         print(f\"edge_index: {edge_index.shape}\")","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-07-26T22:14:40.749202Z","iopub.execute_input":"2023-07-26T22:14:40.749623Z","iopub.status.idle":"2023-07-26T22:14:40.755804Z","shell.execute_reply.started":"2023-07-26T22:14:40.749584Z","shell.execute_reply":"2023-07-26T22:14:40.754586Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"IN_CHANNELS = signals_train[0].node_attr_encoded.shape[1]\nEDGE_CHANNELS = signals_train[0].edge_attr_encoded.shape[1]","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:14:40.757400Z","iopub.execute_input":"2023-07-26T22:14:40.757875Z","iopub.status.idle":"2023-07-26T22:14:40.769640Z","shell.execute_reply.started":"2023-07-26T22:14:40.757835Z","shell.execute_reply":"2023-07-26T22:14:40.768224Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"model = TGAE(\n    in_channels=IN_CHANNELS, \n    out_channels=5, \n    edge_channels=EDGE_CHANNELS, \n    embed_layers=[16,32],\n    gru_out_channels=8,\n    decide_layers=[16,16],\n    gru_conv_layers=[16,16],\n    gru_edge_layers=[32],\n    gru_lin_layers=[],\n)\n\nloss_f = torch.nn.MSELoss(reduction = 'none')\noptimizer = torch.optim.Adam(model.parameters(), lr = 2e-4, weight_decay=1e-5)\n\nmodel = model.to(device)\nloss_f = loss_f.to(device)\nprint(model)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-07-26T22:14:40.771338Z","iopub.execute_input":"2023-07-26T22:14:40.771710Z","iopub.status.idle":"2023-07-26T22:14:40.826005Z","shell.execute_reply.started":"2023-07-26T22:14:40.771677Z","shell.execute_reply":"2023-07-26T22:14:40.824755Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"TGAE(\n  (encoder_embedding_net): Sequential(\n    (0): Linear(in_features=5, out_features=16, bias=True)\n    (1): LeakyReLU(negative_slope=0.01)\n    (2): Linear(in_features=16, out_features=32, bias=True)\n  )\n  (encoder_gru): GraphGRULayer(\n    (gru): GraphGRU(\n      (conv_x_z): MultiNNConv(\n        (convs): ModuleList(\n          (0): NNConv(32, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=512, bias=True)\n          ))\n          (1): NNConv(16, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=256, bias=True)\n          ))\n        )\n        (lin_net): Sequential(\n          (0): ReLU()\n          (1): Linear(in_features=16, out_features=8, bias=True)\n        )\n      )\n      (conv_h_z): MultiNNConv(\n        (convs): ModuleList(\n          (0): NNConv(8, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=128, bias=True)\n          ))\n          (1): NNConv(16, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=256, bias=True)\n          ))\n        )\n        (lin_net): Sequential(\n          (0): ReLU()\n          (1): Linear(in_features=16, out_features=8, bias=True)\n        )\n      )\n      (conv_x_r): MultiNNConv(\n        (convs): ModuleList(\n          (0): NNConv(32, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=512, bias=True)\n          ))\n          (1): NNConv(16, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=256, bias=True)\n          ))\n        )\n        (lin_net): Sequential(\n          (0): ReLU()\n          (1): Linear(in_features=16, out_features=8, bias=True)\n        )\n      )\n      (conv_h_r): MultiNNConv(\n        (convs): ModuleList(\n          (0): NNConv(8, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=128, bias=True)\n          ))\n          (1): NNConv(16, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=256, bias=True)\n          ))\n        )\n        (lin_net): Sequential(\n          (0): ReLU()\n          (1): Linear(in_features=16, out_features=8, bias=True)\n        )\n      )\n      (conv_x_h): MultiNNConv(\n        (convs): ModuleList(\n          (0): NNConv(32, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=512, bias=True)\n          ))\n          (1): NNConv(16, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=256, bias=True)\n          ))\n        )\n        (lin_net): Sequential(\n          (0): ReLU()\n          (1): Linear(in_features=16, out_features=8, bias=True)\n        )\n      )\n      (conv_h_h): MultiNNConv(\n        (convs): ModuleList(\n          (0): NNConv(8, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=128, bias=True)\n          ))\n          (1): NNConv(16, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=256, bias=True)\n          ))\n        )\n        (lin_net): Sequential(\n          (0): ReLU()\n          (1): Linear(in_features=16, out_features=8, bias=True)\n        )\n      )\n    )\n  )\n  (encoder_deciding_net): Sequential(\n    (0): Linear(in_features=8, out_features=16, bias=True)\n    (1): LeakyReLU(negative_slope=0.01)\n    (2): Linear(in_features=16, out_features=16, bias=True)\n    (3): LeakyReLU(negative_slope=0.01)\n    (4): Linear(in_features=16, out_features=5, bias=True)\n  )\n  (decoder_deciding_net): Sequential(\n    (0): Dropout(p=0.2, inplace=False)\n    (1): Linear(in_features=5, out_features=16, bias=True)\n    (2): LeakyReLU(negative_slope=0.01)\n    (3): Dropout(p=0.2, inplace=False)\n    (4): Linear(in_features=16, out_features=16, bias=True)\n    (5): LeakyReLU(negative_slope=0.01)\n    (6): Linear(in_features=16, out_features=8, bias=True)\n  )\n  (decoder_gru): GraphGRULayer(\n    (gru): GraphGRU(\n      (conv_x_z): MultiNNConv(\n        (convs): ModuleList(\n          (0): NNConv(8, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=128, bias=True)\n          ))\n          (1): NNConv(16, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=256, bias=True)\n          ))\n        )\n        (lin_net): Sequential(\n          (0): ReLU()\n          (1): Linear(in_features=16, out_features=32, bias=True)\n        )\n      )\n      (conv_h_z): MultiNNConv(\n        (convs): ModuleList(\n          (0): NNConv(32, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=512, bias=True)\n          ))\n          (1): NNConv(16, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=256, bias=True)\n          ))\n        )\n        (lin_net): Sequential(\n          (0): ReLU()\n          (1): Linear(in_features=16, out_features=32, bias=True)\n        )\n      )\n      (conv_x_r): MultiNNConv(\n        (convs): ModuleList(\n          (0): NNConv(8, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=128, bias=True)\n          ))\n          (1): NNConv(16, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=256, bias=True)\n          ))\n        )\n        (lin_net): Sequential(\n          (0): ReLU()\n          (1): Linear(in_features=16, out_features=32, bias=True)\n        )\n      )\n      (conv_h_r): MultiNNConv(\n        (convs): ModuleList(\n          (0): NNConv(32, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=512, bias=True)\n          ))\n          (1): NNConv(16, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=256, bias=True)\n          ))\n        )\n        (lin_net): Sequential(\n          (0): ReLU()\n          (1): Linear(in_features=16, out_features=32, bias=True)\n        )\n      )\n      (conv_x_h): MultiNNConv(\n        (convs): ModuleList(\n          (0): NNConv(8, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=128, bias=True)\n          ))\n          (1): NNConv(16, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=256, bias=True)\n          ))\n        )\n        (lin_net): Sequential(\n          (0): ReLU()\n          (1): Linear(in_features=16, out_features=32, bias=True)\n        )\n      )\n      (conv_h_h): MultiNNConv(\n        (convs): ModuleList(\n          (0): NNConv(32, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=512, bias=True)\n          ))\n          (1): NNConv(16, 16, aggr=mean, nn=Sequential(\n            (0): Linear(in_features=58, out_features=32, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=32, out_features=256, bias=True)\n          ))\n        )\n        (lin_net): Sequential(\n          (0): ReLU()\n          (1): Linear(in_features=16, out_features=32, bias=True)\n        )\n      )\n    )\n  )\n  (decoder_embedding_net): Sequential(\n    (0): Dropout(p=0.2, inplace=False)\n    (1): Linear(in_features=32, out_features=16, bias=True)\n    (2): LeakyReLU(negative_slope=0.01)\n    (3): Linear(in_features=16, out_features=5, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train Loop","metadata":{}},{"cell_type":"code","source":"# train_loop\ndef train_loop(signal, model, loss_fn, optimizer, device):\n    model.train()\n    \n    X = signal.node_attr_encoded.index_select(dim=0,index=signal.node_index)\n    node_index = signal.node_index\n    node_flag = signal.node_flag\n    edge_index = signal.edge_index\n    edge_attr = signal.edge_attr_encoded\n    edge_flag = signal.edge_flag\n    \n    outs = model(X, node_index, node_flag, edge_index, edge_attr, edge_flag, signal.node_attr.shape[0])\n\n    train_losses = torch.sqrt(torch.sum(loss_f(X, outs),dim=1))\n    total_loss = torch.sum(train_losses)\n    snapshot_losses = [torch.sum(loss).cpu().numpy() for loss in torch.tensor_split(train_losses.detach(), node_flag)]\n    \n    optimizer.zero_grad()\n    total_loss.backward()\n    optimizer.step()\n    return snapshot_losses","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:14:40.827892Z","iopub.execute_input":"2023-07-26T22:14:40.828649Z","iopub.status.idle":"2023-07-26T22:14:40.836963Z","shell.execute_reply.started":"2023-07-26T22:14:40.828615Z","shell.execute_reply":"2023-07-26T22:14:40.836089Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"## Test Loop","metadata":{}},{"cell_type":"code","source":"# test_loop\ndef test_loop(signal, model, loss_fn, optimizer, device):\n    with torch.no_grad():\n        X = signal.node_attr_encoded.index_select(dim=0,index=signal.node_index)\n        node_index = signal.node_index\n        node_flag = signal.node_flag\n        edge_index = signal.edge_index\n        edge_attr = signal.edge_attr_encoded\n        edge_flag = signal.edge_flag\n\n        outs = model(X, node_index, node_flag, edge_index, edge_attr, edge_flag, signal.node_attr.shape[0])\n\n        train_losses = torch.sqrt(torch.sum(loss_f(X, outs),dim=1))\n        total_loss = torch.sum(train_losses)\n        snapshot_losses = [torch.sum(loss).cpu().numpy() for loss in torch.tensor_split(train_losses.detach(), node_flag)]\n    \n    return snapshot_losses","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:14:40.838222Z","iopub.execute_input":"2023-07-26T22:14:40.838561Z","iopub.status.idle":"2023-07-26T22:14:40.852592Z","shell.execute_reply.started":"2023-07-26T22:14:40.838533Z","shell.execute_reply":"2023-07-26T22:14:40.851688Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"GLOBAL_EPOCH = 0\ndef train_function(num_epoch):\n    global GLOBAL_EPOCH\n    \n    history_train = []\n    history_val = []\n\n    for i_epoch in range(1,num_epoch+1):\n        train_losses = []\n        _start = time.time()\n        for signal in signals_train:\n            snapshot_losses = train_loop(signal, model, loss_f, optimizer, device)\n#             print(np.mean(train_loss))\n            train_losses.append(np.mean(snapshot_losses))\n            \n        \n        if i_epoch % 5 == 0:\n            val_losses = []\n            for signal in signals_val:\n                snapshot_losses = test_loop(signal, model, loss_f, optimizer, device)\n#                 print(np.mean(val_loss))\n                val_losses.append(np.mean(snapshot_losses))\n            _end = time.time()\n            \n            history_train.append(np.mean(train_losses))\n            history_val.append(np.mean(val_losses))\n            print(f\"{i_epoch+GLOBAL_EPOCH}/{num_epoch+GLOBAL_EPOCH}: cost {_end-_start:.4f}s train RMSE {np.mean(train_losses):.4f} val RMSE{np.mean(val_losses):.4f}\")\n        else:\n            _end = time.time()\n            history_train.append(np.mean(train_losses))\n            print(f\"{i_epoch+GLOBAL_EPOCH}/{num_epoch+GLOBAL_EPOCH}: cost {_end-_start:.4f}s train RMSE {np.mean(train_losses):.4f}\")\n    GLOBAL_EPOCH += num_epoch\n    return (history_train,history_val)","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:14:40.854128Z","iopub.execute_input":"2023-07-26T22:14:40.854703Z","iopub.status.idle":"2023-07-26T22:14:40.867484Z","shell.execute_reply.started":"2023-07-26T22:14:40.854669Z","shell.execute_reply":"2023-07-26T22:14:40.866156Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"history_train_list = []\nhistory_val_list = []","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:14:40.869185Z","iopub.execute_input":"2023-07-26T22:14:40.869699Z","iopub.status.idle":"2023-07-26T22:14:40.886232Z","shell.execute_reply.started":"2023-07-26T22:14:40.869648Z","shell.execute_reply":"2023-07-26T22:14:40.884747Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"history_train, history_val = train_function(10)\nhistory_train_list += history_train\nhistory_val_list += history_val\nplt.plot(history_train_list[1::5],label=\"Train\")\nplt.plot(history_val_list,label=\"Val\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:14:40.887515Z","iopub.execute_input":"2023-07-26T22:14:40.887876Z","iopub.status.idle":"2023-07-26T22:17:25.987693Z","shell.execute_reply.started":"2023-07-26T22:14:40.887848Z","shell.execute_reply":"2023-07-26T22:17:25.986479Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"1/10: cost 118.5131s train RMSE 89.0718\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history_train, history_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m history_train_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m history_train\n\u001b[1;32m      3\u001b[0m history_val_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m history_val\n","Cell \u001b[0;32mIn[42], line 12\u001b[0m, in \u001b[0;36mtrain_function\u001b[0;34m(num_epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m         _start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m signal \u001b[38;5;129;01min\u001b[39;00m signals_train:\n\u001b[0;32m---> 12\u001b[0m             snapshot_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#             print(np.mean(train_loss))\u001b[39;00m\n\u001b[1;32m     14\u001b[0m             train_losses\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(snapshot_losses))\n","Cell \u001b[0;32mIn[40], line 19\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(signal, model, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m snapshot_losses \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39msum(loss)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor_split(train_losses\u001b[38;5;241m.\u001b[39mdetach(), node_flag)]\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 19\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m snapshot_losses\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,20))    \nfor i_signal,(signal,y) in enumerate(zip(signals_val,y_val)):\n    snapshot_losses = test_loop(signal, model, loss_f, optimizer, device)\n#                 print(np.mean(val_loss))\n#     val_losses.append(np.mean(snapshot_losses))\n    ts_list = signal.ts_list\n    plt.subplot(len(signals_val)+1,1,i_signal+1)\n#     print(len(snapshot_losses))\n    plt.plot(ts_list,snapshot_losses[:-1])\n    if y[0] == 'dos':\n        plt.axvline(x = float(y[1]), color = 'red', label = y[0])\n    if y[0] == 'privesc':\n        plt.axvline(x = float(y[1]), color = 'blue', label = y[0])\n# plt.show()\nplt.savefig(f'val_res_TGAE_NNConv_{GLOBAL_EPOCH}_{np.mean(history_train_list[-1]):.4f}_{np.mean(history_val_list[-1]):.4f}.png')","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:17:25.988669Z","iopub.status.idle":"2023-07-26T22:17:25.989549Z","shell.execute_reply.started":"2023-07-26T22:17:25.989324Z","shell.execute_reply":"2023-07-26T22:17:25.989347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model,f\"TGAE_NNConv_{GLOBAL_EPOCH}_{np.mean(history_train_list[-1]):.4f}_{np.mean(history_val_list[-1]):.4f}.model\")","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:17:25.991419Z","iopub.status.idle":"2023-07-26T22:17:25.992100Z","shell.execute_reply.started":"2023-07-26T22:17:25.991892Z","shell.execute_reply":"2023-07-26T22:17:25.991913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], use_cuda=True, record_shapes=True) as prof:\n#         history_train, history_val = train_function(1)\n#         history_train_list += history_train\n#         history_val_list += history_val\n#         plt.plot(history_train_list[1::5],label=\"Train\")\n#         plt.plot(history_val_list,label=\"Val\")\n#         plt.legend()\n# print(prof.key_averages().table(sort_by=\"cuda_time_total\"))","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:17:25.993374Z","iopub.status.idle":"2023-07-26T22:17:25.994108Z","shell.execute_reply.started":"2023-07-26T22:17:25.993901Z","shell.execute_reply":"2023-07-26T22:17:25.993922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(prof.key_averages().table(sort_by=\"cpu_time_total\"))","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:17:25.995525Z","iopub.status.idle":"2023-07-26T22:17:25.995943Z","shell.execute_reply.started":"2023-07-26T22:17:25.995726Z","shell.execute_reply":"2023-07-26T22:17:25.995744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fig = plt.figure(figsize=(20,20))    \n# for i_signal,(signal,y) in enumerate(zip(signals_val,y_val)):\n#     snapshot_losses = test_loop(signal, model, loss_f, optimizer, device)\n# #                 print(np.mean(val_loss))\n# #     val_losses.append(np.mean(snapshot_losses))\n#     ts_list = signal.ts_list\n#     plt.subplot(len(signals_val)+1,1,i_signal+1)\n# #     print(len(snapshot_losses))\n#     plt.plot(ts_list,snapshot_losses[:-1])\n#     if y[0] == 'dos':\n#         plt.axvline(x = float(y[1]), color = 'red', label = y[0])\n#     if y[0] == 'privesc':\n#         plt.axvline(x = float(y[1]), color = 'blue', label = y[0])\n# # plt.show()\n# plt.savefig('val_res.png')","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:17:25.997461Z","iopub.status.idle":"2023-07-26T22:17:25.998726Z","shell.execute_reply.started":"2023-07-26T22:17:25.998414Z","shell.execute_reply":"2023-07-26T22:17:25.998442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.save(model,f\"{GLOBAL_EPOCH}_{np.mean(history_train_list[-1]):.4f}_{np.mean(history_val_list[-1]):.4f}.model\")","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:17:26.000221Z","iopub.status.idle":"2023-07-26T22:17:26.001105Z","shell.execute_reply.started":"2023-07-26T22:17:26.000806Z","shell.execute_reply":"2023-07-26T22:17:26.000836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history_train, history_val = train_function(100)\n# history_train_list += history_train\n# history_val_list += history_val\n# plt.plot(history_train_list[1::5],label=\"Train\")\n# plt.plot(history_val_list,label=\"Val\")\n# plt.legend()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:17:26.002811Z","iopub.status.idle":"2023-07-26T22:17:26.003354Z","shell.execute_reply.started":"2023-07-26T22:17:26.003078Z","shell.execute_reply":"2023-07-26T22:17:26.003105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# states_encoder_val = []\n# states_decoder_val = []\n# for num_node in nums_node_val:\n#     states_encoder_val.append(create_hidden_global(num_node=num_node,out_channels=model.gnn_out_channels))\n#     states_decoder_val.append(create_hidden_global(num_node=num_node,out_channels=model.embedding_hidden_nums[-1]))    \n\n# fig = plt.figure(figsize=(20,20))    \n# for i_sample, (sample, y, hidden_encoder_global, hidden_decoder_global) in enumerate(zip(X_val, y_val, states_encoder_val, states_decoder_val)):\n#     val_loss = test_loop(sample, hidden_encoder_global, hidden_decoder_global, model, loss_f, optimizer, device)\n#     # print(np.mean(val_loss))\n#     ts_list = [snapshot.timestamp for snapshot in sample]\n#     plt.subplot(len(X_val)+1,1,i_sample+1)\n#     plt.plot(ts_list,val_loss)\n#     if y[0] == 'dos':\n#         plt.axvline(x = float(y[1]), color = 'red', label = y[0])\n#     if y[0] == 'privesc':\n#         plt.axvline(x = float(y[1]), color = 'blue', label = y[0])\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:17:26.005077Z","iopub.status.idle":"2023-07-26T22:17:26.005680Z","shell.execute_reply.started":"2023-07-26T22:17:26.005390Z","shell.execute_reply":"2023-07-26T22:17:26.005415Z"},"trusted":true},"execution_count":null,"outputs":[]}]}