{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nuse_gpu = torch.cuda.is_available()\nprint(torch.__version__)\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:04:57.317214Z","iopub.execute_input":"2023-08-26T00:04:57.317592Z","iopub.status.idle":"2023-08-26T00:04:59.249150Z","shell.execute_reply.started":"2023-08-26T00:04:57.317562Z","shell.execute_reply":"2023-08-26T00:04:59.248131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initialize for CPU & GPU","metadata":{}},{"cell_type":"code","source":"if use_gpu:\n    !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric --no-index --find-links=file:///kaggle/input/torch-geometric\n#     !pip install torch_geometric_temporal  \nelse:\n    !pip install /kaggle/input/pytorch-geometric-cpu/torch_scatter-2.1.1pt20cpu-cp310-cp310-linux_x86_64.whl\n    !pip install /kaggle/input/pytorch-geometric-cpu/torch_sparse-0.6.17pt20cpu-cp310-cp310-linux_x86_64.whl\n    !pip install /kaggle/input/pytorch-geometric-cpu/torch_cluster-1.6.1pt20cpu-cp310-cp310-linux_x86_64.whl\n    !pip install /kaggle/input/pytorch-geometric-cpu/torch_spline_conv-1.2.2pt20cpu-cp310-cp310-linux_x86_64.whl\n    !pip install /kaggle/input/pytorch-geometric-cpu/torch_geometric-2.3.1-py3-none-any.whl\n#     !pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n#     !pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n#     !pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n#     !pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n#     !pip install torch_spline_conv -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n#     !pip install git+https://github.com/pyg-team/pytorch_geometric.git\n#     !pip install torch_geometric_temporal","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-26T00:04:59.251074Z","iopub.execute_input":"2023-08-26T00:04:59.251583Z","iopub.status.idle":"2023-08-26T00:05:13.716088Z","shell.execute_reply.started":"2023-08-26T00:04:59.251556Z","shell.execute_reply":"2023-08-26T00:05:13.714940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport re\nimport json\nimport random\nfrom scipy.special import perm\nfrom itertools import combinations,chain\nfrom typing import List, Union\nfrom torch_geometric.data import Data\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport matplotlib.pyplot as plt\nimport pickle\nimport time\nfrom torch import nn\nfrom torch.nn import Linear as Lin\nfrom torch.nn import ReLU, LeakyReLU\nfrom torch.nn import Sequential as Seq\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, GINConv\nfrom torch_geometric.data import Batch\nfrom torch import autograd\nfrom torch_geometric.nn.models import InnerProductDecoder\nfrom torch_geometric.utils import to_dense_adj\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score\n\nfrom texttable import Texttable\nfrom itertools import product","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:05:13.719537Z","iopub.execute_input":"2023-08-26T00:05:13.719863Z","iopub.status.idle":"2023-08-26T00:05:15.016157Z","shell.execute_reply.started":"2023-08-26T00:05:13.719834Z","shell.execute_reply":"2023-08-26T00:05:15.015113Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataLoader","metadata":{}},{"cell_type":"code","source":"Edge_Flag = List[Union[np.ndarray, None]]\nEdge_Index = List[Union[np.ndarray, None]]\nEdge_Attr = List[Union[np.ndarray, None]]\n\nNode_Flag = List[Union[np.ndarray, None]]\nNode_Index = List[Union[np.ndarray, None]]\nNode_Attr = List[Union[np.ndarray, None]]\n\n\n\nclass GraphSignal(object):\n    # dynamic node static node attr dynamic edge and edge attr\n    def __init__(\n        self,\n        edge_flag: Edge_Flag,\n        edge_index: Edge_Index,\n        edge_attr: Edge_Attr,\n        node_flag: Node_Flag,\n        node_index: Node_Index,\n        node_attr: Node_Attr,\n        ts_list: List,\n        path: str,\n    ):\n        \n        self.raw_edge_flag = torch.LongTensor(edge_flag[:-1])\n        self.raw_edge_index = torch.LongTensor(edge_index).T\n        self.raw_edge_attr = edge_attr\n        self.raw_node_attr = node_attr \n        self.node_flag = torch.LongTensor(node_flag[:-1])\n        self.node_index = torch.LongTensor(node_index)\n        \n        self.ts_list = ts_list\n        \n        self.path = path\n        \n        self.node_attr = None\n        self.edge_flag = None\n        self.edge_index = None\n        \n        self.y = None\n        \n        self._set_snapshot_count()\n        self._set_node_count()\n\n    def _set_snapshot_count(self):\n        self.snapshot_count = len(self.ts_list)\n    \n    def _set_node_count(self):\n        self.node_count = self.raw_node_attr.shape[0]\n    \n    def encode_edge_attr(self, enocder):\n        self.edge_attr_encoded = torch.FloatTensor(enocder.transform(self.raw_edge_attr))\n        \n    def encode_node_attr(self, enocder):\n        self.node_attr_encoded = torch.FloatTensor(enocder.transform(self.raw_node_attr))\n        \n    def extend_node_attr(self):\n        if self.edge_attr_encoded is None:\n            print(\"Edge Attr Need to be Encoded!\")\n            raise\n        node_index = self.node_index\n        node_attr = self.node_attr_encoded.index_select(dim=0,index=self.node_index)\n        node_flag = self.node_flag\n        \n        edge_index = self.raw_edge_index\n        edge_attr = self.edge_attr_encoded\n        edge_flag = self.raw_edge_flag\n        \n        node_index_split = torch.tensor_split(node_index, node_flag)\n        node_attr_split = torch.tensor_split(node_attr, node_flag)\n        edge_index_split = torch.tensor_split(edge_index, edge_flag, dim=1)\n        edge_attr_split = torch.tensor_split(edge_attr, edge_flag)\n\n        base = 0\n        new_node_attr = []\n        new_edge_flag = []\n        new_edge_index = []\n        \n        for i_snapshot in range(self.snapshot_count):\n            _node_index = node_index_split[i_snapshot]\n            _node_attr = node_attr_split[i_snapshot]\n            _edge_index = edge_index_split[i_snapshot]\n            _edge_attr = edge_attr_split[i_snapshot]\n\n            if _edge_index.shape[1] != _edge_attr.shape[0]:\n                print(i_snapshot, edge_index.shape, _edge_attr.shape)\n                raise\n            if _edge_index.shape[1] > 0:\n                index_dict = {}\n                for i_edge in range(_edge_index.shape[1]):\n                    index_tuple = tuple(_edge_index[:,i_edge].tolist())\n                    if index_tuple in index_dict:\n                        index_dict[index_tuple] += [i_edge]\n                    else:\n                        index_dict[index_tuple] = [i_edge]\n\n                _new_edge_index = []\n                _new_edge_attr = []\n                for key in index_dict.keys():\n                    _new_edge_index.append(key)\n                    _new_edge_attr.append(torch.sum(_edge_attr.index_select(0, torch.LongTensor(index_dict[key])),dim=0).unsqueeze(0))\n\n                _new_edge_index = torch.LongTensor(_new_edge_index).T\n                _new_edge_attr = torch.cat(_new_edge_attr,dim=0)\n                \n                base += _new_edge_index.shape[1]\n                new_edge_index.append(_new_edge_index)\n\n#                 _source_attr = torch.zeros((_node_attr.shape[0], _new_edge_attr.shape[1])).to(device)\n#                 _target_attr = torch.zeros((_node_attr.shape[0], _new_edge_attr.shape[1])).to(device)\n#                 _source_attr.index_add_(0, _new_edge_index[0], _new_edge_attr)\n#                 _target_attr.index_add_(0, _new_edge_index[1], _new_edge_attr)\n#                 new_node_attr.append(torch.cat([_node_attr,_source_attr,_target_attr], dim=1))\n\n                _node_attr_extend = torch.zeros((_node_attr.shape[0], _new_edge_attr.shape[1]))\n                _node_attr_extend.index_add_(0, _new_edge_index[0], _new_edge_attr)\n                _node_attr_extend.index_add_(0, _new_edge_index[1], _new_edge_attr)\n                new_node_attr.append(torch.cat([_node_attr,_node_attr_extend], dim=1)) \n                \n            new_edge_flag.append(base)\n        \n        self.node_attr = torch.cat(new_node_attr, dim=0)\n        self.edge_flag = torch.LongTensor(new_edge_flag)\n        self.edge_index = torch.cat(new_edge_index,dim=1)\n    \n    def remove_init_stop(self, threshold, period):\n        node_index = self.node_index\n        node_attr = self.node_attr\n        node_flag = self.node_flag\n\n        edge_index = self.edge_index\n        edge_flag = self.edge_flag\n        \n        raw_edge_index = self.raw_edge_index\n        raw_edge_attr = self.raw_edge_attr\n        raw_edge_flag = self.raw_edge_flag\n\n        node_index_split = torch.tensor_split(node_index, node_flag)\n        node_attr_split = torch.tensor_split(node_attr, node_flag)\n        edge_index_split = torch.tensor_split(edge_index, edge_flag, dim=1)\n        \n        raw_edge_index_split = torch.tensor_split(raw_edge_index, raw_edge_flag, dim=1)\n        raw_edge_attr_split = np.split(raw_edge_attr, raw_edge_flag)\n\n        i_init = None\n        i_stop = None\n        for i_snapshot, node_num in enumerate(torch.diff(self.node_flag)):\n            if node_num > threshold:\n                i_init = i_snapshot+1\n                break\n\n        for i_snapshot, node_num in enumerate(torch.flip(torch.diff(self.node_flag),dims=[0])):\n            if node_num > threshold:\n                i_stop = self.node_flag.shape[0]-1-i_snapshot\n                break\n        \n        new_node_attr = torch.cat(node_attr_split[i_init+1+period:i_stop-period],dim=0)\n        new_node_index = torch.cat(node_index_split[i_init+1+period:i_stop-period],dim=0)\n        new_edge_index = torch.cat(edge_index_split[i_init+1+period:i_stop-period],dim=1)\n        new_raw_edge_index = torch.cat(raw_edge_index_split[i_init+1+period:i_stop-period], dim=1)\n        new_raw_edge_attr = np.concatenate(raw_edge_attr_split[i_init+1+period:i_stop-period])\n\n        new_node_flag = node_flag[i_init+period+1:i_stop-period-1]-node_flag[i_init+period]\n        new_edge_flag = edge_flag[i_init+period+1:i_stop-period-1]-edge_flag[i_init+period]\n        new_raw_edge_flag = raw_edge_flag[i_init+period+1:i_stop-period-1]-raw_edge_flag[i_init+period]\n        \n        self.node_attr = new_node_attr\n        self.node_index = new_node_index\n        self.edge_index = new_edge_index\n        self.raw_edge_attr = new_raw_edge_attr\n        self.raw_edge_index = new_raw_edge_index\n        \n        self.node_flag = new_node_flag\n        self.edge_flag = new_edge_flag\n        self.raw_edge_flag = new_raw_edge_flag\n        \n        self.ts_list = self.ts_list[i_init+1+period:i_stop-period]\n        \n        self._set_snapshot_count()\n    \n    def annotation2y(self, annotation, interval, overlap, offset= -30):\n        ts_list = self.ts_list\n        y = torch.zeros(self.snapshot_count, dtype=torch.long)\n        for i_ts, ts in enumerate(ts_list):\n            if ts < float(annotation[1])+offset and float(annotation[1])+offset <= ts+interval-overlap: \n                y[i_ts] = 1\n        self.y = y\n        self.type = annotation[0]\n    \n    def to(self,device):\n        self.node_attr = self.node_attr.to(device)\n        self.node_index = self.node_index.to(device)\n        self.edge_index = self.edge_index.to(device)\n    \n    def get_adj_list(self):\n        edge_index = self.edge_index\n        edge_flag = self.edge_flag\n        edge_index_split = torch.tensor_split(edge_index, edge_flag, dim=1)\n        adj_list = [torch.clamp(to_dense_adj(_edge_index)[0], min=0, max=1) for _edge_index in edge_index_split]\n        return adj_list\n\n    def __getitem__(self, time_index: int):\n        raise\n#         edge_index = self._get_edge_index(time_index)\n#         edge_attr = self._get_edge_attr(time_index)\n#         node_index,node_attr = self._get_node_index_attr(time_index)\n#         _timestamp = self._get_timestamp(time_index)\n\n#         snapshot = Data(\n#             edge_index=edge_index,\n#             edge_attr=edge_attr,\n#             node_index=node_index,\n#             node_attr=node_attr,\n#             timestamp=_timestamp\n#         )\n#         return snapshot\n\n    def __next__(self):\n        if self.t < self.snapshot_count:\n            snapshot = self[self.t]\n            self.t = self.t + 1\n            return snapshot\n        else:\n            self.t = 0\n            raise StopIteration\n\n    def __iter__(self):\n        self.t = 0\n        return self\n    \n    def __len__(self):\n        return self.snapshot_count\n\n\nclass GraphDatasetLoader(object):\n    def __init__(self,input_path=\"\"):\n        self.input_path = input_path\n        self._read_data()\n    \n    def _read_data(self):\n        self._dataset = np.load(self.input_path)\n\n    def get_dataset(self): # -> DynamicGraphTemporalSignal:\n        dataset = GraphSignal(\n            edge_flag = self._dataset['edge_flag'],\n            edge_index = self._dataset['edge_index'],\n            edge_attr = self._dataset['edge_attr'],\n            node_flag = self._dataset['node_flag'],\n            node_index = self._dataset['node_index'],\n            node_attr = self._dataset['node_attr'],\n            ts_list = self._dataset['timestamp'],\n            path = self.input_path\n        )\n        return dataset","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:05:15.017937Z","iopub.execute_input":"2023-08-26T00:05:15.018343Z","iopub.status.idle":"2023-08-26T00:05:15.064933Z","shell.execute_reply.started":"2023-08-26T00:05:15.018307Z","shell.execute_reply":"2023-08-26T00:05:15.063993Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read Data","metadata":{}},{"cell_type":"code","source":"import pickle\n\nwith open(\"/kaggle/input/dissertation-data/signals_train.pkl\", \"rb\") as f:\n    signals_train = pickle.load(f)\nwith open(\"/kaggle/input/dissertation-data/signals_val.pkl\", \"rb\") as f:\n    signals_val = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:05:15.068956Z","iopub.execute_input":"2023-08-26T00:05:15.069383Z","iopub.status.idle":"2023-08-26T00:05:32.143362Z","shell.execute_reply.started":"2023-08-26T00:05:15.069350Z","shell.execute_reply":"2023-08-26T00:05:32.142364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Multi-Layer GraphConv","metadata":{}},{"cell_type":"code","source":"class MultiGraphConv(torch.nn.Module):\n    def __init__(\n        self, \n        channels, \n    ):\n        super().__init__() \n        \n        self.conv1 = GCNConv(channels, channels * 2)\n#         self.conv2 = GCNConv(channels * 2, channels * 2)\n        self.conv3 = GCNConv(channels * 2, channels)\n        \n\n    def forward(self, x, edge_index):\n        out = x\n        out = F.dropout(out, p=0.6)\n        out = F.elu(self.conv1(out, edge_index))\n#         out = F.dropout(out, p=0.6)\n#         out = F.elu(self.conv2(out, edge_index))\n        out = F.dropout(out, p=0.6)\n        out = self.conv3(out, edge_index)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:05:32.145036Z","iopub.execute_input":"2023-08-26T00:05:32.145452Z","iopub.status.idle":"2023-08-26T00:05:32.153509Z","shell.execute_reply.started":"2023-08-26T00:05:32.145415Z","shell.execute_reply":"2023-08-26T00:05:32.152330Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Graph RNN Operator","metadata":{}},{"cell_type":"code","source":"class GraphGRU(torch.nn.Module):\n    def __init__(\n        self,\n        channels: int,\n        bias: bool = True,\n    ):\n        super().__init__()\n\n        self.channels = channels\n        self.bias = bias\n        self._create_parameters_and_layers()\n\n    def _create_update_gate_parameters_and_layers(self):\n\n        self.conv_x_z = MultiGraphConv(channels = self.channels)\n\n        self.conv_h_z = MultiGraphConv(channels = self.channels)\n        \n    def _create_reset_gate_parameters_and_layers(self):\n\n        self.conv_x_r = MultiGraphConv(channels = self.channels)\n\n        self.conv_h_r = MultiGraphConv(channels = self.channels)\n\n    def _create_candidate_state_parameters_and_layers(self):\n\n        self.conv_x_h = MultiGraphConv(channels = self.channels)\n\n        self.conv_h_h = MultiGraphConv(channels = self.channels)\n\n    def _create_parameters_and_layers(self):\n        self._create_update_gate_parameters_and_layers()\n        self._create_reset_gate_parameters_and_layers()\n        self._create_candidate_state_parameters_and_layers()\n\n    def _set_hidden_state(self, X, H):\n        if H is None:\n            H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n        return H\n\n    def _calculate_update_gate(self, X, edge_index, H):\n        Z = self.conv_x_z(X, edge_index)\n        Z = Z + self.conv_h_z(H, edge_index)\n        Z = torch.sigmoid(Z)\n        return Z\n\n    def _calculate_reset_gate(self, X, edge_index, H):\n        R = self.conv_x_r(X, edge_index)\n        R = R + self.conv_h_r(H, edge_index)\n        R = torch.sigmoid(R)\n        return R\n\n    def _calculate_candidate_state(self, X, edge_index, H, R):\n        H_tilde = self.conv_x_h(X, edge_index)\n        H_tilde = H_tilde + self.conv_h_h(H * R, edge_index)\n        H_tilde = torch.tanh(H_tilde)\n        return H_tilde\n\n    def _calculate_hidden_state(self, Z, H, H_tilde):\n        H = Z * H + (1 - Z) * H_tilde\n        return H\n\n    def forward(\n            self,\n            X: torch.FloatTensor,\n            edge_index: torch.LongTensor,\n            H: torch.FloatTensor = None,\n        ) -> torch.FloatTensor:\n        H = self._set_hidden_state(X, H)\n        Z = self._calculate_update_gate(X, edge_index, H)\n        R = self._calculate_reset_gate(X, edge_index, H)\n        H_tilde = self._calculate_candidate_state(X, edge_index, H, R)\n        H = self._calculate_hidden_state(Z, H, H_tilde)\n        return H","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:05:32.155003Z","iopub.execute_input":"2023-08-26T00:05:32.155535Z","iopub.status.idle":"2023-08-26T00:05:32.171976Z","shell.execute_reply.started":"2023-08-26T00:05:32.155502Z","shell.execute_reply":"2023-08-26T00:05:32.171068Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Graph RNN Layer","metadata":{}},{"cell_type":"code","source":"class GraphGRULayer(torch.nn.Module):\n    def __init__(\n        self,\n        channels: int,\n        bias: bool = True,\n    ):\n        super().__init__()\n        self.gru = GraphGRU(\n            channels = channels,\n            bias = bias\n        )\n        \n        self.channels = channels\n        \n    def forward(\n        self,\n        X: torch.FloatTensor,\n        node_index: torch.LongTensor,\n        node_flag: torch.LongTensor,\n        edge_index: torch.LongTensor,\n        edge_flag: torch.LongTensor,\n        direction: bool # True for Forward; False for Backward\n    ) -> torch.FloatTensor:\n        \n        X_split = torch.tensor_split(X, node_flag)\n        node_index_split = torch.tensor_split(node_index, node_flag)\n        edge_index_split = torch.tensor_split(edge_index, edge_flag, dim=1)\n        \n#         print(X_split[0].device)\n#         print(node_index_split[0].device)\n#         print(edge_index_split[0].device)\n             \n        pre_hidden = None\n        \n        outs = []\n        if direction:\n            snapshot_index = range(len(X_split))\n        else:\n            snapshot_index = range(len(X_split)-1,-1,-1)\n            \n        for _i,i_snapshot in enumerate(snapshot_index):\n            _X = X_split[i_snapshot]\n            _node_index = node_index_split[i_snapshot]\n            _edge_index = edge_index_split[i_snapshot]\n            \n            curr_hidden = torch.zeros(_X.shape[0],self.channels).to(_X.device)\n            if _i != 0:\n                if direction:\n                    pre_node_index = node_index_split[i_snapshot-1]\n                    # Solution from https://discuss.pytorch.org/t/find-indexes-of-elements-from-one-tensor-that-matches-in-another-tensor/147482/2\n                    _index = (node_index_split[i_snapshot-1].unsqueeze(1) == node_index_split[i_snapshot].unsqueeze(0)).nonzero() \n                else:\n                    pre_node_index = node_index_split[i_snapshot+1]\n                    # Solution from https://discuss.pytorch.org/t/find-indexes-of-elements-from-one-tensor-that-matches-in-another-tensor/147482/2\n                    _index = (node_index_split[i_snapshot+1].unsqueeze(1) == node_index_split[i_snapshot].unsqueeze(0)).nonzero() \n                curr_hidden.index_add_(0, _index[:,1], torch.index_select(pre_hidden,0, _index[:,0]))\n\n            new_hidden = self.gru(_X, _edge_index, curr_hidden)\n            pre_hidden = new_hidden\n            outs.append(new_hidden)\n        if direction:\n            H = torch.cat(outs)\n        else:\n            H = torch.cat(outs[::-1])\n        return H","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:05:32.175011Z","iopub.execute_input":"2023-08-26T00:05:32.175331Z","iopub.status.idle":"2023-08-26T00:05:32.191430Z","shell.execute_reply.started":"2023-08-26T00:05:32.175301Z","shell.execute_reply":"2023-08-26T00:05:32.190443Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# STAE Model","metadata":{}},{"cell_type":"code","source":"class STAE(torch.nn.Module): # Not Heterogeneous\n    def __init__(\n        self, \n        in_channels, \n        out_channels, \n        gcn_channels,\n        embed_layers,  \n        decide_layers,\n        bidirectional=False,\n        dropout=0.2,\n    ):\n        super().__init__()\n        \n        # Encoder Embeding\n#         layers = [torch.nn.BatchNorm1d(in_channels)]\n        self.bidirectional = bidirectional\n        self.dropout = dropout\n    \n        layers = []\n        pre_h_num = in_channels\n        for h_num in embed_layers:\n            layers.append(torch.nn.Dropout(p=dropout))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,gcn_channels))\n        self.embed_net = Seq(*layers)\n                \n        self.encoder_gru = GraphGRULayer(channels=gcn_channels)\n        if self.bidirectional:\n            self.encoder_gru_back = GraphGRULayer(channels=gcn_channels)\n\n        layers = []\n        if self.bidirectional:\n            pre_h_num = gcn_channels*2\n        else:\n            pre_h_num = gcn_channels\n            \n        for h_num in decide_layers:\n            layers.append(torch.nn.Dropout(p=dropout))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,out_channels))\n#         layers.append(torch.nn.Sigmoid())\n        self.decide_net = Seq(*layers)\n        \n        # Decoder\n#         self.decoder = InnerProductDecoder()\n        layers = []\n        pre_h_num = out_channels\n        for h_num in decide_layers[::-1]:\n            layers.append(torch.nn.Dropout(p=dropout))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(torch.nn.LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,gcn_channels))\n        self.decode_decide_net = Seq(*layers)\n        \n        self.decoder_gru = GraphGRULayer(channels=gcn_channels)\n        if self.bidirectional:\n            self.decoder_gru_back = GraphGRULayer(channels=gcn_channels)\n        \n        layers = []\n        if self.bidirectional:\n            pre_h_num = gcn_channels*2\n        else:\n            pre_h_num = gcn_channels\n            \n        for h_num in embed_layers[::-1]:\n            layers.append(torch.nn.Dropout(p=dropout))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(torch.nn.LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,in_channels))\n        self.decode_embed_net = Seq(*layers)\n        \n\n    def forward(self, x, node_index, node_flag, edge_index, edge_flag):\n        # Encoder\n        out = self.embed_net(x)\n        \n        # GNN layer\n        h_encoder = self.encoder_gru(out, node_index, node_flag, edge_index, edge_flag, True) \n        \n        if self.bidirectional:\n            h_encoder_back = self.encoder_gru_back(out, node_index, node_flag, edge_index, edge_flag, False) \n            out = torch.concat([h_encoder,h_encoder_back],dim=1)\n        else:\n            out = h_encoder\n            \n        out = self.decide_net(out)\n        \n        out = self.decode_decide_net(out)\n \n        h_decoder = self.decoder_gru(out, node_index, node_flag, torch.flip(edge_index,dims=(0,)), edge_flag, True)\n    \n        if self.bidirectional:\n            h_decoder_back = self.decoder_gru_back(out, node_index, node_flag, torch.flip(edge_index,dims=(0,)), edge_flag, False)\n            out = torch.concat([h_decoder,h_decoder_back],dim=1)\n        else:\n            out = h_encoder\n        \n        out = self.decode_embed_net(out)\n\n        return out\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:05:32.194521Z","iopub.execute_input":"2023-08-26T00:05:32.194781Z","iopub.status.idle":"2023-08-26T00:05:32.214694Z","shell.execute_reply.started":"2023-08-26T00:05:32.194759Z","shell.execute_reply":"2023-08-26T00:05:32.213789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Batch Signal","metadata":{}},{"cell_type":"code","source":"# Concat Batchs to from BatchSignal\nclass BatchSignal():\n    def __init__(self, signals, batch_size, seq_len):   \n        data_list_2D = [[] for _ in range(seq_len)]\n        node_index_split_list = [[] for _ in range(seq_len)]\n        base_node_index = 0\n        \n        if batch_size is None:\n            self.batch_index = [[i_signal, 0] for i_signal in list(range(len(signals)))]\n        else:\n            self.batch_index = [[i_signal, 0] for i_signal in np.random.randint(low=0, high=len(signals), size=batch_size, dtype=int)]\n        \n        for i_batch, (i_signal,_) in enumerate(self.batch_index):\n            signal = signals[i_signal]\n    \n            while signal.snapshot_count < seq_len:\n                new_index = np.random.randint(low=0, high=len(signals))\n                signal = signals[new_index]\n                self.batch_index[i_batch] = [new_index, 0]\n            \n            node_attr_split = signal.node_attr.tensor_split(signal.node_flag)\n            node_index_split = signal.node_index.tensor_split(signal.node_flag)\n            edge_index_split = signal.edge_index.tensor_split(signal.edge_flag, dim=1)\n\n            if signal.snapshot_count-seq_len != 0:\n                _start = np.random.randint(low=0, high=signal.snapshot_count-seq_len+1)\n                self.batch_index[i_batch][1] = _start\n            else:\n                _start = 0\n\n            for i_series, i_snapshot in enumerate(range(_start, _start+seq_len)):\n                data = Data(\n                    x = node_attr_split[i_snapshot],\n                    edge_index = edge_index_split[i_snapshot],\n                    y = signal.y[i_snapshot]\n                )\n                data_list_2D[i_series].append(data)\n                node_index_split_list[i_series].append(node_index_split[i_snapshot]+base_node_index)\n            base_node_index += signal.node_count\n\n        batch_list = [Batch.from_data_list(data_list) for data_list in data_list_2D]\n        node_index_list = [torch.cat(_node_index, dim=0) for _node_index in node_index_split_list]\n\n        node_flag_list = []\n        edge_flag_list = []\n        node_attr = []\n        edge_index = []\n\n        node_base = 0\n        edge_base = 0\n\n        for batch in batch_list:\n            node_base += batch.x.shape[0]\n            edge_base += batch.edge_index.shape[1]\n            node_flag_list.append(node_base)\n            edge_flag_list.append(edge_base)\n\n        self.node_index = torch.cat([_node_index for _node_index in node_index_list], dim=0) \n        self.node_attr = torch.cat([_batch.x for _batch in batch_list], dim=0)\n        self.edge_index = torch.cat([_batch.edge_index for _batch in batch_list], dim=1)\n        self.y = torch.cat([_batch.y for _batch in batch_list], dim=0)\n        self.batch_index_dict = [batch._slice_dict for batch in batch_list]\n        \n        self.node_flag = torch.LongTensor(node_flag_list)[:-1]\n        self.edge_flag = torch.LongTensor(edge_flag_list)[:-1]\n    \n    def to(self, device):\n        self.node_attr = self.node_attr.to(device)\n        self.node_index = self.node_index.to(device)\n        self.edge_index = self.edge_index.to(device)\n        return self","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:05:32.216281Z","iopub.execute_input":"2023-08-26T00:05:32.216972Z","iopub.status.idle":"2023-08-26T00:05:32.235871Z","shell.execute_reply.started":"2023-08-26T00:05:32.216942Z","shell.execute_reply":"2023-08-26T00:05:32.234754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Loop","metadata":{}},{"cell_type":"code","source":"# train_loop\ndef train_loop(signal, model, loss_fn, optimizer, device, split_loss: bool = False):\n    model.train()\n    \n    X = signal.node_attr\n    node_index = signal.node_index\n    node_flag = signal.node_flag\n    edge_index = signal.edge_index\n    edge_flag = signal.edge_flag\n    \n    outs = model(X, node_index, node_flag, edge_index, edge_flag)\n\n    train_losses = torch.sqrt(torch.sum(loss_f(X, outs),dim=1))\n    total_loss = torch.mean(train_losses)\n        \n    optimizer.zero_grad()\n    total_loss.backward()\n    optimizer.step()\n    \n    if split_loss:\n        snapshot_losses = [loss.cpu().numpy() for loss in torch.tensor_split(train_losses.detach(), node_flag)]\n        return snapshot_losses\n    else:\n        return total_loss.cpu().detach().numpy()\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:05:32.237799Z","iopub.execute_input":"2023-08-26T00:05:32.238382Z","iopub.status.idle":"2023-08-26T00:05:32.251853Z","shell.execute_reply.started":"2023-08-26T00:05:32.238351Z","shell.execute_reply":"2023-08-26T00:05:32.250992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Loop","metadata":{}},{"cell_type":"code","source":"# test_loop\ndef test_loop(signal, model, loss_fn, optimizer, device, split_loss: bool = False):\n    with torch.no_grad():\n        X = signal.node_attr\n        node_index = signal.node_index\n        node_flag = signal.node_flag\n        edge_index = signal.edge_index\n        edge_flag = signal.edge_flag\n\n        outs = model(X, node_index, node_flag, edge_index, edge_flag)\n\n        train_losses = torch.sqrt(torch.sum(loss_f(X, outs),dim=1))\n        total_loss = torch.mean(train_losses)\n        snapshot_losses = [loss.cpu().numpy() for loss in torch.tensor_split(train_losses.detach(), node_flag)]\n    \n        if split_loss:\n            snapshot_losses = [loss.cpu().numpy() for loss in torch.tensor_split(train_losses.detach(), node_flag)]\n            return snapshot_losses\n        else:\n            return total_loss.cpu().detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:05:32.253000Z","iopub.execute_input":"2023-08-26T00:05:32.253414Z","iopub.status.idle":"2023-08-26T00:05:32.266835Z","shell.execute_reply.started":"2023-08-26T00:05:32.253383Z","shell.execute_reply":"2023-08-26T00:05:32.265886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation Function","metadata":{}},{"cell_type":"code","source":"def get_graph_anomaly_threshold(batch_signal, batch_node_losses,q=95):\n    batch_index_dict = batch_signal.batch_index_dict\n    graph_losses = []\n    for i_series in range(MIN_LEN):\n        loss_split = np.split(batch_node_losses[i_series], batch_index_dict[i_series]['x'][1:-1])\n        graph_losses += [np.sum(node_losses) for node_losses in loss_split]\n        \n    return np.percentile(graph_losses,q)\n\ndef batch_graph_eval_func(batch_signal, batch_node_losses, threshold):\n    batch_index_dict = batch_signal.batch_index_dict\n    y_pred = []\n    for i_series in range(MIN_LEN):\n        loss_split = np.split(batch_node_losses[i_series], batch_index_dict[i_series]['x'][1:-1])\n        for losses in loss_split:\n            y_pred.append(int(np.sum(losses.reshape(-1, 1)) > threshold))\n    tn, fp, fn, tp = confusion_matrix(batch_signal.y, y_pred, labels=[0,1]).ravel()\n    return tn, fp, fn, tp\n\ndef batch_graph_eval_func_2(batch_signal, batch_node_losses):\n    batch_index_dict = batch_signal.batch_index_dict\n    y_loss = []\n    for i_series in range(MIN_LEN):\n        loss_split = np.split(batch_node_losses[i_series], batch_index_dict[i_series]['x'][1:-1])\n        for losses in loss_split:\n            y_loss.append(np.mean(losses.reshape(-1, 1)))\n            \n    precision_list, recall_list, thresholds = precision_recall_curve(batch_signal.y,y_loss)\n    f1_list = []\n    for precision, recall in zip(precision_list, recall_list):\n        if precision == 0 and recall == 0:\n            f1_list.append(0)\n        else:\n            f1_list.append(2 * (precision * recall) / (precision + recall))\n        \n    precision = precision_list[np.nanargmax(f1_list)]\n    recall = recall_list[np.nanargmax(f1_list)]\n    f1 = f1_list[np.nanargmax(f1_list)]\n    roc_auc = roc_auc_score(batch_signal.y,y_loss)\n    \n    return precision, recall, f1, roc_auc\n\ndef single_graph_eval_func(signal, node_losses, threshold):\n    y_pred = []\n    for losses in node_losses:\n        y_pred.append(int(np.sum(losses.reshape(-1, 1)) > threshold))\n    tn, fp, fn, tp = confusion_matrix(signal.y, y_pred, labels=[0,1]).ravel()\n    return tn, fp, fn, tp\n\ndef single_graph_eval_func_2(signals, node_losses_list):\n    y_true = np.concatenate([signal.y for signal in signals])\n    y_loss = []\n    for losses in node_losses_list:\n        y_loss.append(np.mean(losses.reshape(-1, 1)))\n            \n    precision_list, recall_list, thresholds = precision_recall_curve(y_true,y_loss)\n    f1_list = []\n    for precision, recall in zip(precision_list, recall_list):\n        if precision == 0 and recall == 0:\n            f1_list.append(0)\n        else:\n            f1_list.append(2 * (precision * recall) / (precision + recall))\n        \n    precision = precision_list[np.nanargmax(f1_list)]\n    recall = recall_list[np.nanargmax(f1_list)]\n    f1 = f1_list[np.nanargmax(f1_list)]\n    roc_auc = roc_auc_score(y_true,y_loss)\n    \n    return precision, recall, f1, roc_auc","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:20:14.905555Z","iopub.execute_input":"2023-08-26T00:20:14.905977Z","iopub.status.idle":"2023-08-26T00:20:14.927194Z","shell.execute_reply.started":"2023-08-26T00:20:14.905944Z","shell.execute_reply":"2023-08-26T00:20:14.926150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Function","metadata":{}},{"cell_type":"code","source":"def train_function(num_epoch, val_interval=100, start_val=0, save=False, save_dir=None):\n    global GLOBAL_EPOCH\n    \n    history = {}\n    history['train'] = {\n        \"loss\":[],\n        \"precision\":[],\n        \"recall\":[],\n        \"f1\":[],\n        \"roc_auc\":[],\n        \"time\":[]\n    }\n    history['val'] = {\n        \"loss\":[],\n        \"precision\":[],\n        \"recall\":[],\n        \"f1\":[],\n        \"roc_auc\":[],\n    }\n    history['save'] = []\n    \n    batch_signal = BatchSignal(signals=signals_train, batch_size=BATCH_SIZE, seq_len=MIN_LEN).to(device)\n    for i_epoch in range(1,num_epoch+1):\n        _start = time.time()    \n#         if i_epoch % 10: \n        del batch_signal\n        batch_signal = BatchSignal(signals=signals_train, batch_size=BATCH_SIZE, seq_len=MIN_LEN).to(device)\n        train_losses = train_loop(batch_signal, model, loss_f, optimizer, device, split_loss=False)\n        _end = time.time()\n        if i_epoch >= start_val and i_epoch % val_interval == 0:\n            \n#             batch_signal = BatchSignal(signals=signals_train, batch_size=BATCH_SIZE, seq_len=MIN_LEN).to(device)        \n#             node_losses_list_train = test_loop(batch_signal, model, loss_f, optimizer, device, split_loss=True)\n#             precision_train, recall_train, f1_train, roc_auc_train = batch_graph_eval_func_2(batch_signal, node_losses_list_train)\n            \n            f1_list = []\n            roc_auc_list = []\n            for _ in range(5):\n                batch_signal_val = BatchSignal(signals=signals_val, batch_size=BATCH_SIZE, seq_len=MIN_LEN).to(device)\n                node_losses_list_val = test_loop(batch_signal_val, model, loss_f, optimizer, device, split_loss=True)\n                precision_val, recall_val, f1_val, roc_auc_val = batch_graph_eval_func_2(batch_signal_val, node_losses_list_val)\n                f1_list.append(f1_val)\n                roc_auc_list.append(roc_auc_val)\n#             train_losses = np.concatenate(node_losses_list_train)\n            val_losses = np.concatenate(node_losses_list_val)\n            \n#             history['train']['loss'].append(np.mean(train_losses))\n#             history['train']['precision'].append(precision_train)\n#             history['train']['recall'].append(recall_train)\n#             history['train']['f1'].append(f1_train)\n#             history['train']['roc_auc'].append(roc_auc_train)\n            history['train']['time'].append(_end-_start)\n            \n            history['val']['loss'].append(np.mean(val_losses))\n#             history['val']['precision'].append(precision_val)\n#             history['val']['recall'].append(recall_val)\n            history['val']['f1'].append(np.mean(f1_val))\n            history['val']['roc_auc'].append(np.mean(roc_auc_val))\n                \n            print(f\"{i_epoch+GLOBAL_EPOCH}/{num_epoch+GLOBAL_EPOCH}: cost {_end-_start:.4f}s train loss {np.mean(train_losses):.4f} val loss {np.mean(val_losses):.4f}\")\n            t = Texttable()\n            t.add_rows([\n                ['', 'F1', 'AUC_ROC'], \n#                 ['Train', precision_train, recall_train, f1_train, roc_auc_train], \n                ['Val', f1_val, roc_auc_val]])\n            print(t.draw())\n            \n            if save:\n                if save_dir is not None:\n                    os.makedirs(save_dir,exist_ok=True)\n                    path = os.path.join(save_dir, f\"{i_epoch+GLOBAL_EPOCH}.pt\")\n                else:\n                    path =  f\"{i_epoch+GLOBAL_EPOCH}.pt\"\n                torch.save(model.state_dict(), path)\n                history['save'].append(path)\n        else:\n            if i_epoch % 50 == 0:\n                history['train']['time'].append(_end-_start)\n                print(f\"{i_epoch+GLOBAL_EPOCH}/{num_epoch+GLOBAL_EPOCH}: cost {_end-_start:.4f}s train loss {np.mean(train_losses):.4f}\")\n    GLOBAL_EPOCH += num_epoch\n    return history","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:20:15.925740Z","iopub.execute_input":"2023-08-26T00:20:15.926142Z","iopub.status.idle":"2023-08-26T00:20:15.943994Z","shell.execute_reply.started":"2023-08-26T00:20:15.926100Z","shell.execute_reply":"2023-08-26T00:20:15.942741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IN_CHANNELS = signals_train[0].node_attr.shape[1]\nMIN_LEN=10\nBATCH_SIZE = 50","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:20:16.407896Z","iopub.execute_input":"2023-08-26T00:20:16.408280Z","iopub.status.idle":"2023-08-26T00:20:16.414164Z","shell.execute_reply.started":"2023-08-26T00:20:16.408249Z","shell.execute_reply":"2023-08-26T00:20:16.412017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Structure Selection\nout_channels_range = [16,32]\ngcn_channels_range = [64,128,256]\n\ncombinations = list(product(out_channels_range, gcn_channels_range))\nprint(len(combinations))\n\nhistory_list = [] \nfor out_channels, gcn_channels in combinations:\n    GLOBAL_EPOCH = 0\n    print(out_channels, gcn_channels)\n    model = STAE(\n        in_channels=IN_CHANNELS, \n        out_channels=out_channels, \n        gcn_channels=gcn_channels,\n        embed_layers=[128,512,256],\n        decide_layers=[256,128,128,64],\n    )\n\n    # model = torch.load(\n    #     \"/kaggle/input/tgae-model-saved/TGAE2_GRUConv_50_5.7319_5.8686.model\",\n    #     map_location=torch.device(device)\n    # )\n\n    # loss_f = torch.nn.CrossEntropyLoss()\n    loss_f = torch.nn.MSELoss(reduction = 'none')\n    optimizer = torch.optim.Adam(model.parameters(), lr = 5e-4)\n\n    model = model.to(device)\n    loss_f = loss_f.to(device)\n    \n    history = train_function(1000,50,400, save=True, save_dir=f\"{out_channels}_{gcn_channels}\")\n    history_list.append(history)\n    \n    del model\n    del loss_f\n    del optimizer\n    torch.cuda.empty_cache()\n    print(\"---------------------------------------------------------------------------\")\nfor (out_channels, gcn_channels),history in zip(combinations,history_list):\n    print(out_channels, gcn_channels, history['train']['f1'][np.argmax(history['val']['f1'])], history['val']['f1'][np.argmax(history['val']['f1'])])\n\nimport pickle\nwith open('history_list.pkl','wb') as f:\n    pickle.dump(history_list,f)\nraise","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:20:16.800979Z","iopub.execute_input":"2023-08-26T00:20:16.801675Z","iopub.status.idle":"2023-08-26T00:53:40.484898Z","shell.execute_reply.started":"2023-08-26T00:20:16.801639Z","shell.execute_reply":"2023-08-26T00:53:40.483569Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (out_channels, gcn_channels),history in zip(combinations,history_list):\n    print(np.argmax(history['val']['f1'])*50+400, out_channels, gcn_channels, history['val']['f1'][np.argmax(history['val']['f1'])], history['val']['roc_auc'][np.argmax(history['val']['f1'])])","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:54:37.682787Z","iopub.execute_input":"2023-08-26T00:54:37.683205Z","iopub.status.idle":"2023-08-26T00:54:37.692278Z","shell.execute_reply.started":"2023-08-26T00:54:37.683171Z","shell.execute_reply":"2023-08-26T00:54:37.691118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (out_channels, gcn_channels),history in zip(combinations,history_list):\n    print(f\"{history['val']['f1'][np.argmax(history['val']['f1'])]:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:55:28.559428Z","iopub.execute_input":"2023-08-26T00:55:28.559799Z","iopub.status.idle":"2023-08-26T00:55:28.566052Z","shell.execute_reply.started":"2023-08-26T00:55:28.559767Z","shell.execute_reply":"2023-08-26T00:55:28.564887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (out_channels, gcn_channels),history in zip(combinations,history_list):\n    print(np.argmax(history['val']['f1'])*50+400, out_channels, gcn_channels, history['val']['f1'][np.argmax(history['val']['f1'])])\n#     path = history['save'][np.argmax(history['val']['f1'])]\n    path = history['save'][-1]\n    \n    model = STAE(\n        in_channels=IN_CHANNELS, \n        out_channels=out_channels, \n        gcn_channels=gcn_channels,\n        embed_layers=[128,512,256],\n        decide_layers=[256,128,128,64],\n        dropout=0.2\n    )\n\n    loss_f = torch.nn.MSELoss(reduction = 'none')\n    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n\n    model = model.to(device)\n    loss_f = loss_f.to(device)\n    \n    model.load_state_dict(torch.load(path))\n    model.eval()\n\n    print(\"Evaluate on whole dataset:\")\n    node_losses_list_train = []\n    for i_signal, signal in enumerate(signals_train):\n        signal.to(device)\n        node_losses_list = test_loop(signal, model, loss_f, optimizer, device, split_loss=True)\n        node_losses_list_train += node_losses_list\n\n    precision_train, recall_train, f1_train, roc_auc_train = single_graph_eval_func_2(signals_train, node_losses_list_train)\n\n    node_losses_list_val = []\n    for i_signal, signal in enumerate(signals_val):\n        signal.to(device)\n        node_losses_list = test_loop(signal, model, loss_f, optimizer, device, split_loss=True)\n        node_losses_list_val += node_losses_list\n\n    precision_val, recall_val, f1_val, roc_auc_val = single_graph_eval_func_2(signals_val, node_losses_list_val)\n\n    t = Texttable()\n    t.add_rows([\n        ['', 'Precision', 'Recall', 'F1', 'AUC_ROC'], \n        ['Train', precision_train, recall_train, f1_train, roc_auc_train], \n        ['Val', precision_val, recall_val, f1_val, roc_auc_val]])\n    print(t.draw())","metadata":{"execution":{"iopub.status.busy":"2023-08-26T01:02:11.541372Z","iopub.execute_input":"2023-08-26T01:02:11.541816Z","iopub.status.idle":"2023-08-26T01:06:17.986805Z","shell.execute_reply.started":"2023-08-26T01:02:11.541777Z","shell.execute_reply":"2023-08-26T01:06:17.985753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select LR,DR\n\nlr_range = [5e-4,1e-3]\ndropout_range= [0, 0.2, 0.6]\n\ncombinations = list(product(lr_range,dropout_range))\nprint(len(combinations))\nhistory_list = [] \nfor lr, dropout in combinations:\n    GLOBAL_EPOCH = 0\n    print(lr, dropout)\n    model = STAE(\n        in_channels=IN_CHANNELS, \n        out_channels=16, \n        gcn_channels=256,\n        embed_layers=[128,512,256],\n        decide_layers=[256,128,128,64],\n        dropout=dropout\n    )\n\n    # model = torch.load(\n    #     \"/kaggle/input/tgae-model-saved/TGAE2_GRUConv_50_5.7319_5.8686.model\",\n    #     map_location=torch.device(device)\n    # )\n\n    # loss_f = torch.nn.CrossEntropyLoss()\n    loss_f = torch.nn.MSELoss(reduction = 'none')\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    model = model.to(device)\n    loss_f = loss_f.to(device)\n    \n    history = train_function(1000,50,400, save=True, save_dir=f\"{lr}_{dropout}\")\n    history_list.append(history)\n\n    del model\n    del loss_f\n    del optimizer\n    torch.cuda.empty_cache()\n    print(\"---------------------------------------------------------------------------\")\n    \nfor (lr, dropout),history in zip(combinations,history_list):\n    print(np.argmax(history['val']['f1'])*50+400, lr, dropout, history['val']['f1'][np.argmax(history['val']['f1'])])\n\nimport pickle\nwith open('history_list.pkl','wb') as f:\n    pickle.dump(history_list,f)\nraise","metadata":{"execution":{"iopub.status.busy":"2023-08-26T01:14:14.795550Z","iopub.execute_input":"2023-08-26T01:14:14.795947Z","iopub.status.idle":"2023-08-26T01:55:13.592931Z","shell.execute_reply.started":"2023-08-26T01:14:14.795913Z","shell.execute_reply":"2023-08-26T01:55:13.591567Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (lr, dropout),history in zip(combinations,history_list):\n    print(np.argmax(history['val']['f1'])*50+400, lr, dropout, history['val']['f1'][np.argmax(history['val']['f1'])])\n    path = history['save'][np.argmax(history['val']['f1'])]\n    \n    model = STAE(\n        in_channels=IN_CHANNELS, \n        out_channels=16, \n        gcn_channels=256,\n        embed_layers=[128,512,256],\n        decide_layers=[256,128,128,64],\n        dropout=dropout\n    )\n\n    loss_f = torch.nn.MSELoss(reduction = 'none')\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    model = model.to(device)\n    loss_f = loss_f.to(device)\n    \n    model.load_state_dict(torch.load(path))\n    model.eval()\n\n    print(\"Evaluate on whole dataset:\")\n    \n#     node_losses_list_train = []\n#     for i_signal, signal in enumerate(signals_train):\n#         signal.to(device)\n#         node_losses_list = test_loop(signal, model, loss_f, optimizer, device, split_loss=True)\n#         node_losses_list_train += node_losses_list\n\n#     precision_train, recall_train, f1_train, roc_auc_train = single_graph_eval_func_2(signals_train, node_losses_list_train)\n    \n    privesc_signals_val = []\n    privesc_losses_list_val = []\n    dos_signals_val = []\n    dos_losses_list_val = []\n    \n    node_losses_list_val = []\n    for i_signal, signal in enumerate(signals_val):\n        signal.to(device)\n        node_losses_list = test_loop(signal, model, loss_f, optimizer, device, split_loss=True)\n        node_losses_list_val += node_losses_list\n        if signal.type == 'privesc':\n            privesc_signals_val.append(signal)\n            privesc_losses_list_val += node_losses_list\n        if signal.type == 'dos':\n            dos_signals_val.append(signal)\n            dos_losses_list_val += node_losses_list\n\n    precision_val, recall_val, f1_val, roc_auc_val = single_graph_eval_func_2(signals_val, node_losses_list_val)\n    precision_privesc, recall_privesc, f1_privesc, roc_auc_privesc = single_graph_eval_func_2(privesc_signals_val, privesc_losses_list_val)\n    precision_dos, recall_dos, f1_dos, roc_auc_dos = single_graph_eval_func_2(dos_signals_val, dos_losses_list_val)\n\n    t = Texttable()\n    t.add_rows([\n        ['', 'Precision', 'Recall', 'F1', 'AUC_ROC'], \n        ['ALL', precision_val, recall_val, f1_val, roc_auc_val], \n        ['privesc', precision_privesc, recall_privesc, f1_privesc, roc_auc_privesc],\n        ['dos',precision_dos, recall_dos, f1_dos, roc_auc_dos],\n    \n    ])\n    print(t.draw())\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-26T02:36:33.473577Z","iopub.execute_input":"2023-08-26T02:36:33.474023Z","iopub.status.idle":"2023-08-26T02:38:38.155053Z","shell.execute_reply.started":"2023-08-26T02:36:33.473989Z","shell.execute_reply":"2023-08-26T02:38:38.154055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" model = STAE(\n        in_channels=IN_CHANNELS, \n        out_channels=16, \n        gcn_channels=256,\n        embed_layers=[128,512,256],\n        decide_layers=[256,128,128,64],\n        dropout=dropout\n    )\n\nloss_f = torch.nn.MSELoss(reduction = 'none')\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\nmodel = model.to(device)\nloss_f = loss_f.to(device)\n\nmodel.load_state_dict(torch.load(path))\nmodel.eval()\n\nprint(\"Evaluate on whole dataset:\")\nnode_losses_list_train = []\nfor i_signal, signal in enumerate(signals_train):\n    signal.to(device)\n    node_losses_list = test_loop(signal, model, loss_f, optimizer, device, split_loss=True)\n    node_losses_list_train += node_losses_list\n\nprecision_train, recall_train, f1_train, roc_auc_train = single_graph_eval_func_2(signals_train, node_losses_list_train)\n\nnode_losses_list_val = []\nfor i_signal, signal in enumerate(signals_val):\n    signal.to(device)\n    node_losses_list = test_loop(signal, model, loss_f, optimizer, device, split_loss=True)\n    node_losses_list_val += node_losses_list\n\nprecision_val, recall_val, f1_val, roc_auc_val = single_graph_eval_func_2(signals_val, node_losses_list_val)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:12:38.340712Z","iopub.status.idle":"2023-08-26T00:12:38.341414Z","shell.execute_reply.started":"2023-08-26T00:12:38.341171Z","shell.execute_reply":"2023-08-26T00:12:38.341193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Single model running\n\nGLOBAL_EPOCH = 0\nmodel = STAE(\n    in_channels=IN_CHANNELS, \n    out_channels=32, \n    gcn_channels=32,\n    embed_layers=[128,512,256],\n    decide_layers=[256,128,128,64],\n#     bidirectional=True,\n)\n\n# model = torch.load(\n#     \"/kaggle/input/tgae-model-saved/TGAE2_GRUConv_50_5.7319_5.8686.model\",\n#     map_location=torch.device(device)\n# )\n\n# loss_f = torch.nn.CrossEntropyLoss()\nloss_f = torch.nn.MSELoss(reduction = 'none')\noptimizer = torch.optim.Adam(model.parameters(), lr = 5e-4)\n\nmodel = model.to(device)\nloss_f = loss_f.to(device)\n\nhistory = train_function(200,200,100)\n# history_list.append(history)\nprint(np.mean(history['train']['time']))\n\nraise","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:12:38.342659Z","iopub.status.idle":"2023-08-26T00:12:38.343354Z","shell.execute_reply.started":"2023-08-26T00:12:38.343112Z","shell.execute_reply":"2023-08-26T00:12:38.343134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn\nroc_auc = sklearn.metrics.auc(fpr_list, tpr_list)\nprint(roc_auc)\ndisplay = sklearn.metrics.RocCurveDisplay(fpr=fpr_list, tpr=tpr_list, roc_auc=roc_auc,estimator_name='example estimator')\ndisplay.plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:12:38.344652Z","iopub.status.idle":"2023-08-26T00:12:38.345385Z","shell.execute_reply.started":"2023-08-26T00:12:38.345132Z","shell.execute_reply":"2023-08-26T00:12:38.345156Z"},"trusted":true},"execution_count":null,"outputs":[]}]}