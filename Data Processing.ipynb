{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nuse_gpu = torch.cuda.is_available()\nprint(torch.__version__)\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-08-28T01:04:05.998645Z","iopub.execute_input":"2023-08-28T01:04:05.99906Z","iopub.status.idle":"2023-08-28T01:04:10.227962Z","shell.execute_reply.started":"2023-08-28T01:04:05.999033Z","shell.execute_reply":"2023-08-28T01:04:10.226982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initialize for CPU & GPU","metadata":{}},{"cell_type":"code","source":"if use_gpu:\n    !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric --no-index --find-links=file:///kaggle/input/torch-geometric\n#     !pip install torch_geometric_temporal  \nelse:\n    !pip install /kaggle/input/pytorch-geometric-cpu/torch_scatter-2.1.1pt20cpu-cp310-cp310-linux_x86_64.whl\n    !pip install /kaggle/input/pytorch-geometric-cpu/torch_sparse-0.6.17pt20cpu-cp310-cp310-linux_x86_64.whl\n    !pip install /kaggle/input/pytorch-geometric-cpu/torch_cluster-1.6.1pt20cpu-cp310-cp310-linux_x86_64.whl\n    !pip install /kaggle/input/pytorch-geometric-cpu/torch_spline_conv-1.2.2pt20cpu-cp310-cp310-linux_x86_64.whl\n    !pip install /kaggle/input/pytorch-geometric-cpu/torch_geometric-2.3.1-py3-none-any.whl\n#     !pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n#     !pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n#     !pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n#     !pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n#     !pip install torch_spline_conv -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n#     !pip install git+https://github.com/pyg-team/pytorch_geometric.git\n#     !pip install torch_geometric_temporal","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-28T01:04:10.229964Z","iopub.execute_input":"2023-08-28T01:04:10.23126Z","iopub.status.idle":"2023-08-28T01:04:24.024396Z","shell.execute_reply.started":"2023-08-28T01:04:10.231224Z","shell.execute_reply":"2023-08-28T01:04:24.023261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport re\nimport json\nimport random\nfrom scipy.special import perm\nfrom itertools import combinations,chain\nfrom typing import List, Union\nfrom torch_geometric.data import Data\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport matplotlib.pyplot as plt\nimport pickle\nimport time\nfrom torch import nn\nfrom torch.nn import Linear as Lin\nfrom torch.nn import ReLU, LeakyReLU\nfrom torch.nn import Sequential as Seq\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, GINConv\nfrom torch_geometric.data import Batch\nfrom torch import autograd\nfrom torch_geometric.nn.models import InnerProductDecoder\nfrom torch_geometric.utils import to_dense_adj\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score\n\nfrom texttable import Texttable\nfrom itertools import product","metadata":{"execution":{"iopub.status.busy":"2023-08-28T01:04:24.026489Z","iopub.execute_input":"2023-08-28T01:04:24.026867Z","iopub.status.idle":"2023-08-28T01:04:25.500882Z","shell.execute_reply.started":"2023-08-28T01:04:24.026824Z","shell.execute_reply":"2023-08-28T01:04:25.499868Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataLoader","metadata":{}},{"cell_type":"code","source":"Edge_Flag = List[Union[np.ndarray, None]]\nEdge_Index = List[Union[np.ndarray, None]]\nEdge_Attr = List[Union[np.ndarray, None]]\n\nNode_Flag = List[Union[np.ndarray, None]]\nNode_Index = List[Union[np.ndarray, None]]\nNode_Attr = List[Union[np.ndarray, None]]\n\n\n\nclass GraphSignal(object):\n    # dynamic node static node attr dynamic edge and edge attr\n    def __init__(\n        self,\n        edge_flag: Edge_Flag,\n        edge_index: Edge_Index,\n        edge_attr: Edge_Attr,\n        node_flag: Node_Flag,\n        node_index: Node_Index,\n        node_attr: Node_Attr,\n        ts_list: List,\n        path: str,\n    ):\n        \n        self.raw_edge_flag = torch.LongTensor(edge_flag[:-1])\n        self.raw_edge_index = torch.LongTensor(edge_index).T\n        self.raw_edge_attr = edge_attr\n        self.raw_node_attr = node_attr \n        self.node_flag = torch.LongTensor(node_flag[:-1])\n        self.node_index = torch.LongTensor(node_index)\n        \n        self.ts_list = ts_list\n        \n        self.path = path\n        \n        self.node_attr = None\n        self.edge_flag = None\n        self.edge_index = None\n        \n        self.y = None\n        \n        self._set_snapshot_count()\n        self._set_node_count()\n\n    def _set_snapshot_count(self):\n        self.snapshot_count = len(self.ts_list)\n    \n    def _set_node_count(self):\n        self.node_count = self.raw_node_attr.shape[0]\n    \n    def encode_edge_attr(self, enocder):\n        self.edge_attr_encoded = torch.FloatTensor(enocder.transform(self.raw_edge_attr))\n        \n    def encode_node_attr(self, enocder):\n        self.node_attr_encoded = torch.FloatTensor(enocder.transform(self.raw_node_attr))\n        \n    def extend_node_attr(self):\n        if self.edge_attr_encoded is None:\n            print(\"Edge Attr Need to be Encoded!\")\n            raise\n        node_index = self.node_index\n        node_attr = self.node_attr_encoded.index_select(dim=0,index=self.node_index)\n        node_flag = self.node_flag\n        \n        edge_index = self.raw_edge_index\n        edge_attr = self.edge_attr_encoded\n        edge_flag = self.raw_edge_flag\n        \n        node_index_split = torch.tensor_split(node_index, node_flag)\n        node_attr_split = torch.tensor_split(node_attr, node_flag)\n        edge_index_split = torch.tensor_split(edge_index, edge_flag, dim=1)\n        edge_attr_split = torch.tensor_split(edge_attr, edge_flag)\n\n        base = 0\n        new_node_attr = []\n        new_edge_flag = []\n        new_edge_index = []\n        \n        for i_snapshot in range(self.snapshot_count):\n            _node_index = node_index_split[i_snapshot]\n            _node_attr = node_attr_split[i_snapshot]\n            _edge_index = edge_index_split[i_snapshot]\n            _edge_attr = edge_attr_split[i_snapshot]\n\n            if _edge_index.shape[1] != _edge_attr.shape[0]:\n                print(i_snapshot, edge_index.shape, _edge_attr.shape)\n                raise\n            if _edge_index.shape[1] > 0:\n                index_dict = {}\n                for i_edge in range(_edge_index.shape[1]):\n                    index_tuple = tuple(_edge_index[:,i_edge].tolist())\n                    if index_tuple in index_dict:\n                        index_dict[index_tuple] += [i_edge]\n                    else:\n                        index_dict[index_tuple] = [i_edge]\n\n                _new_edge_index = []\n                _new_edge_attr = []\n                for key in index_dict.keys():\n                    _new_edge_index.append(key)\n                    _new_edge_attr.append(torch.sum(_edge_attr.index_select(0, torch.LongTensor(index_dict[key])),dim=0).unsqueeze(0))\n\n                _new_edge_index = torch.LongTensor(_new_edge_index).T\n                _new_edge_attr = torch.cat(_new_edge_attr,dim=0)\n                \n                base += _new_edge_index.shape[1]\n                new_edge_index.append(_new_edge_index)\n\n#                 _source_attr = torch.zeros((_node_attr.shape[0], _new_edge_attr.shape[1])).to(device)\n#                 _target_attr = torch.zeros((_node_attr.shape[0], _new_edge_attr.shape[1])).to(device)\n#                 _source_attr.index_add_(0, _new_edge_index[0], _new_edge_attr)\n#                 _target_attr.index_add_(0, _new_edge_index[1], _new_edge_attr)\n#                 new_node_attr.append(torch.cat([_node_attr,_source_attr,_target_attr], dim=1))\n\n                _node_attr_extend = torch.zeros((_node_attr.shape[0], _new_edge_attr.shape[1]))\n                _node_attr_extend.index_add_(0, _new_edge_index[0], _new_edge_attr)\n                _node_attr_extend.index_add_(0, _new_edge_index[1], _new_edge_attr)\n                new_node_attr.append(torch.cat([_node_attr,_node_attr_extend], dim=1)) \n                \n            new_edge_flag.append(base)\n        \n        self.node_attr = torch.cat(new_node_attr, dim=0)\n        self.edge_flag = torch.LongTensor(new_edge_flag)\n        self.edge_index = torch.cat(new_edge_index,dim=1)\n    \n    def remove_init_stop(self, threshold, period,):\n        node_index = self.node_index\n        node_attr = self.node_attr\n        node_flag = self.node_flag\n\n        edge_index = self.edge_index\n        edge_flag = self.edge_flag\n        \n        raw_edge_index = self.raw_edge_index\n        raw_edge_attr = self.raw_edge_attr\n        raw_edge_flag = self.raw_edge_flag\n\n        node_index_split = torch.tensor_split(node_index, node_flag)\n        node_attr_split = torch.tensor_split(node_attr, node_flag)\n        edge_index_split = torch.tensor_split(edge_index, edge_flag, dim=1)\n        \n        raw_edge_index_split = torch.tensor_split(raw_edge_index, raw_edge_flag, dim=1)\n        raw_edge_attr_split = np.split(raw_edge_attr, raw_edge_flag)\n\n        i_init = None\n        i_stop = None\n        for i_snapshot, node_num in enumerate(torch.diff(self.node_flag)):\n            if node_num > threshold:\n                i_init = i_snapshot+1\n                break\n\n        for i_snapshot, node_num in enumerate(torch.flip(torch.diff(self.node_flag),dims=[0])):\n            if node_num > threshold:\n                i_stop = self.node_flag.shape[0]-1-i_snapshot\n                break\n        \n        new_node_attr = torch.cat(node_attr_split[i_init+1+period:i_stop-period],dim=0)\n        new_node_index = torch.cat(node_index_split[i_init+1+period:i_stop-period],dim=0)\n        new_edge_index = torch.cat(edge_index_split[i_init+1+period:i_stop-period],dim=1)\n        new_raw_edge_index = torch.cat(raw_edge_index_split[i_init+1+period:i_stop-period], dim=1)\n        new_raw_edge_attr = np.concatenate(raw_edge_attr_split[i_init+1+period:i_stop-period])\n\n        new_node_flag = node_flag[i_init+period+1:i_stop-period-1]-node_flag[i_init+period]\n        new_edge_flag = edge_flag[i_init+period+1:i_stop-period-1]-edge_flag[i_init+period]\n        new_raw_edge_flag = raw_edge_flag[i_init+period+1:i_stop-period-1]-raw_edge_flag[i_init+period]\n        \n        self.node_attr = new_node_attr\n        self.node_index = new_node_index\n        self.edge_index = new_edge_index\n        self.raw_edge_attr = new_raw_edge_attr\n        self.raw_edge_index = new_raw_edge_index\n        \n        self.node_flag = new_node_flag\n        self.edge_flag = new_edge_flag\n        self.raw_edge_flag = new_raw_edge_flag\n        \n        self.ts_list = self.ts_list[i_init+1+period:i_stop-period]\n        \n        self._set_snapshot_count()\n    \n    def annotation2y(self, annotation, interval, overlap, offset= -30):\n        ts_list = self.ts_list\n        y = torch.zeros(self.snapshot_count, dtype=torch.long)\n        for i_ts, ts in enumerate(ts_list):\n            if ts < float(annotation[1])+offset and float(annotation[1])+offset <= ts+interval-overlap: \n                y[i_ts] = 1\n        self.y = y\n        self.type = annotation[0]\n    \n    def to(self,device):\n        self.node_attr = self.node_attr.to(device)\n        self.node_index = self.node_index.to(device)\n        self.edge_index = self.edge_index.to(device)\n    \n    def get_adj_list(self):\n        edge_index = self.edge_index\n        edge_flag = self.edge_flag\n        edge_index_split = torch.tensor_split(edge_index, edge_flag, dim=1)\n        adj_list = [torch.clamp(to_dense_adj(_edge_index)[0], min=0, max=1) for _edge_index in edge_index_split]\n        return adj_list\n\n    def __getitem__(self, time_index: int):\n        raise\n#         edge_index = self._get_edge_index(time_index)\n#         edge_attr = self._get_edge_attr(time_index)\n#         node_index,node_attr = self._get_node_index_attr(time_index)\n#         _timestamp = self._get_timestamp(time_index)\n\n#         snapshot = Data(\n#             edge_index=edge_index,\n#             edge_attr=edge_attr,\n#             node_index=node_index,\n#             node_attr=node_attr,\n#             timestamp=_timestamp\n#         )\n#         return snapshot\n\n    def __next__(self):\n        if self.t < self.snapshot_count:\n            snapshot = self[self.t]\n            self.t = self.t + 1\n            return snapshot\n        else:\n            self.t = 0\n            raise StopIteration\n\n    def __iter__(self):\n        self.t = 0\n        return self\n    \n    def __len__(self):\n        return self.snapshot_count\n\n\nclass GraphDatasetLoader(object):\n    def __init__(self,input_path=\"\"):\n        self.input_path = input_path\n        self._read_data()\n    \n    def _read_data(self):\n        self._dataset = np.load(self.input_path)\n\n    def get_dataset(self): # -> DynamicGraphTemporalSignal:\n        dataset = GraphSignal(\n            edge_flag = self._dataset['edge_flag'],\n            edge_index = self._dataset['edge_index'],\n            edge_attr = self._dataset['edge_attr'],\n            node_flag = self._dataset['node_flag'],\n            node_index = self._dataset['node_index'],\n            node_attr = self._dataset['node_attr'],\n            ts_list = self._dataset['timestamp'],\n            path = self.input_path\n        )\n        return dataset","metadata":{"execution":{"iopub.status.busy":"2023-08-28T01:04:25.503141Z","iopub.execute_input":"2023-08-28T01:04:25.503448Z","iopub.status.idle":"2023-08-28T01:04:25.547547Z","shell.execute_reply.started":"2023-08-28T01:04:25.503422Z","shell.execute_reply":"2023-08-28T01:04:25.546352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read Data","metadata":{}},{"cell_type":"code","source":"data_dir_0 = '/kaggle/input/dissertation-data'\ndata_dir_1_list = [\n    '2021-09-24-umbrella-experiment-64run-fran',\n    '2021-09-27-RaspVM-experiment-64run-env1',\n    '2021-09-29-RaspVM-experiment-64run-env1'\n]\n\n\nsignals = []\nannotation = []\n\nfor data_dir_1 in data_dir_1_list:\n    with open(os.path.join(data_dir_0, data_dir_1, \"annotated.json\")) as f:\n        annotated_dict = json.load(f)\n\n    for data_dir_2 in os.listdir(os.path.join(data_dir_0, data_dir_1)):\n        if data_dir_2 == \"annotated.json\":\n            continue\n        r = re.compile(\".*.npz\")\n        graph_files = list(filter(r.match, os.listdir(os.path.join(data_dir_0, data_dir_1, data_dir_2))))\n\n        if len(graph_files) > 1:\n            print(\"Multiple Graph Files!\")\n            raise\n        if len(graph_files) == 0:\n            print(\"Not Found Graph File!\")\n            continue\n\n        dataloader = GraphDatasetLoader(os.path.join(data_dir_0, data_dir_1, data_dir_2, graph_files[0]))\n        signal = dataloader.get_dataset()\n        signals.append(signal)\n        annotation.append(annotated_dict[data_dir_2])\n\nsignals_train, signals_val, annotation_train, annotation_val = train_test_split(signals, annotation, test_size=0.5, random_state=1365)","metadata":{"execution":{"iopub.status.busy":"2023-08-28T01:04:25.549525Z","iopub.execute_input":"2023-08-28T01:04:25.549993Z","iopub.status.idle":"2023-08-28T01:04:29.472658Z","shell.execute_reply.started":"2023-08-28T01:04:25.549958Z","shell.execute_reply":"2023-08-28T01:04:29.471588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_interval = 60\n_overlap = 30\n\nnode_num_list = []\nfor signal in signals_train:\n    node_num_list += torch.diff(signal.node_flag).tolist()\n    \nthreshold = np.median(node_num_list)/2\nperiod = 3\n\nprint(f\"Threshold = {threshold} Period = {period}\")\n\nnode_attr_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\nnode_attr_encoder = node_attr_encoder.fit(np.concatenate([sample.raw_node_attr for sample in signals_train]))\n\nedge_attr_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\nedge_attr_encoder = edge_attr_encoder.fit(np.concatenate([sample.raw_edge_attr for sample in signals_train]))\n\nfor i_signal, (signal, annotation) in enumerate(zip(signals_train, annotation_train)):\n    signal.encode_node_attr(node_attr_encoder)\n    signal.encode_edge_attr(edge_attr_encoder)\n    signal.extend_node_attr()\n    signal.remove_init_stop(threshold, period)\n    signal.node_attr = F.tanh(signal.node_attr)\n    signal.annotation2y(annotation, _interval, _overlap)\n    \nfor i_signal, (signal, annotation) in enumerate(zip(signals_val, annotation_val)):\n    signal.encode_node_attr(node_attr_encoder)\n    signal.encode_edge_attr(edge_attr_encoder)\n    signal.extend_node_attr()\n    signal.remove_init_stop(threshold, period)\n    signal.node_attr = F.tanh(signal.node_attr)\n    signal.annotation2y(annotation, _interval, _overlap)\n\n# for signal in signals_train:\n#     signal.to(device)\n\n# for signal in signals_val:\n#     signal.to(device)\n    \n    \nIN_CHANNELS = signals_train[0].node_attr.shape[1]\n# EDGE_CHANNELS = signals_train[0].edge_attr_encoded.shape[1]","metadata":{"execution":{"iopub.status.busy":"2023-08-28T01:04:29.477354Z","iopub.execute_input":"2023-08-28T01:04:29.477723Z","iopub.status.idle":"2023-08-28T01:05:31.15499Z","shell.execute_reply.started":"2023-08-28T01:04:29.477689Z","shell.execute_reply":"2023-08-28T01:05:31.153966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist([signal.snapshot_count for signal in signals_train], range=(0,50), bins=50)\nplt.show()\nplt.hist([signal.snapshot_count for signal in signals_val], range=(0,50), bins=50)\nplt.show()\nplt.hist([signal.snapshot_count for signal in signals_test], range=(0,50), bins=50)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-28T01:05:47.770312Z","iopub.execute_input":"2023-08-28T01:05:47.770724Z","iopub.status.idle":"2023-08-28T01:05:48.76417Z","shell.execute_reply.started":"2023-08-28T01:05:47.770695Z","shell.execute_reply":"2023-08-28T01:05:48.763184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for signal in signals_train[:30]:\n    print(signal.type,list(map(int,torch.diff(signal.node_flag))))","metadata":{"execution":{"iopub.status.busy":"2023-08-28T01:09:25.282443Z","iopub.execute_input":"2023-08-28T01:09:25.282806Z","iopub.status.idle":"2023-08-28T01:09:25.293051Z","shell.execute_reply.started":"2023-08-28T01:09:25.282776Z","shell.execute_reply":"2023-08-28T01:09:25.29206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MIN_LEN = 10\n\ni_signal = 0\nwhile i_signal < len(signals_train):\n    if signals_train[i_signal].snapshot_count < MIN_LEN:\n        signals_train.pop(i_signal)\n    else:\n        i_signal += 1\nplt.hist([signal.snapshot_count for signal in signals_train], range=(0,30), bins=30)\nplt.show()\n\ni_signal = 0\nwhile i_signal < len(signals_val):\n    if signals_val[i_signal].snapshot_count < MIN_LEN:\n        signals_val.pop(i_signal)\n    else:\n        i_signal += 1\nplt.hist([signal.snapshot_count for signal in signals_val], range=(0,30), bins=30)\nplt.show()\n\nimport pickle\n\nwith open('signals_train.pkl','wb') as f:\n    pickle.dump(signals_train, f)\nwith open('signals_val.pkl','wb') as f:\n    pickle.dump(signals_val, f)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pickle\n\n# with open(\"/kaggle/input/dissertation-data/signals_train.pkl\", \"rb\") as f:\n#     signals_train = pickle.load(f)\n# with open(\"/kaggle/input/dissertation-data/signals_val.pkl\", \"rb\") as f:\n#     signals_val = pickle.load(f)\n# with open(\"/kaggle/input/dissertation-data/signals_test.pkl\", \"rb\") as f:\n#     signals_test = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:05:15.068956Z","iopub.execute_input":"2023-08-26T00:05:15.069383Z","iopub.status.idle":"2023-08-26T00:05:32.143362Z","shell.execute_reply.started":"2023-08-26T00:05:15.06935Z","shell.execute_reply":"2023-08-26T00:05:32.142364Z"},"trusted":true},"execution_count":null,"outputs":[]}]}