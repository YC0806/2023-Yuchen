{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nuse_gpu = torch.cuda.is_available()\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:51:46.594720Z","iopub.execute_input":"2023-07-22T11:51:46.595861Z","iopub.status.idle":"2023-07-22T11:51:50.206334Z","shell.execute_reply.started":"2023-07-22T11:51:46.595832Z","shell.execute_reply":"2023-07-22T11:51:50.205354Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"a = torch.LongTensor([[1,2,3,4,5]]).to(device)\nprint(a[0:3].device)\nprint(a[:,[1,3,4]].device)\nprint(a.T.device)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:51:50.208451Z","iopub.execute_input":"2023-07-22T11:51:50.209344Z","iopub.status.idle":"2023-07-22T11:51:53.219764Z","shell.execute_reply.started":"2023-07-22T11:51:50.209308Z","shell.execute_reply":"2023-07-22T11:51:53.218734Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"cuda:0\ncuda:0\ncuda:0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Initialize for CPU & GPU","metadata":{}},{"cell_type":"code","source":"if device == 'cpu':\n    !pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n    !pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n    !pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n    !pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n    !pip install git+https://github.com/pyg-team/pytorch_geometric.git\n#     !pip install torch_geometric_temporal\nelse:\n    !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric --no-index --find-links=file:///kaggle/input/torch-geometric\n#     !pip install torch_geometric_temporal  ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-07-22T11:51:53.221146Z","iopub.execute_input":"2023-07-22T11:51:53.222753Z","iopub.status.idle":"2023-07-22T11:52:06.922565Z","shell.execute_reply.started":"2023-07-22T11:51:53.222719Z","shell.execute_reply":"2023-07-22T11:52:06.921399Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Looking in links: file:///kaggle/input/torch-geometric\nProcessing /kaggle/input/torch-geometric/torch_scatter-2.1.1-cp310-cp310-linux_x86_64.whl\nProcessing /kaggle/input/torch-geometric/torch_sparse-0.6.17-cp310-cp310-linux_x86_64.whl\nProcessing /kaggle/input/torch-geometric/torch_cluster-1.6.1-cp310-cp310-linux_x86_64.whl\nProcessing /kaggle/input/torch-geometric/torch_spline_conv-1.2.2-cp310-cp310-linux_x86_64.whl\nProcessing /kaggle/input/torch-geometric/torch_geometric-2.3.1-py3-none-any.whl\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-sparse) (1.10.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (4.64.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.23.5)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (2.28.2)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.0.9)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.2.2)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (5.9.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch-geometric) (2.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (2023.5.7)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.1.0)\nInstalling collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster, torch-geometric\nSuccessfully installed torch-cluster-1.6.1 torch-geometric-2.3.1 torch-scatter-2.1.1 torch-sparse-0.6.17 torch-spline-conv-1.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport re\nimport json\nfrom scipy.special import perm\nfrom itertools import combinations,chain\nfrom typing import List, Union\nfrom torch_geometric.data import Data\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport matplotlib.pyplot as plt\nimport pickle\nimport time\nfrom torch import nn\nfrom torch.nn import Linear as Lin\nfrom torch.nn import ReLU\nfrom torch.nn import Sequential as Seq\nimport torch.nn.functional as F\nfrom torch_geometric.nn import NNConv\nfrom torch import autograd\n\nfrom sklearn.model_selection import train_test_split","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-07-22T11:52:06.926314Z","iopub.execute_input":"2023-07-22T11:52:06.926711Z","iopub.status.idle":"2023-07-22T11:52:08.398473Z","shell.execute_reply.started":"2023-07-22T11:52:06.926676Z","shell.execute_reply":"2023-07-22T11:52:08.397477Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# DataLoader","metadata":{}},{"cell_type":"code","source":"Edge_Flag = List[Union[np.ndarray, None]]\nEdge_Indices = List[Union[np.ndarray, None]]\nEdge_Attr = List[Union[np.ndarray, None]]\n\nNode_Flag = List[Union[np.ndarray, None]]\nNode_Indices = List[Union[np.ndarray, None]]\nNode_Attr = List[Union[np.ndarray, None]]\nAdditional_Attrs = List[np.ndarray]\n\n\n\nclass GraphSignal(object):\n    # dynamic node static node attr dynamic edge and edge attr\n    def __init__(\n        self,\n        edge_flag: Edge_Flag,\n        edge_indices: Edge_Indices,\n        edge_attr: Edge_Attr,\n        node_flag: Node_Flag,\n        node_indices: Node_Indices,\n        node_attr: Node_Attr,\n    ):\n        \n        self.edge_flag = edge_flag \n        self.edge_indices = torch.LongTensor(edge_indices).T.to(device)\n        self.edge_attr = edge_attr\n        self.node_flag = node_flag\n        self.node_indices = torch.LongTensor(node_indices).to(device)\n        self.node_attr = node_attr\n        self.edge_attr_encoded = None\n        self.node_attr_encoded = None\n        \n        self._set_snapshot_count()\n\n    def _set_snapshot_count(self):\n        self.snapshot_count = len(self.edge_flag)\n    \n    def encode_edge_attr(self, enocder):\n        self.edge_attr_encoded = torch.FloatTensor(enocder.transform(self.edge_attr)).to(device)\n    \n    def encode_node_attr(self, enocder):\n        self.node_attr_encoded = torch.FloatTensor(enocder.transform(self.node_attr)).to(device)\n        \n    def _get_edge_index(self, time_index: int):\n        if time_index == 0:\n            _start = 0\n        else:\n            _start = self.edge_flag[time_index-1]\n        _end = self.edge_flag[time_index]\n        _edge_index = self.edge_indices[:,_start:_end]\n        return _edge_index\n\n    # def _get_edge_weight(self, time_index: int):\n    #     if self.edge_weights[time_index] is None:\n    #         return self.edge_weights[time_index]\n    #     else:\n    #         return torch.FloatTensor(self.edge_weights[time_index])\n\n    def _get_edge_attr(self, time_index: int):\n        if self.edge_attr_encoded is None:\n            print(\"Edge Attr Need to be Encoded!\")\n            raise\n        if time_index == 0:\n            _start = 0\n        else:\n            _start = self.edge_flag[time_index-1]\n        _end = self.edge_flag[time_index]\n        _edge_attr = self.edge_attr_encoded[_start:_end]\n        return _edge_attr\n    \n    def _get_node_index_attr(self, time_index: int):\n        if self.node_attr_encoded is None:\n            print(\"Node Attr Need to be Encoded!\")\n            raise\n        if time_index == 0:\n            _start = 0\n        else:\n            _start = self.node_flag[time_index-1]\n        _end = self.node_flag[time_index]\n        _node_index = self.node_indices[_start:_end]\n        _node_attr = self.node_attr_encoded[_node_index]\n        return _node_index,_node_attr\n\n\n    def __getitem__(self, time_index: int):\n        edge_index = self._get_edge_index(time_index)\n        edge_attr = self._get_edge_attr(time_index)\n        node_index,node_attr = self._get_node_index_attr(time_index)\n\n        snapshot = Data(\n            edge_index=edge_index,\n            edge_attr=edge_attr,\n            node_index=node_index,\n            node_attr=node_attr,\n        )\n        return snapshot\n\n    def __next__(self):\n        if self.t < self.snapshot_count:\n            snapshot = self[self.t]\n            self.t = self.t + 1\n            return snapshot\n        else:\n            self.t = 0\n            raise StopIteration\n\n    def __iter__(self):\n        self.t = 0\n        return self\n    \n    def __len__(self):\n        return self.snapshot_count\n\n\nclass GraphDatasetLoader(object):\n    def __init__(self,input_path=\"\"):\n        self.input_path = input_path\n        self._read_data()\n    \n    def _read_data(self):\n        self._dataset = np.load(self.input_path)\n\n    def get_dataset(self): # -> DynamicGraphTemporalSignal:\n        dataset = GraphSignal(\n            edge_flag = self._dataset['edge_flag'],\n            edge_indices = self._dataset['edge_index'],\n            edge_attr = self._dataset['edge_attr'],\n            node_flag = self._dataset['node_flag'],\n            node_indices = self._dataset['node_index'],\n            node_attr = self._dataset['node_attr'],\n        )\n        return dataset","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-07-22T11:52:08.400295Z","iopub.execute_input":"2023-07-22T11:52:08.401024Z","iopub.status.idle":"2023-07-22T11:52:08.425020Z","shell.execute_reply.started":"2023-07-22T11:52:08.400989Z","shell.execute_reply":"2023-07-22T11:52:08.423415Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"## MultiNNConv","metadata":{}},{"cell_type":"code","source":"class MultiNNConv(torch.nn.Module):\n    def __init__(self, in_channels, out_channels, edge_channels, gcn_hidden_nums, edge_hidden_nums, lin_hidden_nums):\n        super().__init__()\n        \n        def _create_edge_nn(edge_out_channels):\n            edge_nn = Seq()\n            pre_edge_h_num = edge_channels\n            for edge_h_num in edge_hidden_nums:\n                edge_nn.append(Lin(pre_edge_h_num,edge_h_num))\n                edge_nn.append(ReLU())\n                pre_edge_h_num = edge_h_num\n            edge_nn.append(Lin(pre_edge_h_num,edge_out_channels))\n            return edge_nn\n        \n        self.gcn_layers = nn.ModuleList()\n        pre_h_num = in_channels\n        for h_num in gcn_hidden_nums:\n            edge_nn = _create_edge_nn(pre_h_num*h_num)\n            self.gcn_layers.append(NNConv(pre_h_num, h_num, edge_nn, aggr='mean'))\n            pre_h_num = h_num\n\n        self.lin_net = Seq()\n        for h_num in lin_hidden_nums[:-1]:\n            self.lin_net.append(Lin(pre_h_num,h_num))\n            pre_h_num = h_num\n        self.lin_net.append(ReLU())\n        self.lin_net.append(Lin(pre_h_num,out_channels))\n\n    def forward(self, x, edge_index, edge_attr):\n        out = x\n        for conv in self.gcn_layers:\n            out = conv(\n                x=out,\n                edge_index=edge_index,\n                edge_attr=edge_attr,\n            )\n        out = self.lin_net(out)\n        return out\n\n\n\nclass NNConvGRU(torch.nn.Module):\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        edge_channels: int,\n        gcn_hidden_nums: List,\n        edge_hidden_nums: List,\n        lin_hidden_nums: List,\n        normalization: str = \"sym\",\n        bias: bool = True,\n    ):\n        super(NNConvGRU, self).__init__()\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.edge_channels = edge_channels\n        self.gcn_hidden_nums = gcn_hidden_nums\n        self.edge_hidden_nums = edge_hidden_nums\n        self.lin_hidden_nums = lin_hidden_nums\n            \n        self.normalization = normalization\n        self.bias = bias\n        self._create_parameters_and_layers()\n\n    def _create_update_gate_parameters_and_layers(self):\n\n        self.conv_x_z = MultiNNConv(\n            in_channels = self.in_channels,\n            out_channels = self.out_channels,\n            edge_channels = self.edge_channels,\n            gcn_hidden_nums = self.gcn_hidden_nums,\n            edge_hidden_nums = self.edge_hidden_nums,\n            lin_hidden_nums = self.lin_hidden_nums,\n        )\n\n        self.conv_h_z = MultiNNConv(\n            in_channels = self.out_channels,\n            out_channels = self.out_channels,\n            edge_channels = self.edge_channels,\n            gcn_hidden_nums = self.gcn_hidden_nums,\n            edge_hidden_nums = self.edge_hidden_nums,\n            lin_hidden_nums = self.lin_hidden_nums,\n        )\n        \n    def _create_reset_gate_parameters_and_layers(self):\n\n        self.conv_x_r = MultiNNConv(\n            in_channels = self.in_channels,\n            out_channels = self.out_channels,\n            edge_channels = self.edge_channels,\n            gcn_hidden_nums = self.gcn_hidden_nums,\n            edge_hidden_nums = self.edge_hidden_nums,\n            lin_hidden_nums = self.lin_hidden_nums,\n        )\n\n        self.conv_h_r = MultiNNConv(\n            in_channels = self.out_channels,\n            out_channels = self.out_channels,\n            edge_channels = self.edge_channels,\n            gcn_hidden_nums = self.gcn_hidden_nums,\n            edge_hidden_nums = self.edge_hidden_nums,\n            lin_hidden_nums = self.lin_hidden_nums,\n        )\n\n    def _create_candidate_state_parameters_and_layers(self):\n\n        self.conv_x_h = MultiNNConv(\n            in_channels = self.in_channels,\n            out_channels = self.out_channels,\n            edge_channels = self.edge_channels,\n            gcn_hidden_nums = self.gcn_hidden_nums,\n            edge_hidden_nums = self.edge_hidden_nums,\n            lin_hidden_nums = self.lin_hidden_nums,\n        )\n\n        self.conv_h_h = MultiNNConv(\n            in_channels = self.out_channels,\n            out_channels = self.out_channels,\n            edge_channels = self.edge_channels,\n            gcn_hidden_nums = self.gcn_hidden_nums,\n            edge_hidden_nums = self.edge_hidden_nums,\n            lin_hidden_nums = self.lin_hidden_nums,\n        )\n\n    def _create_parameters_and_layers(self):\n        self._create_update_gate_parameters_and_layers()\n        self._create_reset_gate_parameters_and_layers()\n        self._create_candidate_state_parameters_and_layers()\n\n    def _set_hidden_state(self, X, H):\n        if H is None:\n            H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n        return H\n\n    def _calculate_update_gate(self, X, edge_index, edge_attr, H):\n        Z = self.conv_x_z(X, edge_index, edge_attr)\n        Z = Z + self.conv_h_z(H, edge_index, edge_attr)\n        Z = torch.sigmoid(Z)\n        return Z\n\n    def _calculate_reset_gate(self, X, edge_index, edge_attr, H):\n        R = self.conv_x_r(X, edge_index, edge_attr)\n        R = R + self.conv_h_r(H, edge_index, edge_attr)\n        R = torch.sigmoid(R)\n        return R\n\n    def _calculate_candidate_state(self, X, edge_index, edge_attr, H, R):\n        H_tilde = self.conv_x_h(X, edge_index, edge_attr)\n        H_tilde = H_tilde + self.conv_h_h(H * R, edge_index, edge_attr)\n        H_tilde = torch.tanh(H_tilde)\n        return H_tilde\n\n    def _calculate_hidden_state(self, Z, H, H_tilde):\n        H = Z * H + (1 - Z) * H_tilde\n        return H\n\n    def forward(\n            self,\n            X: torch.FloatTensor,\n            edge_index: torch.LongTensor,\n            edge_attr: torch.FloatTensor,\n            H: torch.FloatTensor = None,\n        ) -> torch.FloatTensor:\n            H = self._set_hidden_state(X, H)\n            Z = self._calculate_update_gate(X, edge_index, edge_attr, H)\n            R = self._calculate_reset_gate(X, edge_index, edge_attr, H)\n            H_tilde = self._calculate_candidate_state(X, edge_index, edge_attr, H, R)\n            H = self._calculate_hidden_state(Z, H, H_tilde)\n            return H","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:52:08.428681Z","iopub.execute_input":"2023-07-22T11:52:08.429043Z","iopub.status.idle":"2023-07-22T11:52:08.457010Z","shell.execute_reply.started":"2023-07-22T11:52:08.429016Z","shell.execute_reply":"2023-07-22T11:52:08.456082Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## TGAE","metadata":{}},{"cell_type":"code","source":"class TGAE(torch.nn.Module): # Not Heterogeneous\n    def __init__(\n        self, in_channels, out_channels, edge_channels, \n        embedding_hidden_nums, gnn_out_channels, deciding_hidden_nums,\n        gru_gcn_hidden_nums, gru_edge_hidden_nums, gru_lin_hidden_nums):\n        super(TGAE, self).__init__()\n        \n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.edge_channels = edge_channels\n        self.embedding_hidden_nums = embedding_hidden_nums\n        self.gnn_out_channels = gnn_out_channels\n        self.deciding_hidden_nums = deciding_hidden_nums\n        self.gru_gcn_hidden_nums = gru_gcn_hidden_nums\n        self.gru_edge_hidden_nums = gru_edge_hidden_nums\n        self.gru_lin_hidden_nums = gru_lin_hidden_nums\n        \n        # Encoder\n        layers = []\n        pre_h_num = in_channels\n        for h_num in embedding_hidden_nums[:-1]:\n#             layers.append(torch.nn.Dropout(p=0.2))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(torch.nn.LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,embedding_hidden_nums[-1]))\n        self.encoder_embedding_net = Seq(*layers)\n        \n        self.encoder_gru = NNConvGRU(\n            in_channels=embedding_hidden_nums[-1],\n            out_channels=gnn_out_channels,\n            edge_channels=edge_channels,\n            gcn_hidden_nums=gru_gcn_hidden_nums,\n            edge_hidden_nums=gru_edge_hidden_nums,\n            lin_hidden_nums=gru_lin_hidden_nums,\n        )\n\n        layers = []\n        pre_h_num = gnn_out_channels\n        for h_num in deciding_hidden_nums:\n#             layers.append(torch.nn.Dropout(p=0.2))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(torch.nn.LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,out_channels))\n        self.encoder_deciding_net = Seq(*layers)\n        \n        # Decoder\n        layers = []\n        pre_h_num = out_channels\n        for h_num in deciding_hidden_nums[::-1]:\n            layers.append(torch.nn.Dropout(p=0.2))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(torch.nn.LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,gnn_out_channels))\n        self.decoder_deciding_net = Seq(*layers)\n        \n        self.decoder_gru = NNConvGRU(\n            in_channels=gnn_out_channels,\n            out_channels=embedding_hidden_nums[-1],\n            edge_channels=edge_channels,\n            gcn_hidden_nums=gru_gcn_hidden_nums,\n            edge_hidden_nums=gru_edge_hidden_nums,\n            lin_hidden_nums=gru_lin_hidden_nums,\n        )\n        \n        layers = []\n        pre_h_num = embedding_hidden_nums[-1]\n        for h_num in embedding_hidden_nums[:-1][::-1]:\n            layers.append(torch.nn.Dropout(p=0.2))\n            layers.append(Lin(pre_h_num,h_num))\n            layers.append(torch.nn.LeakyReLU())\n            pre_h_num = h_num\n        layers.append(Lin(pre_h_num,in_channels))\n        self.decoder_embedding_net = Seq(*layers)\n        \n\n    def forward(self, x, edge_index, edge_attr, h_encoder=None, h_decoder=None):\n        \"\"\"\n        x = Node features for T time steps\n        edge_index = Graph edge indices\n        \"\"\"\n        # Encoder\n        out = self.encoder_embedding_net(x)\n        \n        # GNN layer\n        h_encoder = self.encoder_gru(out, edge_index, edge_attr, h_encoder) \n        \n        out = self.encoder_deciding_net(h_encoder)\n        \n        out = self.decoder_deciding_net(out)\n        \n        # TODO Reverse Edge Index \n        \n        h_decoder = self.decoder_gru(out, torch.flip(edge_index,dims=(0,)), edge_attr, h_decoder)\n        \n        out = self.decoder_embedding_net(h_decoder)\n\n        return out, h_encoder, h_decoder","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:52:08.458597Z","iopub.execute_input":"2023-07-22T11:52:08.459292Z","iopub.status.idle":"2023-07-22T11:52:08.477118Z","shell.execute_reply.started":"2023-07-22T11:52:08.459259Z","shell.execute_reply":"2023-07-22T11:52:08.476248Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"## Global State Function","metadata":{}},{"cell_type":"code","source":"def create_hidden_global(num_node, out_channels):\n    hidden_global = torch.FloatTensor(np.zeros([num_node,out_channels])).to(device)\n#     hidden_global =torch.zeros([num_node,out_channels], dtype=torch.float).to(device)\n    return hidden_global\n\ndef select_hidden_local(hidden_global, index):\n#     h = hidden_global[index] #REGULAR INDEXING\n    h = hidden_global.index_select(dim=0, index=index) #INDEX SELECT\n    return h\n\n# TODO: Aggregation of hidden and cell\ndef update_hidden_gobal(hidden_global, h, index):\n    # hidden_global[index] = h.detach() #REGULAR INDEXING\n    # for key,value in mapping.items():\n    #     hidden_global[value] = h[key] \n    hidden_global.index_copy_(dim=0, index=index, source=h)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:55:10.563749Z","iopub.execute_input":"2023-07-22T11:55:10.564122Z","iopub.status.idle":"2023-07-22T11:55:10.572079Z","shell.execute_reply.started":"2023-07-22T11:55:10.564093Z","shell.execute_reply":"2023-07-22T11:55:10.570999Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Read Data","metadata":{}},{"cell_type":"code","source":"data_dir_0 = '/kaggle/input/dissertation-data'\ndata_dir_1 = '2021-09-11-umbrella-experiment-32run-fran'\n\n\nsignals = []\ny = []\nwith open(os.path.join(data_dir_0, data_dir_1, \"annotated.json\")) as f:\n    annotated_dict = json.load(f)\n\nfor data_dir_2 in os.listdir(os.path.join(data_dir_0, data_dir_1)):\n    if data_dir_2 == \"annotated.json\":\n        continue\n    r = re.compile(\".*.npz\")\n    graph_files = list(filter(r.match, os.listdir(os.path.join(data_dir_0, data_dir_1, data_dir_2))))\n\n    if len(graph_files) > 1:\n        print(\"Multiple Graph Files!\")\n        raise\n    if len(graph_files) == 0:\n        print(\"Not Found Graph File!\")\n        raise\n\n    dataloader = GraphDatasetLoader(os.path.join(data_dir_0, data_dir_1, data_dir_2, graph_files[0]))\n    signal = dataloader.get_dataset()\n    signals.append(signal)\n    y.append(annotated_dict[data_dir_2])\n\n# split train and test dataset\nsignals_train, signals_test, y_train, y_test = train_test_split(signals, y, test_size=0.2, random_state=1)\nsignals_train, signals_val, y_train, y_val = train_test_split(signals_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-07-22T11:54:58.308567Z","iopub.execute_input":"2023-07-22T11:54:58.309283Z","iopub.status.idle":"2023-07-22T11:54:58.658365Z","shell.execute_reply.started":"2023-07-22T11:54:58.309252Z","shell.execute_reply":"2023-07-22T11:54:58.657359Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"node_attr_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\nnode_attr_encoder = node_attr_encoder.fit(np.concatenate([sample.node_attr for sample in signals_train]))\n\nedge_attr_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\nedge_attr_encoder = edge_attr_encoder.fit(np.concatenate([sample.edge_attr for sample in signals_train]))\n\nfor signal in signals_train:\n    signal.encode_node_attr(node_attr_encoder)\n    signal.encode_edge_attr(edge_attr_encoder)\n\nX_train = []\nfor signal in signals_train:\n    X_train.append(list(signal))\n\nnums_node_train = []\nfor signal in signals_train:\n    nums_node_train.append(signal.node_attr.shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:54:58.683448Z","iopub.execute_input":"2023-07-22T11:54:58.684062Z","iopub.status.idle":"2023-07-22T11:55:01.160595Z","shell.execute_reply.started":"2023-07-22T11:54:58.684025Z","shell.execute_reply":"2023-07-22T11:55:01.159619Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# for sample in X_train[:1]:\n#     for snapshot in sample:\n#         node_attr = snapshot.node_attr\n#         node_index = snapshot.node_index\n#         edge_attr = snapshot.edge_attr\n#         edge_index = snapshot.edge_index\n        \n#         print(f\"node_attr: {node_attr.shape}\")\n#         print(f\"node_index: {node_index.shape}\")\n#         print(f\"edge_attr: {edge_attr.shape}\")\n#         print(f\"edge_index: {edge_index.shape}\")","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-07-22T11:55:01.162418Z","iopub.execute_input":"2023-07-22T11:55:01.162969Z","iopub.status.idle":"2023-07-22T11:55:01.167923Z","shell.execute_reply.started":"2023-07-22T11:55:01.162935Z","shell.execute_reply":"2023-07-22T11:55:01.167004Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCH = 10\nIN_CHANNELS = signals_train[0].node_attr_encoded.shape[1]\nEDGE_CHANNELS = signals_train[0].edge_attr_encoded.shape[1]","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:55:01.169102Z","iopub.execute_input":"2023-07-22T11:55:01.170157Z","iopub.status.idle":"2023-07-22T11:55:01.178432Z","shell.execute_reply.started":"2023-07-22T11:55:01.170115Z","shell.execute_reply":"2023-07-22T11:55:01.177540Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model = TGAE(\n    in_channels=IN_CHANNELS, \n    out_channels=5, \n    edge_channels=EDGE_CHANNELS, \n    embedding_hidden_nums=[4,4],\n    gnn_out_channels=8,\n    deciding_hidden_nums=[4,4],\n    gru_gcn_hidden_nums=[16,16],\n    gru_edge_hidden_nums=[32],\n    gru_lin_hidden_nums=[64,64],\n)\n\nloss_f = torch.nn.MSELoss(reduction = 'none')\noptimizer = torch.optim.Adam(model.parameters(), lr = 2e-4, weight_decay=1e-5)\n\nmodel = model.to(device)\nloss_f = loss_f.to(device)\n# print(model)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:55:01.180544Z","iopub.execute_input":"2023-07-22T11:55:01.181149Z","iopub.status.idle":"2023-07-22T11:55:01.227000Z","shell.execute_reply.started":"2023-07-22T11:55:01.181110Z","shell.execute_reply":"2023-07-22T11:55:01.226057Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# train_loop\ndef train_loop(sample, num_node, state_channels, model, loss_fn, optimizer, device):\n\n    hidden_encoder_global = create_hidden_global(num_node=num_node,out_channels=state_channels)\n    hidden_decoder_global = create_hidden_global(num_node=num_node,out_channels=model.embedding_hidden_nums[-1])\n    # cell_global = create_cell_global(num_nodes=len(global_nodes),out_channels=256)\n    \n    train_losses = []\n    total_loss = 0\n    model.train()\n    for i,snapshot in enumerate(sample,start=1):\n        if snapshot.node_attr.shape[0] == 0:\n            # print(\"snapshot_{} has no data...\".format(i))\n            continue\n\n        _node_index = snapshot.node_index        \n        _node_attr = snapshot.node_attr\n        _edge_attr = snapshot.edge_attr\n        _edge_index =  snapshot.edge_index\n        \n        pre_h_encoder = select_hidden_local(hidden_encoder_global, _node_index)\n        pre_h_decoder = select_hidden_local(hidden_decoder_global, _node_index)\n        \n        # print(_node_attr.type())\n        # Compute prediction and loss\n        outs, h_encoder, h_decoder = model(_node_attr,_edge_index,_edge_attr)\n\n        update_hidden_gobal(hidden_encoder_global, h_encoder.detach(), _node_index)\n        update_hidden_gobal(hidden_decoder_global, h_decoder.detach(), _node_index)\n\n#         train_loss = 0\n#         for i in range(_node_attr.shape[0]):\n# #             train_loss += torch.sqrt(loss_f(torch.log(_node_attr[i]+1), torch.log(outs[i]+1)))\n#             train_loss += torch.sqrt(torch.sum(loss_f(_node_attr[i], outs[i])))\n        train_loss = torch.sum(torch.sqrt(torch.sum(loss_f(_node_attr, outs),dim=1)))\n        total_loss += train_loss\n        train_losses.append(train_loss.cpu().detach().numpy())\n    \n        optimizer.zero_grad()\n        train_loss.backward()\n        optimizer.step()\n    return train_losses","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:03:49.828202Z","iopub.execute_input":"2023-07-22T12:03:49.828592Z","iopub.status.idle":"2023-07-22T12:03:49.839437Z","shell.execute_reply.started":"2023-07-22T12:03:49.828559Z","shell.execute_reply":"2023-07-22T12:03:49.838551Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"for i_epoch in range(1,NUM_EPOCH+1):\n    train_losses = []\n    _start = time.time()\n    for sample,y, num_node in zip(X_train,y_train,nums_node_train):\n        train_loss = train_loop(sample, num_node, model.gnn_out_channels, model, loss_f, optimizer, device)\n#         print(np.mean(train_loss))\n        train_losses += train_loss\n    _end = time.time()\n    print(f\"{i_epoch}/{NUM_EPOCH}: train loss {np.mean(train_losses):.4f} cost {_end-_start:.4f}s\")","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:03:50.545233Z","iopub.execute_input":"2023-07-22T12:03:50.545911Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"1/10: train loss 95.2464 cost 45.4459s\n2/10: train loss 77.9003 cost 44.2892s\n3/10: train loss 58.1484 cost 44.4208s\n4/10: train loss 56.4516 cost 44.2751s\n5/10: train loss 54.7992 cost 44.3660s\n6/10: train loss 50.0876 cost 44.5210s\n7/10: train loss 32.8199 cost 44.3605s\n8/10: train loss 29.3768 cost 44.7493s\n","output_type":"stream"}]},{"cell_type":"code","source":"def test_loop(test_set, num_nodes, state_channels, model, loss_fn, device):\n    size = len(train_set)\n\n    hidden_encoder_global = create_hidden_global(num_nodes=num_nodes,out_channels=state_channels)\n    hidden_decoder_global = create_hidden_global(num_nodes=num_nodes,out_channels=state_channels)\n    # cell_global = create_cell_global(num_nodes=len(global_nodes),out_channels=256)\n    \n    test_losses = []\n    with torch.no_grad():\n        for i,snapshot in enumerate(test_set,start=1):\n            if snapshot.node_attr.shape[0] == 0:\n                # print(\"snapshot_{} has no data...\".format(i))\n                continue\n\n            node_attr = snapshot.node_attr\n            node_index = snapshot.node_index\n            edge_attr = snapshot.edge_attr\n            edge_index = snapshot.edge_index\n\n\n            _node_attr = node_attr.to(device)\n            _edge_attr = edge_attr.to(device)\n            _edge_index = edge_index.to(device)\n\n            pre_h_encoder = torch.tensor(select_hidden_local(hidden_encoder_global, node_index),dtype=torch.float32).to(device)\n            pre_h_decoder = torch.tensor(select_hidden_local(hidden_decoder_global, node_index),dtype=torch.float32).to(device)\n\n            # Compute prediction and loss\n            outs, h_encoder, h_decoder = model(_node_attr,_edge_index,_edge_attr)\n\n            update_hidden_gobal(hidden_encoder_global, h_encoder, node_index)\n            update_hidden_gobal(hidden_decoder_global, h_decoder, node_index)\n\n            test_loss = 0\n            for i in range(node_attr.shape[0]):\n    #             train_loss += torch.sqrt(loss_f(torch.log(_node_attr[i]+1), torch.log(outs[i]+1)))\n                test_loss += torch.sqrt(loss_f(_node_attr[i], outs[i]))\n        \n        if(use_gpu):\n            test_losses.append(test_loss.cpu().detach().numpy())\n        else:\n            test_losses.append(test_loss.detach().numpy())\n    return test_losses\n        ","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:03:31.687416Z","iopub.status.idle":"2023-07-22T12:03:31.688287Z","shell.execute_reply.started":"2023-07-22T12:03:31.688042Z","shell.execute_reply":"2023-07-22T12:03:31.688065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}